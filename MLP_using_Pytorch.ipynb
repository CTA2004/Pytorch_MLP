{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sW9cpiiozk3w"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read the data file**"
      ],
      "metadata": {
        "id": "SvYGf9u81ZVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('iris.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6LlhSxaVz9BZ",
        "outputId": "37e196fb-7869-4a1d-e5d9-33c28836e2eb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sepal.length  sepal.width  petal.length  petal.width variety\n",
              "0           5.1          3.5           1.4          0.2  Setosa\n",
              "1           4.9          3.0           1.4          0.2  Setosa\n",
              "2           4.7          3.2           1.3          0.2  Setosa\n",
              "3           4.6          3.1           1.5          0.2  Setosa\n",
              "4           5.0          3.6           1.4          0.2  Setosa"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1c8bb323-ed45-47b9-8577-4894aaf92d42\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal.length</th>\n",
              "      <th>sepal.width</th>\n",
              "      <th>petal.length</th>\n",
              "      <th>petal.width</th>\n",
              "      <th>variety</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c8bb323-ed45-47b9-8577-4894aaf92d42')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1c8bb323-ed45-47b9-8577-4894aaf92d42 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1c8bb323-ed45-47b9-8577-4894aaf92d42');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3c871286-13a1-4e14-b156-259824fe3db6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3c871286-13a1-4e14-b156-259824fe3db6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3c871286-13a1-4e14-b156-259824fe3db6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 150,\n  \"fields\": [\n    {\n      \"column\": \"sepal.length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8280661279778629,\n        \"min\": 4.3,\n        \"max\": 7.9,\n        \"num_unique_values\": 35,\n        \"samples\": [\n          6.2,\n          4.5,\n          5.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sepal.width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.435866284936698,\n        \"min\": 2.0,\n        \"max\": 4.4,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          2.3,\n          4.0,\n          3.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal.length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7652982332594667,\n        \"min\": 1.0,\n        \"max\": 6.9,\n        \"num_unique_values\": 43,\n        \"samples\": [\n          6.7,\n          3.8,\n          3.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal.width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7622376689603465,\n        \"min\": 0.1,\n        \"max\": 2.5,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0.2,\n          1.2,\n          1.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"variety\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Setosa\",\n          \"Versicolor\",\n          \"Virginica\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "vnDeJLk11KW4",
        "outputId": "3248a13b-496c-486a-80ff-41254f48c4b1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       sepal.length  sepal.width  petal.length  petal.width\n",
              "count    150.000000   150.000000    150.000000   150.000000\n",
              "mean       5.843333     3.057333      3.758000     1.199333\n",
              "std        0.828066     0.435866      1.765298     0.762238\n",
              "min        4.300000     2.000000      1.000000     0.100000\n",
              "25%        5.100000     2.800000      1.600000     0.300000\n",
              "50%        5.800000     3.000000      4.350000     1.300000\n",
              "75%        6.400000     3.300000      5.100000     1.800000\n",
              "max        7.900000     4.400000      6.900000     2.500000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6cf139f-7299-4c29-9d31-8d7d8115c24a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal.length</th>\n",
              "      <th>sepal.width</th>\n",
              "      <th>petal.length</th>\n",
              "      <th>petal.width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.843333</td>\n",
              "      <td>3.057333</td>\n",
              "      <td>3.758000</td>\n",
              "      <td>1.199333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.828066</td>\n",
              "      <td>0.435866</td>\n",
              "      <td>1.765298</td>\n",
              "      <td>0.762238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.300000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.100000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>0.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.800000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.350000</td>\n",
              "      <td>1.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.400000</td>\n",
              "      <td>3.300000</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>1.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.900000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>6.900000</td>\n",
              "      <td>2.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6cf139f-7299-4c29-9d31-8d7d8115c24a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e6cf139f-7299-4c29-9d31-8d7d8115c24a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e6cf139f-7299-4c29-9d31-8d7d8115c24a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-583e5b12-40f4-470b-867b-12749d2d03de\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-583e5b12-40f4-470b-867b-12749d2d03de')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-583e5b12-40f4-470b-867b-12749d2d03de button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"sepal.length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 51.24711349471842,\n        \"min\": 0.8280661279778629,\n        \"max\": 150.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5.843333333333334,\n          5.8,\n          150.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sepal.width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 52.08617800869866,\n        \"min\": 0.435866284936698,\n        \"max\": 150.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          3.0573333333333337,\n          3.0,\n          150.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal.length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 51.83521261418364,\n        \"min\": 1.0,\n        \"max\": 150.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          3.7580000000000005,\n          4.35,\n          150.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal.width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 52.636648242617504,\n        \"min\": 0.1,\n        \"max\": 150.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1.1993333333333336,\n          1.3,\n          150.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data preprocessing and visualizing**"
      ],
      "metadata": {
        "id": "QzrLDBL-1iJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['variety'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "UpPESY0U1oti",
        "outputId": "9ed9991d-702c-4d39-9a31-124154742b38"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "variety\n",
              "Setosa        50\n",
              "Versicolor    50\n",
              "Virginica     50\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>variety</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Setosa</th>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Versicolor</th>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Virginica</th>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['variety'].value_counts().plot(kind = 'pie')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "CPJpqGnN2noZ",
        "outputId": "2640de8c-4f32-4d8f-fc43-3d6d93fc9cbd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['variety'] = data['variety'].map({'Setosa': 0, 'Versicolor': 1, 'Virginica': 2})\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9D8j4ptu2bFJ",
        "outputId": "2168a234-48df-4c19-dab7-08be6c54dca4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sepal.length  sepal.width  petal.length  petal.width  variety\n",
              "0           5.1          3.5           1.4          0.2        0\n",
              "1           4.9          3.0           1.4          0.2        0\n",
              "2           4.7          3.2           1.3          0.2        0\n",
              "3           4.6          3.1           1.5          0.2        0\n",
              "4           5.0          3.6           1.4          0.2        0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de89ec40-e26d-496b-a606-adbf9a6ff4ee\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal.length</th>\n",
              "      <th>sepal.width</th>\n",
              "      <th>petal.length</th>\n",
              "      <th>petal.width</th>\n",
              "      <th>variety</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de89ec40-e26d-496b-a606-adbf9a6ff4ee')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-de89ec40-e26d-496b-a606-adbf9a6ff4ee button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-de89ec40-e26d-496b-a606-adbf9a6ff4ee');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9758e5fe-c5ce-4c2b-858f-21f8a07bfc78\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9758e5fe-c5ce-4c2b-858f-21f8a07bfc78')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9758e5fe-c5ce-4c2b-858f-21f8a07bfc78 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 150,\n  \"fields\": [\n    {\n      \"column\": \"sepal.length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8280661279778629,\n        \"min\": 4.3,\n        \"max\": 7.9,\n        \"num_unique_values\": 35,\n        \"samples\": [\n          6.2,\n          4.5,\n          5.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sepal.width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.435866284936698,\n        \"min\": 2.0,\n        \"max\": 4.4,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          2.3,\n          4.0,\n          3.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal.length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7652982332594667,\n        \"min\": 1.0,\n        \"max\": 6.9,\n        \"num_unique_values\": 43,\n        \"samples\": [\n          6.7,\n          3.8,\n          3.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal.width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7622376689603465,\n        \"min\": 0.1,\n        \"max\": 2.5,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0.2,\n          1.2,\n          1.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"variety\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(data['sepal.length'], data['sepal.width'], c = data['variety'], cmap = 'rainbow')\n",
        "plt.xlabel('Sepal Length')\n",
        "plt.ylabel('Sepal Width')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "YrdMy-4BcVAq",
        "outputId": "c86b9216-0123-4e86-e783-f5531d68718a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data split into train, validation and test**"
      ],
      "metadata": {
        "id": "PggVX3HMYugh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = data.drop('variety', axis = 1)\n",
        "y = data['variety']"
      ],
      "metadata": {
        "id": "QlQAfxIfDkQJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, random_state = 1, shuffle = True, stratify = y)"
      ],
      "metadata": {
        "id": "QkT9Ve8lV8gv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state = 1, shuffle = True, stratify = y_train)"
      ],
      "metadata": {
        "id": "KhqK_3bhKn0D"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1J557NQvXGrY",
        "outputId": "353e75e8-801f-41d5-d7fe-7436e8308cc0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(121, 4)\n",
            "(14, 4)\n",
            "(15, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training labels: ', np.bincount(y_train))\n",
        "print('Validation labels: ',np.bincount(y_val))\n",
        "print('Testing labels: ',np.bincount(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAElGE-TYJlH",
        "outputId": "21e4a2b4-75aa-4a73-9e82-12c311eea736"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training labels:  [41 40 40]\n",
            "Validation labels:  [4 5 5]\n",
            "Testing labels:  [5 5 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(torch.nn.Module):\n",
        "  def __init__(self, num_features, num_classes):\n",
        "    super().__init__()\n",
        "    self.all_layers = torch.nn.Sequential(\n",
        "        # input layer\n",
        "        torch.nn.Linear(num_features, 40),\n",
        "        torch.nn.ReLU(),\n",
        "        # hidden layer\n",
        "        torch.nn.Linear(40, 20),\n",
        "        torch.nn.ReLU(),\n",
        "        # output layer\n",
        "        torch.nn.Linear(20, num_classes)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    logits = self.all_layers(x)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "49WD91woDmTS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "   def __init__(self, x, y):\n",
        "\n",
        "       self.features = torch.tensor(x.values, dtype = torch.float32)\n",
        "       self.classes = torch.tensor(y.values, dtype = torch.int64)\n",
        "\n",
        "   def __len__(self):\n",
        "      return self.classes.shape[0]\n",
        "\n",
        "   def __getitem__(self, idx):\n",
        "       x = self.features[idx]\n",
        "       y = self.classes[idx]\n",
        "       return x, y"
      ],
      "metadata": {
        "id": "wJnKhSEghOAK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define loader**"
      ],
      "metadata": {
        "id": "KZ4FwfoRkhoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = MyDataset(x_train, y_train)\n",
        "val_ds = MyDataset(x_val, y_val)\n",
        "test_ds = MyDataset(x_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(dataset = train_ds, batch_size = 32, shuffle = True)\n",
        "val_loader = DataLoader(dataset = val_ds, batch_size = 32, shuffle = False)\n",
        "test_loader = DataLoader(dataset= test_ds, batch_size = 32, shuffle = False)"
      ],
      "metadata": {
        "id": "Fr-sUdmwi5ex"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(model, data_loader):\n",
        "   model = model.eval()\n",
        "\n",
        "   correct = 0.0\n",
        "   total = 0\n",
        "\n",
        "   for idx, (features, classes) in enumerate(data_loader):\n",
        "\n",
        "          with torch.inference_mode():\n",
        "               logits = model(features)\n",
        "\n",
        "          predictions = torch.argmax(logits, dim = 1)\n",
        "\n",
        "          compare = classes == predictions\n",
        "          correct += torch.sum(compare)\n",
        "          total += len(compare)\n",
        "\n",
        "   return correct / total"
      ],
      "metadata": {
        "id": "Wr4vu3I5krCC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)\n",
        "model = MLP(num_features = 4,num_classes = 3)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\n"
      ],
      "metadata": {
        "id": "GYWfnlInHNkr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1000\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model = model.train()\n",
        "    for batch_idx, (features, classes) in enumerate(train_loader):\n",
        "\n",
        "        logits = model(features)\n",
        "        loss = F.cross_entropy(logits, classes)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item():.4f}')\n",
        "\n",
        "    train_acc = compute_accuracy(model, train_loader)\n",
        "    val_acc = compute_accuracy(model, val_loader)\n",
        "    print(f'Epoch: {epoch}, Training Accuracy: {train_acc*100:.2f}%, Validation Accuracy: {val_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e8fuiOZIyab",
        "outputId": "f9c36776-d76c-4666-f1ee-549f01851da3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Batch: 0, Loss: 0.0180\n",
            "Epoch: 0, Batch: 1, Loss: 0.0051\n",
            "Epoch: 0, Batch: 2, Loss: 0.0577\n",
            "Epoch: 0, Batch: 3, Loss: 0.1198\n",
            "Epoch: 0, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 1, Batch: 0, Loss: 0.1202\n",
            "Epoch: 1, Batch: 1, Loss: 0.0151\n",
            "Epoch: 1, Batch: 2, Loss: 0.0323\n",
            "Epoch: 1, Batch: 3, Loss: 0.0237\n",
            "Epoch: 1, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 2, Batch: 0, Loss: 0.1293\n",
            "Epoch: 2, Batch: 1, Loss: 0.0373\n",
            "Epoch: 2, Batch: 2, Loss: 0.0026\n",
            "Epoch: 2, Batch: 3, Loss: 0.0089\n",
            "Epoch: 2, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 3, Batch: 0, Loss: 0.1374\n",
            "Epoch: 3, Batch: 1, Loss: 0.0228\n",
            "Epoch: 3, Batch: 2, Loss: 0.0033\n",
            "Epoch: 3, Batch: 3, Loss: 0.0390\n",
            "Epoch: 3, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 4, Batch: 0, Loss: 0.0070\n",
            "Epoch: 4, Batch: 1, Loss: 0.0441\n",
            "Epoch: 4, Batch: 2, Loss: 0.0901\n",
            "Epoch: 4, Batch: 3, Loss: 0.0852\n",
            "Epoch: 4, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 5, Batch: 0, Loss: 0.0095\n",
            "Epoch: 5, Batch: 1, Loss: 0.1329\n",
            "Epoch: 5, Batch: 2, Loss: 0.0154\n",
            "Epoch: 5, Batch: 3, Loss: 0.0620\n",
            "Epoch: 5, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 6, Batch: 0, Loss: 0.0108\n",
            "Epoch: 6, Batch: 1, Loss: 0.0122\n",
            "Epoch: 6, Batch: 2, Loss: 0.0206\n",
            "Epoch: 6, Batch: 3, Loss: 0.2019\n",
            "Epoch: 6, Training Accuracy: 94.21%, Validation Accuracy: 92.86%\n",
            "Epoch: 7, Batch: 0, Loss: 0.0174\n",
            "Epoch: 7, Batch: 1, Loss: 0.0893\n",
            "Epoch: 7, Batch: 2, Loss: 0.0788\n",
            "Epoch: 7, Batch: 3, Loss: 0.0173\n",
            "Epoch: 7, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 8, Batch: 0, Loss: 0.0162\n",
            "Epoch: 8, Batch: 1, Loss: 0.0139\n",
            "Epoch: 8, Batch: 2, Loss: 0.0432\n",
            "Epoch: 8, Batch: 3, Loss: 0.1618\n",
            "Epoch: 8, Training Accuracy: 97.52%, Validation Accuracy: 92.86%\n",
            "Epoch: 9, Batch: 0, Loss: 0.1161\n",
            "Epoch: 9, Batch: 1, Loss: 0.0252\n",
            "Epoch: 9, Batch: 2, Loss: 0.0359\n",
            "Epoch: 9, Batch: 3, Loss: 0.0070\n",
            "Epoch: 9, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 10, Batch: 0, Loss: 0.1297\n",
            "Epoch: 10, Batch: 1, Loss: 0.0120\n",
            "Epoch: 10, Batch: 2, Loss: 0.0283\n",
            "Epoch: 10, Batch: 3, Loss: 0.0251\n",
            "Epoch: 10, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 11, Batch: 0, Loss: 0.0149\n",
            "Epoch: 11, Batch: 1, Loss: 0.0601\n",
            "Epoch: 11, Batch: 2, Loss: 0.0084\n",
            "Epoch: 11, Batch: 3, Loss: 0.1921\n",
            "Epoch: 11, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 12, Batch: 0, Loss: 0.1172\n",
            "Epoch: 12, Batch: 1, Loss: 0.0034\n",
            "Epoch: 12, Batch: 2, Loss: 0.0272\n",
            "Epoch: 12, Batch: 3, Loss: 0.0600\n",
            "Epoch: 12, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 13, Batch: 0, Loss: 0.0029\n",
            "Epoch: 13, Batch: 1, Loss: 0.1253\n",
            "Epoch: 13, Batch: 2, Loss: 0.0242\n",
            "Epoch: 13, Batch: 3, Loss: 0.0591\n",
            "Epoch: 13, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 14, Batch: 0, Loss: 0.1190\n",
            "Epoch: 14, Batch: 1, Loss: 0.0419\n",
            "Epoch: 14, Batch: 2, Loss: 0.0297\n",
            "Epoch: 14, Batch: 3, Loss: 0.0379\n",
            "Epoch: 14, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 15, Batch: 0, Loss: 0.0291\n",
            "Epoch: 15, Batch: 1, Loss: 0.0253\n",
            "Epoch: 15, Batch: 2, Loss: 0.1401\n",
            "Epoch: 15, Batch: 3, Loss: 0.0146\n",
            "Epoch: 15, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 16, Batch: 0, Loss: 0.0383\n",
            "Epoch: 16, Batch: 1, Loss: 0.1175\n",
            "Epoch: 16, Batch: 2, Loss: 0.0203\n",
            "Epoch: 16, Batch: 3, Loss: 0.0264\n",
            "Epoch: 16, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 17, Batch: 0, Loss: 0.0346\n",
            "Epoch: 17, Batch: 1, Loss: 0.1002\n",
            "Epoch: 17, Batch: 2, Loss: 0.0540\n",
            "Epoch: 17, Batch: 3, Loss: 0.0059\n",
            "Epoch: 17, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 18, Batch: 0, Loss: 0.0086\n",
            "Epoch: 18, Batch: 1, Loss: 0.0297\n",
            "Epoch: 18, Batch: 2, Loss: 0.0339\n",
            "Epoch: 18, Batch: 3, Loss: 0.1389\n",
            "Epoch: 18, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 19, Batch: 0, Loss: 0.0150\n",
            "Epoch: 19, Batch: 1, Loss: 0.0802\n",
            "Epoch: 19, Batch: 2, Loss: 0.1367\n",
            "Epoch: 19, Batch: 3, Loss: 0.0143\n",
            "Epoch: 19, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 20, Batch: 0, Loss: 0.0266\n",
            "Epoch: 20, Batch: 1, Loss: 0.0249\n",
            "Epoch: 20, Batch: 2, Loss: 0.0931\n",
            "Epoch: 20, Batch: 3, Loss: 0.0748\n",
            "Epoch: 20, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 21, Batch: 0, Loss: 0.1233\n",
            "Epoch: 21, Batch: 1, Loss: 0.0501\n",
            "Epoch: 21, Batch: 2, Loss: 0.0233\n",
            "Epoch: 21, Batch: 3, Loss: 0.0022\n",
            "Epoch: 21, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 22, Batch: 0, Loss: 0.1018\n",
            "Epoch: 22, Batch: 1, Loss: 0.0182\n",
            "Epoch: 22, Batch: 2, Loss: 0.0159\n",
            "Epoch: 22, Batch: 3, Loss: 0.0758\n",
            "Epoch: 22, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 23, Batch: 0, Loss: 0.0404\n",
            "Epoch: 23, Batch: 1, Loss: 0.1211\n",
            "Epoch: 23, Batch: 2, Loss: 0.0330\n",
            "Epoch: 23, Batch: 3, Loss: 0.0383\n",
            "Epoch: 23, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 24, Batch: 0, Loss: 0.0061\n",
            "Epoch: 24, Batch: 1, Loss: 0.0233\n",
            "Epoch: 24, Batch: 2, Loss: 0.0566\n",
            "Epoch: 24, Batch: 3, Loss: 0.1522\n",
            "Epoch: 24, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 25, Batch: 0, Loss: 0.0397\n",
            "Epoch: 25, Batch: 1, Loss: 0.0251\n",
            "Epoch: 25, Batch: 2, Loss: 0.1197\n",
            "Epoch: 25, Batch: 3, Loss: 0.0187\n",
            "Epoch: 25, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 26, Batch: 0, Loss: 0.0710\n",
            "Epoch: 26, Batch: 1, Loss: 0.0291\n",
            "Epoch: 26, Batch: 2, Loss: 0.1020\n",
            "Epoch: 26, Batch: 3, Loss: 0.0119\n",
            "Epoch: 26, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 27, Batch: 0, Loss: 0.0392\n",
            "Epoch: 27, Batch: 1, Loss: 0.0059\n",
            "Epoch: 27, Batch: 2, Loss: 0.1395\n",
            "Epoch: 27, Batch: 3, Loss: 0.0063\n",
            "Epoch: 27, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 28, Batch: 0, Loss: 0.0461\n",
            "Epoch: 28, Batch: 1, Loss: 0.1073\n",
            "Epoch: 28, Batch: 2, Loss: 0.0440\n",
            "Epoch: 28, Batch: 3, Loss: 0.0021\n",
            "Epoch: 28, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 29, Batch: 0, Loss: 0.0347\n",
            "Epoch: 29, Batch: 1, Loss: 0.0386\n",
            "Epoch: 29, Batch: 2, Loss: 0.1123\n",
            "Epoch: 29, Batch: 3, Loss: 0.0023\n",
            "Epoch: 29, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 30, Batch: 0, Loss: 0.0407\n",
            "Epoch: 30, Batch: 1, Loss: 0.0331\n",
            "Epoch: 30, Batch: 2, Loss: 0.1175\n",
            "Epoch: 30, Batch: 3, Loss: 0.0287\n",
            "Epoch: 30, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 31, Batch: 0, Loss: 0.0485\n",
            "Epoch: 31, Batch: 1, Loss: 0.1271\n",
            "Epoch: 31, Batch: 2, Loss: 0.0189\n",
            "Epoch: 31, Batch: 3, Loss: 0.0279\n",
            "Epoch: 31, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 32, Batch: 0, Loss: 0.0056\n",
            "Epoch: 32, Batch: 1, Loss: 0.0206\n",
            "Epoch: 32, Batch: 2, Loss: 0.1750\n",
            "Epoch: 32, Batch: 3, Loss: 0.0028\n",
            "Epoch: 32, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 33, Batch: 0, Loss: 0.0746\n",
            "Epoch: 33, Batch: 1, Loss: 0.0410\n",
            "Epoch: 33, Batch: 2, Loss: 0.0327\n",
            "Epoch: 33, Batch: 3, Loss: 0.0428\n",
            "Epoch: 33, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 34, Batch: 0, Loss: 0.0093\n",
            "Epoch: 34, Batch: 1, Loss: 0.0194\n",
            "Epoch: 34, Batch: 2, Loss: 0.1191\n",
            "Epoch: 34, Batch: 3, Loss: 0.0622\n",
            "Epoch: 34, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 35, Batch: 0, Loss: 0.0341\n",
            "Epoch: 35, Batch: 1, Loss: 0.0185\n",
            "Epoch: 35, Batch: 2, Loss: 0.1218\n",
            "Epoch: 35, Batch: 3, Loss: 0.0013\n",
            "Epoch: 35, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 36, Batch: 0, Loss: 0.0360\n",
            "Epoch: 36, Batch: 1, Loss: 0.1315\n",
            "Epoch: 36, Batch: 2, Loss: 0.0629\n",
            "Epoch: 36, Batch: 3, Loss: 0.0072\n",
            "Epoch: 36, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 37, Batch: 0, Loss: 0.0657\n",
            "Epoch: 37, Batch: 1, Loss: 0.1037\n",
            "Epoch: 37, Batch: 2, Loss: 0.0140\n",
            "Epoch: 37, Batch: 3, Loss: 0.0023\n",
            "Epoch: 37, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 38, Batch: 0, Loss: 0.0176\n",
            "Epoch: 38, Batch: 1, Loss: 0.0943\n",
            "Epoch: 38, Batch: 2, Loss: 0.0764\n",
            "Epoch: 38, Batch: 3, Loss: 0.0340\n",
            "Epoch: 38, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 39, Batch: 0, Loss: 0.0411\n",
            "Epoch: 39, Batch: 1, Loss: 0.1034\n",
            "Epoch: 39, Batch: 2, Loss: 0.0366\n",
            "Epoch: 39, Batch: 3, Loss: 0.0010\n",
            "Epoch: 39, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 40, Batch: 0, Loss: 0.0226\n",
            "Epoch: 40, Batch: 1, Loss: 0.0353\n",
            "Epoch: 40, Batch: 2, Loss: 0.1261\n",
            "Epoch: 40, Batch: 3, Loss: 0.0160\n",
            "Epoch: 40, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 41, Batch: 0, Loss: 0.0192\n",
            "Epoch: 41, Batch: 1, Loss: 0.0265\n",
            "Epoch: 41, Batch: 2, Loss: 0.0199\n",
            "Epoch: 41, Batch: 3, Loss: 0.1526\n",
            "Epoch: 41, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 42, Batch: 0, Loss: 0.0524\n",
            "Epoch: 42, Batch: 1, Loss: 0.1026\n",
            "Epoch: 42, Batch: 2, Loss: 0.0111\n",
            "Epoch: 42, Batch: 3, Loss: 0.0258\n",
            "Epoch: 42, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 43, Batch: 0, Loss: 0.1363\n",
            "Epoch: 43, Batch: 1, Loss: 0.0369\n",
            "Epoch: 43, Batch: 2, Loss: 0.0248\n",
            "Epoch: 43, Batch: 3, Loss: 0.0026\n",
            "Epoch: 43, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 44, Batch: 0, Loss: 0.0164\n",
            "Epoch: 44, Batch: 1, Loss: 0.0342\n",
            "Epoch: 44, Batch: 2, Loss: 0.1204\n",
            "Epoch: 44, Batch: 3, Loss: 0.0110\n",
            "Epoch: 44, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 45, Batch: 0, Loss: 0.0512\n",
            "Epoch: 45, Batch: 1, Loss: 0.0081\n",
            "Epoch: 45, Batch: 2, Loss: 0.1149\n",
            "Epoch: 45, Batch: 3, Loss: 0.0029\n",
            "Epoch: 45, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 46, Batch: 0, Loss: 0.0904\n",
            "Epoch: 46, Batch: 1, Loss: 0.1565\n",
            "Epoch: 46, Batch: 2, Loss: 0.0121\n",
            "Epoch: 46, Batch: 3, Loss: 0.0570\n",
            "Epoch: 46, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 47, Batch: 0, Loss: 0.1192\n",
            "Epoch: 47, Batch: 1, Loss: 0.0165\n",
            "Epoch: 47, Batch: 2, Loss: 0.0496\n",
            "Epoch: 47, Batch: 3, Loss: 0.0065\n",
            "Epoch: 47, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 48, Batch: 0, Loss: 0.0287\n",
            "Epoch: 48, Batch: 1, Loss: 0.0369\n",
            "Epoch: 48, Batch: 2, Loss: 0.0069\n",
            "Epoch: 48, Batch: 3, Loss: 0.1906\n",
            "Epoch: 48, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 49, Batch: 0, Loss: 0.0972\n",
            "Epoch: 49, Batch: 1, Loss: 0.1490\n",
            "Epoch: 49, Batch: 2, Loss: 0.0039\n",
            "Epoch: 49, Batch: 3, Loss: 0.0376\n",
            "Epoch: 49, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 50, Batch: 0, Loss: 0.0216\n",
            "Epoch: 50, Batch: 1, Loss: 0.1293\n",
            "Epoch: 50, Batch: 2, Loss: 0.0209\n",
            "Epoch: 50, Batch: 3, Loss: 0.0035\n",
            "Epoch: 50, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 51, Batch: 0, Loss: 0.0208\n",
            "Epoch: 51, Batch: 1, Loss: 0.0429\n",
            "Epoch: 51, Batch: 2, Loss: 0.0369\n",
            "Epoch: 51, Batch: 3, Loss: 0.1257\n",
            "Epoch: 51, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 52, Batch: 0, Loss: 0.0184\n",
            "Epoch: 52, Batch: 1, Loss: 0.0517\n",
            "Epoch: 52, Batch: 2, Loss: 0.1417\n",
            "Epoch: 52, Batch: 3, Loss: 0.0230\n",
            "Epoch: 52, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 53, Batch: 0, Loss: 0.0088\n",
            "Epoch: 53, Batch: 1, Loss: 0.0406\n",
            "Epoch: 53, Batch: 2, Loss: 0.1197\n",
            "Epoch: 53, Batch: 3, Loss: 0.0084\n",
            "Epoch: 53, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 54, Batch: 0, Loss: 0.0063\n",
            "Epoch: 54, Batch: 1, Loss: 0.0405\n",
            "Epoch: 54, Batch: 2, Loss: 0.1043\n",
            "Epoch: 54, Batch: 3, Loss: 0.0498\n",
            "Epoch: 54, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 55, Batch: 0, Loss: 0.1200\n",
            "Epoch: 55, Batch: 1, Loss: 0.0087\n",
            "Epoch: 55, Batch: 2, Loss: 0.0424\n",
            "Epoch: 55, Batch: 3, Loss: 0.0095\n",
            "Epoch: 55, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 56, Batch: 0, Loss: 0.0080\n",
            "Epoch: 56, Batch: 1, Loss: 0.1144\n",
            "Epoch: 56, Batch: 2, Loss: 0.0429\n",
            "Epoch: 56, Batch: 3, Loss: 0.0247\n",
            "Epoch: 56, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 57, Batch: 0, Loss: 0.0654\n",
            "Epoch: 57, Batch: 1, Loss: 0.1083\n",
            "Epoch: 57, Batch: 2, Loss: 0.0049\n",
            "Epoch: 57, Batch: 3, Loss: 0.0124\n",
            "Epoch: 57, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 58, Batch: 0, Loss: 0.0052\n",
            "Epoch: 58, Batch: 1, Loss: 0.0984\n",
            "Epoch: 58, Batch: 2, Loss: 0.0554\n",
            "Epoch: 58, Batch: 3, Loss: 0.0385\n",
            "Epoch: 58, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 59, Batch: 0, Loss: 0.0058\n",
            "Epoch: 59, Batch: 1, Loss: 0.0349\n",
            "Epoch: 59, Batch: 2, Loss: 0.0622\n",
            "Epoch: 59, Batch: 3, Loss: 0.1745\n",
            "Epoch: 59, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 60, Batch: 0, Loss: 0.0363\n",
            "Epoch: 60, Batch: 1, Loss: 0.1402\n",
            "Epoch: 60, Batch: 2, Loss: 0.0564\n",
            "Epoch: 60, Batch: 3, Loss: 0.0055\n",
            "Epoch: 60, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 61, Batch: 0, Loss: 0.0083\n",
            "Epoch: 61, Batch: 1, Loss: 0.1091\n",
            "Epoch: 61, Batch: 2, Loss: 0.0667\n",
            "Epoch: 61, Batch: 3, Loss: 0.0343\n",
            "Epoch: 61, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 62, Batch: 0, Loss: 0.0289\n",
            "Epoch: 62, Batch: 1, Loss: 0.0068\n",
            "Epoch: 62, Batch: 2, Loss: 0.0402\n",
            "Epoch: 62, Batch: 3, Loss: 0.1437\n",
            "Epoch: 62, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 63, Batch: 0, Loss: 0.0522\n",
            "Epoch: 63, Batch: 1, Loss: 0.1175\n",
            "Epoch: 63, Batch: 2, Loss: 0.0174\n",
            "Epoch: 63, Batch: 3, Loss: 0.0135\n",
            "Epoch: 63, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 64, Batch: 0, Loss: 0.0374\n",
            "Epoch: 64, Batch: 1, Loss: 0.1307\n",
            "Epoch: 64, Batch: 2, Loss: 0.0108\n",
            "Epoch: 64, Batch: 3, Loss: 0.0217\n",
            "Epoch: 64, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 65, Batch: 0, Loss: 0.0079\n",
            "Epoch: 65, Batch: 1, Loss: 0.0119\n",
            "Epoch: 65, Batch: 2, Loss: 0.0302\n",
            "Epoch: 65, Batch: 3, Loss: 0.1860\n",
            "Epoch: 65, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 66, Batch: 0, Loss: 0.0116\n",
            "Epoch: 66, Batch: 1, Loss: 0.0795\n",
            "Epoch: 66, Batch: 2, Loss: 0.1580\n",
            "Epoch: 66, Batch: 3, Loss: 0.0066\n",
            "Epoch: 66, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 67, Batch: 0, Loss: 0.0210\n",
            "Epoch: 67, Batch: 1, Loss: 0.0075\n",
            "Epoch: 67, Batch: 2, Loss: 0.1587\n",
            "Epoch: 67, Batch: 3, Loss: 0.0411\n",
            "Epoch: 67, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 68, Batch: 0, Loss: 0.0169\n",
            "Epoch: 68, Batch: 1, Loss: 0.1212\n",
            "Epoch: 68, Batch: 2, Loss: 0.0199\n",
            "Epoch: 68, Batch: 3, Loss: 0.0266\n",
            "Epoch: 68, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 69, Batch: 0, Loss: 0.0245\n",
            "Epoch: 69, Batch: 1, Loss: 0.0158\n",
            "Epoch: 69, Batch: 2, Loss: 0.1318\n",
            "Epoch: 69, Batch: 3, Loss: 0.0460\n",
            "Epoch: 69, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 70, Batch: 0, Loss: 0.0152\n",
            "Epoch: 70, Batch: 1, Loss: 0.1377\n",
            "Epoch: 70, Batch: 2, Loss: 0.0301\n",
            "Epoch: 70, Batch: 3, Loss: 0.0134\n",
            "Epoch: 70, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 71, Batch: 0, Loss: 0.0661\n",
            "Epoch: 71, Batch: 1, Loss: 0.0029\n",
            "Epoch: 71, Batch: 2, Loss: 0.1357\n",
            "Epoch: 71, Batch: 3, Loss: 0.0165\n",
            "Epoch: 71, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 72, Batch: 0, Loss: 0.0487\n",
            "Epoch: 72, Batch: 1, Loss: 0.0165\n",
            "Epoch: 72, Batch: 2, Loss: 0.0059\n",
            "Epoch: 72, Batch: 3, Loss: 0.1779\n",
            "Epoch: 72, Training Accuracy: 97.52%, Validation Accuracy: 92.86%\n",
            "Epoch: 73, Batch: 0, Loss: 0.0883\n",
            "Epoch: 73, Batch: 1, Loss: 0.0050\n",
            "Epoch: 73, Batch: 2, Loss: 0.1316\n",
            "Epoch: 73, Batch: 3, Loss: 0.0451\n",
            "Epoch: 73, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 74, Batch: 0, Loss: 0.0152\n",
            "Epoch: 74, Batch: 1, Loss: 0.1072\n",
            "Epoch: 74, Batch: 2, Loss: 0.0474\n",
            "Epoch: 74, Batch: 3, Loss: 0.0289\n",
            "Epoch: 74, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 75, Batch: 0, Loss: 0.0146\n",
            "Epoch: 75, Batch: 1, Loss: 0.0343\n",
            "Epoch: 75, Batch: 2, Loss: 0.1200\n",
            "Epoch: 75, Batch: 3, Loss: 0.0261\n",
            "Epoch: 75, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 76, Batch: 0, Loss: 0.0523\n",
            "Epoch: 76, Batch: 1, Loss: 0.0116\n",
            "Epoch: 76, Batch: 2, Loss: 0.0043\n",
            "Epoch: 76, Batch: 3, Loss: 0.1416\n",
            "Epoch: 76, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 77, Batch: 0, Loss: 0.0849\n",
            "Epoch: 77, Batch: 1, Loss: 0.0181\n",
            "Epoch: 77, Batch: 2, Loss: 0.0253\n",
            "Epoch: 77, Batch: 3, Loss: 0.0641\n",
            "Epoch: 77, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 78, Batch: 0, Loss: 0.1891\n",
            "Epoch: 78, Batch: 1, Loss: 0.0338\n",
            "Epoch: 78, Batch: 2, Loss: 0.0425\n",
            "Epoch: 78, Batch: 3, Loss: 0.0216\n",
            "Epoch: 78, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 79, Batch: 0, Loss: 0.0096\n",
            "Epoch: 79, Batch: 1, Loss: 0.0042\n",
            "Epoch: 79, Batch: 2, Loss: 0.0279\n",
            "Epoch: 79, Batch: 3, Loss: 0.1787\n",
            "Epoch: 79, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 80, Batch: 0, Loss: 0.0127\n",
            "Epoch: 80, Batch: 1, Loss: 0.1330\n",
            "Epoch: 80, Batch: 2, Loss: 0.0050\n",
            "Epoch: 80, Batch: 3, Loss: 0.0306\n",
            "Epoch: 80, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 81, Batch: 0, Loss: 0.0077\n",
            "Epoch: 81, Batch: 1, Loss: 0.1612\n",
            "Epoch: 81, Batch: 2, Loss: 0.0661\n",
            "Epoch: 81, Batch: 3, Loss: 0.0076\n",
            "Epoch: 81, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 82, Batch: 0, Loss: 0.0369\n",
            "Epoch: 82, Batch: 1, Loss: 0.0910\n",
            "Epoch: 82, Batch: 2, Loss: 0.0809\n",
            "Epoch: 82, Batch: 3, Loss: 0.0039\n",
            "Epoch: 82, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 83, Batch: 0, Loss: 0.0075\n",
            "Epoch: 83, Batch: 1, Loss: 0.0395\n",
            "Epoch: 83, Batch: 2, Loss: 0.0861\n",
            "Epoch: 83, Batch: 3, Loss: 0.1305\n",
            "Epoch: 83, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 84, Batch: 0, Loss: 0.0073\n",
            "Epoch: 84, Batch: 1, Loss: 0.0615\n",
            "Epoch: 84, Batch: 2, Loss: 0.0281\n",
            "Epoch: 84, Batch: 3, Loss: 0.1253\n",
            "Epoch: 84, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 85, Batch: 0, Loss: 0.0171\n",
            "Epoch: 85, Batch: 1, Loss: 0.1408\n",
            "Epoch: 85, Batch: 2, Loss: 0.0087\n",
            "Epoch: 85, Batch: 3, Loss: 0.0229\n",
            "Epoch: 85, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 86, Batch: 0, Loss: 0.0295\n",
            "Epoch: 86, Batch: 1, Loss: 0.0282\n",
            "Epoch: 86, Batch: 2, Loss: 0.0064\n",
            "Epoch: 86, Batch: 3, Loss: 0.1720\n",
            "Epoch: 86, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 87, Batch: 0, Loss: 0.1026\n",
            "Epoch: 87, Batch: 1, Loss: 0.0061\n",
            "Epoch: 87, Batch: 2, Loss: 0.0594\n",
            "Epoch: 87, Batch: 3, Loss: 0.0581\n",
            "Epoch: 87, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 88, Batch: 0, Loss: 0.0402\n",
            "Epoch: 88, Batch: 1, Loss: 0.1273\n",
            "Epoch: 88, Batch: 2, Loss: 0.0292\n",
            "Epoch: 88, Batch: 3, Loss: 0.0034\n",
            "Epoch: 88, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 89, Batch: 0, Loss: 0.1008\n",
            "Epoch: 89, Batch: 1, Loss: 0.0971\n",
            "Epoch: 89, Batch: 2, Loss: 0.0095\n",
            "Epoch: 89, Batch: 3, Loss: 0.0049\n",
            "Epoch: 89, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 90, Batch: 0, Loss: 0.0350\n",
            "Epoch: 90, Batch: 1, Loss: 0.1257\n",
            "Epoch: 90, Batch: 2, Loss: 0.0127\n",
            "Epoch: 90, Batch: 3, Loss: 0.0494\n",
            "Epoch: 90, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 91, Batch: 0, Loss: 0.0014\n",
            "Epoch: 91, Batch: 1, Loss: 0.1534\n",
            "Epoch: 91, Batch: 2, Loss: 0.0709\n",
            "Epoch: 91, Batch: 3, Loss: 0.0074\n",
            "Epoch: 91, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 92, Batch: 0, Loss: 0.1220\n",
            "Epoch: 92, Batch: 1, Loss: 0.0086\n",
            "Epoch: 92, Batch: 2, Loss: 0.0886\n",
            "Epoch: 92, Batch: 3, Loss: 0.0568\n",
            "Epoch: 92, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 93, Batch: 0, Loss: 0.0147\n",
            "Epoch: 93, Batch: 1, Loss: 0.0620\n",
            "Epoch: 93, Batch: 2, Loss: 0.0949\n",
            "Epoch: 93, Batch: 3, Loss: 0.0088\n",
            "Epoch: 93, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 94, Batch: 0, Loss: 0.1088\n",
            "Epoch: 94, Batch: 1, Loss: 0.0393\n",
            "Epoch: 94, Batch: 2, Loss: 0.0199\n",
            "Epoch: 94, Batch: 3, Loss: 0.0123\n",
            "Epoch: 94, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 95, Batch: 0, Loss: 0.0338\n",
            "Epoch: 95, Batch: 1, Loss: 0.0412\n",
            "Epoch: 95, Batch: 2, Loss: 0.1209\n",
            "Epoch: 95, Batch: 3, Loss: 0.0019\n",
            "Epoch: 95, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 96, Batch: 0, Loss: 0.0862\n",
            "Epoch: 96, Batch: 1, Loss: 0.0905\n",
            "Epoch: 96, Batch: 2, Loss: 0.0132\n",
            "Epoch: 96, Batch: 3, Loss: 0.0043\n",
            "Epoch: 96, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 97, Batch: 0, Loss: 0.0102\n",
            "Epoch: 97, Batch: 1, Loss: 0.1449\n",
            "Epoch: 97, Batch: 2, Loss: 0.0663\n",
            "Epoch: 97, Batch: 3, Loss: 0.0103\n",
            "Epoch: 97, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 98, Batch: 0, Loss: 0.0043\n",
            "Epoch: 98, Batch: 1, Loss: 0.0334\n",
            "Epoch: 98, Batch: 2, Loss: 0.0220\n",
            "Epoch: 98, Batch: 3, Loss: 0.1475\n",
            "Epoch: 98, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 99, Batch: 0, Loss: 0.0756\n",
            "Epoch: 99, Batch: 1, Loss: 0.0496\n",
            "Epoch: 99, Batch: 2, Loss: 0.1091\n",
            "Epoch: 99, Batch: 3, Loss: 0.0196\n",
            "Epoch: 99, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 100, Batch: 0, Loss: 0.0109\n",
            "Epoch: 100, Batch: 1, Loss: 0.1326\n",
            "Epoch: 100, Batch: 2, Loss: 0.0267\n",
            "Epoch: 100, Batch: 3, Loss: 0.0087\n",
            "Epoch: 100, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 101, Batch: 0, Loss: 0.0496\n",
            "Epoch: 101, Batch: 1, Loss: 0.1192\n",
            "Epoch: 101, Batch: 2, Loss: 0.0047\n",
            "Epoch: 101, Batch: 3, Loss: 0.0202\n",
            "Epoch: 101, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 102, Batch: 0, Loss: 0.0089\n",
            "Epoch: 102, Batch: 1, Loss: 0.0316\n",
            "Epoch: 102, Batch: 2, Loss: 0.0071\n",
            "Epoch: 102, Batch: 3, Loss: 0.1691\n",
            "Epoch: 102, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 103, Batch: 0, Loss: 0.0247\n",
            "Epoch: 103, Batch: 1, Loss: 0.0997\n",
            "Epoch: 103, Batch: 2, Loss: 0.0591\n",
            "Epoch: 103, Batch: 3, Loss: 0.0302\n",
            "Epoch: 103, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 104, Batch: 0, Loss: 0.0152\n",
            "Epoch: 104, Batch: 1, Loss: 0.0342\n",
            "Epoch: 104, Batch: 2, Loss: 0.1139\n",
            "Epoch: 104, Batch: 3, Loss: 0.0400\n",
            "Epoch: 104, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 105, Batch: 0, Loss: 0.0109\n",
            "Epoch: 105, Batch: 1, Loss: 0.1103\n",
            "Epoch: 105, Batch: 2, Loss: 0.0676\n",
            "Epoch: 105, Batch: 3, Loss: 0.0059\n",
            "Epoch: 105, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 106, Batch: 0, Loss: 0.0156\n",
            "Epoch: 106, Batch: 1, Loss: 0.1216\n",
            "Epoch: 106, Batch: 2, Loss: 0.0141\n",
            "Epoch: 106, Batch: 3, Loss: 0.0675\n",
            "Epoch: 106, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 107, Batch: 0, Loss: 0.1490\n",
            "Epoch: 107, Batch: 1, Loss: 0.0031\n",
            "Epoch: 107, Batch: 2, Loss: 0.0170\n",
            "Epoch: 107, Batch: 3, Loss: 0.0141\n",
            "Epoch: 107, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 108, Batch: 0, Loss: 0.0194\n",
            "Epoch: 108, Batch: 1, Loss: 0.0404\n",
            "Epoch: 108, Batch: 2, Loss: 0.1132\n",
            "Epoch: 108, Batch: 3, Loss: 0.0223\n",
            "Epoch: 108, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 109, Batch: 0, Loss: 0.1266\n",
            "Epoch: 109, Batch: 1, Loss: 0.0125\n",
            "Epoch: 109, Batch: 2, Loss: 0.0200\n",
            "Epoch: 109, Batch: 3, Loss: 0.0240\n",
            "Epoch: 109, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 110, Batch: 0, Loss: 0.0389\n",
            "Epoch: 110, Batch: 1, Loss: 0.0264\n",
            "Epoch: 110, Batch: 2, Loss: 0.0040\n",
            "Epoch: 110, Batch: 3, Loss: 0.1757\n",
            "Epoch: 110, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 111, Batch: 0, Loss: 0.0926\n",
            "Epoch: 111, Batch: 1, Loss: 0.1208\n",
            "Epoch: 111, Batch: 2, Loss: 0.0078\n",
            "Epoch: 111, Batch: 3, Loss: 0.0418\n",
            "Epoch: 111, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 112, Batch: 0, Loss: 0.0282\n",
            "Epoch: 112, Batch: 1, Loss: 0.1001\n",
            "Epoch: 112, Batch: 2, Loss: 0.0282\n",
            "Epoch: 112, Batch: 3, Loss: 0.0403\n",
            "Epoch: 112, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 113, Batch: 0, Loss: 0.1229\n",
            "Epoch: 113, Batch: 1, Loss: 0.0260\n",
            "Epoch: 113, Batch: 2, Loss: 0.0256\n",
            "Epoch: 113, Batch: 3, Loss: 0.0266\n",
            "Epoch: 113, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 114, Batch: 0, Loss: 0.0149\n",
            "Epoch: 114, Batch: 1, Loss: 0.0280\n",
            "Epoch: 114, Batch: 2, Loss: 0.1059\n",
            "Epoch: 114, Batch: 3, Loss: 0.0494\n",
            "Epoch: 114, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 115, Batch: 0, Loss: 0.0134\n",
            "Epoch: 115, Batch: 1, Loss: 0.1281\n",
            "Epoch: 115, Batch: 2, Loss: 0.0268\n",
            "Epoch: 115, Batch: 3, Loss: 0.0530\n",
            "Epoch: 115, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 116, Batch: 0, Loss: 0.1159\n",
            "Epoch: 116, Batch: 1, Loss: 0.0562\n",
            "Epoch: 116, Batch: 2, Loss: 0.0373\n",
            "Epoch: 116, Batch: 3, Loss: 0.0199\n",
            "Epoch: 116, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 117, Batch: 0, Loss: 0.0256\n",
            "Epoch: 117, Batch: 1, Loss: 0.0347\n",
            "Epoch: 117, Batch: 2, Loss: 0.1297\n",
            "Epoch: 117, Batch: 3, Loss: 0.0104\n",
            "Epoch: 117, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 118, Batch: 0, Loss: 0.0822\n",
            "Epoch: 118, Batch: 1, Loss: 0.1271\n",
            "Epoch: 118, Batch: 2, Loss: 0.0099\n",
            "Epoch: 118, Batch: 3, Loss: 0.0213\n",
            "Epoch: 118, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 119, Batch: 0, Loss: 0.0890\n",
            "Epoch: 119, Batch: 1, Loss: 0.0604\n",
            "Epoch: 119, Batch: 2, Loss: 0.0089\n",
            "Epoch: 119, Batch: 3, Loss: 0.0437\n",
            "Epoch: 119, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 120, Batch: 0, Loss: 0.0142\n",
            "Epoch: 120, Batch: 1, Loss: 0.1741\n",
            "Epoch: 120, Batch: 2, Loss: 0.0157\n",
            "Epoch: 120, Batch: 3, Loss: 0.0122\n",
            "Epoch: 120, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 121, Batch: 0, Loss: 0.0043\n",
            "Epoch: 121, Batch: 1, Loss: 0.0472\n",
            "Epoch: 121, Batch: 2, Loss: 0.0114\n",
            "Epoch: 121, Batch: 3, Loss: 0.1798\n",
            "Epoch: 121, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 122, Batch: 0, Loss: 0.0593\n",
            "Epoch: 122, Batch: 1, Loss: 0.0138\n",
            "Epoch: 122, Batch: 2, Loss: 0.0080\n",
            "Epoch: 122, Batch: 3, Loss: 0.1437\n",
            "Epoch: 122, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 123, Batch: 0, Loss: 0.0597\n",
            "Epoch: 123, Batch: 1, Loss: 0.1212\n",
            "Epoch: 123, Batch: 2, Loss: 0.0158\n",
            "Epoch: 123, Batch: 3, Loss: 0.0358\n",
            "Epoch: 123, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 124, Batch: 0, Loss: 0.1045\n",
            "Epoch: 124, Batch: 1, Loss: 0.0223\n",
            "Epoch: 124, Batch: 2, Loss: 0.0331\n",
            "Epoch: 124, Batch: 3, Loss: 0.0447\n",
            "Epoch: 124, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 125, Batch: 0, Loss: 0.1258\n",
            "Epoch: 125, Batch: 1, Loss: 0.0183\n",
            "Epoch: 125, Batch: 2, Loss: 0.0096\n",
            "Epoch: 125, Batch: 3, Loss: 0.0382\n",
            "Epoch: 125, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 126, Batch: 0, Loss: 0.0256\n",
            "Epoch: 126, Batch: 1, Loss: 0.0289\n",
            "Epoch: 126, Batch: 2, Loss: 0.0085\n",
            "Epoch: 126, Batch: 3, Loss: 0.1455\n",
            "Epoch: 126, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 127, Batch: 0, Loss: 0.0382\n",
            "Epoch: 127, Batch: 1, Loss: 0.1197\n",
            "Epoch: 127, Batch: 2, Loss: 0.0112\n",
            "Epoch: 127, Batch: 3, Loss: 0.0180\n",
            "Epoch: 127, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 128, Batch: 0, Loss: 0.0372\n",
            "Epoch: 128, Batch: 1, Loss: 0.0194\n",
            "Epoch: 128, Batch: 2, Loss: 0.1110\n",
            "Epoch: 128, Batch: 3, Loss: 0.0132\n",
            "Epoch: 128, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 129, Batch: 0, Loss: 0.0193\n",
            "Epoch: 129, Batch: 1, Loss: 0.0044\n",
            "Epoch: 129, Batch: 2, Loss: 0.0388\n",
            "Epoch: 129, Batch: 3, Loss: 0.1530\n",
            "Epoch: 129, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 130, Batch: 0, Loss: 0.0321\n",
            "Epoch: 130, Batch: 1, Loss: 0.0580\n",
            "Epoch: 130, Batch: 2, Loss: 0.0287\n",
            "Epoch: 130, Batch: 3, Loss: 0.1377\n",
            "Epoch: 130, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 131, Batch: 0, Loss: 0.1564\n",
            "Epoch: 131, Batch: 1, Loss: 0.0070\n",
            "Epoch: 131, Batch: 2, Loss: 0.0211\n",
            "Epoch: 131, Batch: 3, Loss: 0.0066\n",
            "Epoch: 131, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 132, Batch: 0, Loss: 0.0163\n",
            "Epoch: 132, Batch: 1, Loss: 0.1070\n",
            "Epoch: 132, Batch: 2, Loss: 0.0577\n",
            "Epoch: 132, Batch: 3, Loss: 0.0302\n",
            "Epoch: 132, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 133, Batch: 0, Loss: 0.0375\n",
            "Epoch: 133, Batch: 1, Loss: 0.0273\n",
            "Epoch: 133, Batch: 2, Loss: 0.1005\n",
            "Epoch: 133, Batch: 3, Loss: 0.0340\n",
            "Epoch: 133, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 134, Batch: 0, Loss: 0.0174\n",
            "Epoch: 134, Batch: 1, Loss: 0.1107\n",
            "Epoch: 134, Batch: 2, Loss: 0.0048\n",
            "Epoch: 134, Batch: 3, Loss: 0.0596\n",
            "Epoch: 134, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 135, Batch: 0, Loss: 0.0143\n",
            "Epoch: 135, Batch: 1, Loss: 0.0302\n",
            "Epoch: 135, Batch: 2, Loss: 0.1101\n",
            "Epoch: 135, Batch: 3, Loss: 0.0422\n",
            "Epoch: 135, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 136, Batch: 0, Loss: 0.0150\n",
            "Epoch: 136, Batch: 1, Loss: 0.1244\n",
            "Epoch: 136, Batch: 2, Loss: 0.0416\n",
            "Epoch: 136, Batch: 3, Loss: 0.0085\n",
            "Epoch: 136, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 137, Batch: 0, Loss: 0.1056\n",
            "Epoch: 137, Batch: 1, Loss: 0.0371\n",
            "Epoch: 137, Batch: 2, Loss: 0.0536\n",
            "Epoch: 137, Batch: 3, Loss: 0.0031\n",
            "Epoch: 137, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 138, Batch: 0, Loss: 0.1108\n",
            "Epoch: 138, Batch: 1, Loss: 0.0215\n",
            "Epoch: 138, Batch: 2, Loss: 0.0268\n",
            "Epoch: 138, Batch: 3, Loss: 0.0289\n",
            "Epoch: 138, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 139, Batch: 0, Loss: 0.0449\n",
            "Epoch: 139, Batch: 1, Loss: 0.0193\n",
            "Epoch: 139, Batch: 2, Loss: 0.1226\n",
            "Epoch: 139, Batch: 3, Loss: 0.0149\n",
            "Epoch: 139, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 140, Batch: 0, Loss: 0.1002\n",
            "Epoch: 140, Batch: 1, Loss: 0.0201\n",
            "Epoch: 140, Batch: 2, Loss: 0.0654\n",
            "Epoch: 140, Batch: 3, Loss: 0.0052\n",
            "Epoch: 140, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 141, Batch: 0, Loss: 0.0084\n",
            "Epoch: 141, Batch: 1, Loss: 0.0315\n",
            "Epoch: 141, Batch: 2, Loss: 0.1220\n",
            "Epoch: 141, Batch: 3, Loss: 0.0910\n",
            "Epoch: 141, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 142, Batch: 0, Loss: 0.0146\n",
            "Epoch: 142, Batch: 1, Loss: 0.0154\n",
            "Epoch: 142, Batch: 2, Loss: 0.0649\n",
            "Epoch: 142, Batch: 3, Loss: 0.1165\n",
            "Epoch: 142, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 143, Batch: 0, Loss: 0.0854\n",
            "Epoch: 143, Batch: 1, Loss: 0.0059\n",
            "Epoch: 143, Batch: 2, Loss: 0.0256\n",
            "Epoch: 143, Batch: 3, Loss: 0.0788\n",
            "Epoch: 143, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 144, Batch: 0, Loss: 0.1292\n",
            "Epoch: 144, Batch: 1, Loss: 0.0109\n",
            "Epoch: 144, Batch: 2, Loss: 0.0126\n",
            "Epoch: 144, Batch: 3, Loss: 0.0691\n",
            "Epoch: 144, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 145, Batch: 0, Loss: 0.1337\n",
            "Epoch: 145, Batch: 1, Loss: 0.0097\n",
            "Epoch: 145, Batch: 2, Loss: 0.0377\n",
            "Epoch: 145, Batch: 3, Loss: 0.0431\n",
            "Epoch: 145, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 146, Batch: 0, Loss: 0.0085\n",
            "Epoch: 146, Batch: 1, Loss: 0.0267\n",
            "Epoch: 146, Batch: 2, Loss: 0.1263\n",
            "Epoch: 146, Batch: 3, Loss: 0.0174\n",
            "Epoch: 146, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 147, Batch: 0, Loss: 0.0065\n",
            "Epoch: 147, Batch: 1, Loss: 0.1125\n",
            "Epoch: 147, Batch: 2, Loss: 0.1376\n",
            "Epoch: 147, Batch: 3, Loss: 0.0059\n",
            "Epoch: 147, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 148, Batch: 0, Loss: 0.0409\n",
            "Epoch: 148, Batch: 1, Loss: 0.0142\n",
            "Epoch: 148, Batch: 2, Loss: 0.0014\n",
            "Epoch: 148, Batch: 3, Loss: 0.1665\n",
            "Epoch: 148, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 149, Batch: 0, Loss: 0.0354\n",
            "Epoch: 149, Batch: 1, Loss: 0.0143\n",
            "Epoch: 149, Batch: 2, Loss: 0.1018\n",
            "Epoch: 149, Batch: 3, Loss: 0.0738\n",
            "Epoch: 149, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 150, Batch: 0, Loss: 0.1378\n",
            "Epoch: 150, Batch: 1, Loss: 0.0236\n",
            "Epoch: 150, Batch: 2, Loss: 0.0059\n",
            "Epoch: 150, Batch: 3, Loss: 0.0628\n",
            "Epoch: 150, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 151, Batch: 0, Loss: 0.1374\n",
            "Epoch: 151, Batch: 1, Loss: 0.0109\n",
            "Epoch: 151, Batch: 2, Loss: 0.0322\n",
            "Epoch: 151, Batch: 3, Loss: 0.0242\n",
            "Epoch: 151, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 152, Batch: 0, Loss: 0.0374\n",
            "Epoch: 152, Batch: 1, Loss: 0.0301\n",
            "Epoch: 152, Batch: 2, Loss: 0.0097\n",
            "Epoch: 152, Batch: 3, Loss: 0.1518\n",
            "Epoch: 152, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 153, Batch: 0, Loss: 0.0419\n",
            "Epoch: 153, Batch: 1, Loss: 0.0903\n",
            "Epoch: 153, Batch: 2, Loss: 0.0020\n",
            "Epoch: 153, Batch: 3, Loss: 0.1117\n",
            "Epoch: 153, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 154, Batch: 0, Loss: 0.0450\n",
            "Epoch: 154, Batch: 1, Loss: 0.0217\n",
            "Epoch: 154, Batch: 2, Loss: 0.1196\n",
            "Epoch: 154, Batch: 3, Loss: 0.0542\n",
            "Epoch: 154, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 155, Batch: 0, Loss: 0.1251\n",
            "Epoch: 155, Batch: 1, Loss: 0.0049\n",
            "Epoch: 155, Batch: 2, Loss: 0.0305\n",
            "Epoch: 155, Batch: 3, Loss: 0.0361\n",
            "Epoch: 155, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 156, Batch: 0, Loss: 0.0066\n",
            "Epoch: 156, Batch: 1, Loss: 0.1498\n",
            "Epoch: 156, Batch: 2, Loss: 0.0187\n",
            "Epoch: 156, Batch: 3, Loss: 0.0012\n",
            "Epoch: 156, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 157, Batch: 0, Loss: 0.0295\n",
            "Epoch: 157, Batch: 1, Loss: 0.1242\n",
            "Epoch: 157, Batch: 2, Loss: 0.0201\n",
            "Epoch: 157, Batch: 3, Loss: 0.0171\n",
            "Epoch: 157, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 158, Batch: 0, Loss: 0.0311\n",
            "Epoch: 158, Batch: 1, Loss: 0.1032\n",
            "Epoch: 158, Batch: 2, Loss: 0.0311\n",
            "Epoch: 158, Batch: 3, Loss: 0.0486\n",
            "Epoch: 158, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 159, Batch: 0, Loss: 0.0472\n",
            "Epoch: 159, Batch: 1, Loss: 0.0281\n",
            "Epoch: 159, Batch: 2, Loss: 0.1237\n",
            "Epoch: 159, Batch: 3, Loss: 0.0038\n",
            "Epoch: 159, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 160, Batch: 0, Loss: 0.0354\n",
            "Epoch: 160, Batch: 1, Loss: 0.1206\n",
            "Epoch: 160, Batch: 2, Loss: 0.0123\n",
            "Epoch: 160, Batch: 3, Loss: 0.0382\n",
            "Epoch: 160, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 161, Batch: 0, Loss: 0.0152\n",
            "Epoch: 161, Batch: 1, Loss: 0.1702\n",
            "Epoch: 161, Batch: 2, Loss: 0.0024\n",
            "Epoch: 161, Batch: 3, Loss: 0.0306\n",
            "Epoch: 161, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 162, Batch: 0, Loss: 0.0384\n",
            "Epoch: 162, Batch: 1, Loss: 0.0079\n",
            "Epoch: 162, Batch: 2, Loss: 0.1084\n",
            "Epoch: 162, Batch: 3, Loss: 0.0364\n",
            "Epoch: 162, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 163, Batch: 0, Loss: 0.0372\n",
            "Epoch: 163, Batch: 1, Loss: 0.0048\n",
            "Epoch: 163, Batch: 2, Loss: 0.1391\n",
            "Epoch: 163, Batch: 3, Loss: 0.0016\n",
            "Epoch: 163, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 164, Batch: 0, Loss: 0.0765\n",
            "Epoch: 164, Batch: 1, Loss: 0.0046\n",
            "Epoch: 164, Batch: 2, Loss: 0.0130\n",
            "Epoch: 164, Batch: 3, Loss: 0.1394\n",
            "Epoch: 164, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 165, Batch: 0, Loss: 0.0507\n",
            "Epoch: 165, Batch: 1, Loss: 0.1393\n",
            "Epoch: 165, Batch: 2, Loss: 0.0081\n",
            "Epoch: 165, Batch: 3, Loss: 0.0130\n",
            "Epoch: 165, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 166, Batch: 0, Loss: 0.0287\n",
            "Epoch: 166, Batch: 1, Loss: 0.0189\n",
            "Epoch: 166, Batch: 2, Loss: 0.0166\n",
            "Epoch: 166, Batch: 3, Loss: 0.2287\n",
            "Epoch: 166, Training Accuracy: 94.21%, Validation Accuracy: 92.86%\n",
            "Epoch: 167, Batch: 0, Loss: 0.0736\n",
            "Epoch: 167, Batch: 1, Loss: 0.0235\n",
            "Epoch: 167, Batch: 2, Loss: 0.0475\n",
            "Epoch: 167, Batch: 3, Loss: 0.1355\n",
            "Epoch: 167, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 168, Batch: 0, Loss: 0.0232\n",
            "Epoch: 168, Batch: 1, Loss: 0.1100\n",
            "Epoch: 168, Batch: 2, Loss: 0.0465\n",
            "Epoch: 168, Batch: 3, Loss: 0.0474\n",
            "Epoch: 168, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 169, Batch: 0, Loss: 0.0437\n",
            "Epoch: 169, Batch: 1, Loss: 0.0203\n",
            "Epoch: 169, Batch: 2, Loss: 0.0894\n",
            "Epoch: 169, Batch: 3, Loss: 0.0889\n",
            "Epoch: 169, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 170, Batch: 0, Loss: 0.1576\n",
            "Epoch: 170, Batch: 1, Loss: 0.0118\n",
            "Epoch: 170, Batch: 2, Loss: 0.0340\n",
            "Epoch: 170, Batch: 3, Loss: 0.0355\n",
            "Epoch: 170, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 171, Batch: 0, Loss: 0.0110\n",
            "Epoch: 171, Batch: 1, Loss: 0.0040\n",
            "Epoch: 171, Batch: 2, Loss: 0.1714\n",
            "Epoch: 171, Batch: 3, Loss: 0.0887\n",
            "Epoch: 171, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 172, Batch: 0, Loss: 0.0323\n",
            "Epoch: 172, Batch: 1, Loss: 0.1097\n",
            "Epoch: 172, Batch: 2, Loss: 0.0176\n",
            "Epoch: 172, Batch: 3, Loss: 0.0524\n",
            "Epoch: 172, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 173, Batch: 0, Loss: 0.0077\n",
            "Epoch: 173, Batch: 1, Loss: 0.1277\n",
            "Epoch: 173, Batch: 2, Loss: 0.0300\n",
            "Epoch: 173, Batch: 3, Loss: 0.0440\n",
            "Epoch: 173, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 174, Batch: 0, Loss: 0.0133\n",
            "Epoch: 174, Batch: 1, Loss: 0.0321\n",
            "Epoch: 174, Batch: 2, Loss: 0.1319\n",
            "Epoch: 174, Batch: 3, Loss: 0.0054\n",
            "Epoch: 174, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 175, Batch: 0, Loss: 0.0219\n",
            "Epoch: 175, Batch: 1, Loss: 0.1261\n",
            "Epoch: 175, Batch: 2, Loss: 0.0119\n",
            "Epoch: 175, Batch: 3, Loss: 0.0255\n",
            "Epoch: 175, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 176, Batch: 0, Loss: 0.0192\n",
            "Epoch: 176, Batch: 1, Loss: 0.0397\n",
            "Epoch: 176, Batch: 2, Loss: 0.1002\n",
            "Epoch: 176, Batch: 3, Loss: 0.0445\n",
            "Epoch: 176, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 177, Batch: 0, Loss: 0.0255\n",
            "Epoch: 177, Batch: 1, Loss: 0.1281\n",
            "Epoch: 177, Batch: 2, Loss: 0.0114\n",
            "Epoch: 177, Batch: 3, Loss: 0.0206\n",
            "Epoch: 177, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 178, Batch: 0, Loss: 0.0333\n",
            "Epoch: 178, Batch: 1, Loss: 0.1109\n",
            "Epoch: 178, Batch: 2, Loss: 0.0326\n",
            "Epoch: 178, Batch: 3, Loss: 0.0445\n",
            "Epoch: 178, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 179, Batch: 0, Loss: 0.0167\n",
            "Epoch: 179, Batch: 1, Loss: 0.0396\n",
            "Epoch: 179, Batch: 2, Loss: 0.0980\n",
            "Epoch: 179, Batch: 3, Loss: 0.0551\n",
            "Epoch: 179, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 180, Batch: 0, Loss: 0.0198\n",
            "Epoch: 180, Batch: 1, Loss: 0.0261\n",
            "Epoch: 180, Batch: 2, Loss: 0.1238\n",
            "Epoch: 180, Batch: 3, Loss: 0.0150\n",
            "Epoch: 180, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 181, Batch: 0, Loss: 0.0087\n",
            "Epoch: 181, Batch: 1, Loss: 0.0447\n",
            "Epoch: 181, Batch: 2, Loss: 0.1467\n",
            "Epoch: 181, Batch: 3, Loss: 0.0148\n",
            "Epoch: 181, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 182, Batch: 0, Loss: 0.1111\n",
            "Epoch: 182, Batch: 1, Loss: 0.0646\n",
            "Epoch: 182, Batch: 2, Loss: 0.0232\n",
            "Epoch: 182, Batch: 3, Loss: 0.0103\n",
            "Epoch: 182, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 183, Batch: 0, Loss: 0.0055\n",
            "Epoch: 183, Batch: 1, Loss: 0.0209\n",
            "Epoch: 183, Batch: 2, Loss: 0.1822\n",
            "Epoch: 183, Batch: 3, Loss: 0.0101\n",
            "Epoch: 183, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 184, Batch: 0, Loss: 0.0805\n",
            "Epoch: 184, Batch: 1, Loss: 0.0054\n",
            "Epoch: 184, Batch: 2, Loss: 0.1176\n",
            "Epoch: 184, Batch: 3, Loss: 0.0128\n",
            "Epoch: 184, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 185, Batch: 0, Loss: 0.0286\n",
            "Epoch: 185, Batch: 1, Loss: 0.1297\n",
            "Epoch: 185, Batch: 2, Loss: 0.0708\n",
            "Epoch: 185, Batch: 3, Loss: 0.0046\n",
            "Epoch: 185, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 186, Batch: 0, Loss: 0.0214\n",
            "Epoch: 186, Batch: 1, Loss: 0.0086\n",
            "Epoch: 186, Batch: 2, Loss: 0.0474\n",
            "Epoch: 186, Batch: 3, Loss: 0.1351\n",
            "Epoch: 186, Training Accuracy: 96.69%, Validation Accuracy: 92.86%\n",
            "Epoch: 187, Batch: 0, Loss: 0.0734\n",
            "Epoch: 187, Batch: 1, Loss: 0.0214\n",
            "Epoch: 187, Batch: 2, Loss: 0.0330\n",
            "Epoch: 187, Batch: 3, Loss: 0.1407\n",
            "Epoch: 187, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 188, Batch: 0, Loss: 0.0418\n",
            "Epoch: 188, Batch: 1, Loss: 0.0084\n",
            "Epoch: 188, Batch: 2, Loss: 0.1354\n",
            "Epoch: 188, Batch: 3, Loss: 0.0196\n",
            "Epoch: 188, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 189, Batch: 0, Loss: 0.1041\n",
            "Epoch: 189, Batch: 1, Loss: 0.0671\n",
            "Epoch: 189, Batch: 2, Loss: 0.0081\n",
            "Epoch: 189, Batch: 3, Loss: 0.0101\n",
            "Epoch: 189, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 190, Batch: 0, Loss: 0.0133\n",
            "Epoch: 190, Batch: 1, Loss: 0.0045\n",
            "Epoch: 190, Batch: 2, Loss: 0.0373\n",
            "Epoch: 190, Batch: 3, Loss: 0.1734\n",
            "Epoch: 190, Training Accuracy: 97.52%, Validation Accuracy: 92.86%\n",
            "Epoch: 191, Batch: 0, Loss: 0.0767\n",
            "Epoch: 191, Batch: 1, Loss: 0.0043\n",
            "Epoch: 191, Batch: 2, Loss: 0.1172\n",
            "Epoch: 191, Batch: 3, Loss: 0.0256\n",
            "Epoch: 191, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 192, Batch: 0, Loss: 0.0024\n",
            "Epoch: 192, Batch: 1, Loss: 0.0255\n",
            "Epoch: 192, Batch: 2, Loss: 0.1394\n",
            "Epoch: 192, Batch: 3, Loss: 0.0152\n",
            "Epoch: 192, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 193, Batch: 0, Loss: 0.0249\n",
            "Epoch: 193, Batch: 1, Loss: 0.0347\n",
            "Epoch: 193, Batch: 2, Loss: 0.1067\n",
            "Epoch: 193, Batch: 3, Loss: 0.0195\n",
            "Epoch: 193, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 194, Batch: 0, Loss: 0.0811\n",
            "Epoch: 194, Batch: 1, Loss: 0.0370\n",
            "Epoch: 194, Batch: 2, Loss: 0.0273\n",
            "Epoch: 194, Batch: 3, Loss: 0.0576\n",
            "Epoch: 194, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 195, Batch: 0, Loss: 0.0125\n",
            "Epoch: 195, Batch: 1, Loss: 0.1279\n",
            "Epoch: 195, Batch: 2, Loss: 0.0255\n",
            "Epoch: 195, Batch: 3, Loss: 0.0458\n",
            "Epoch: 195, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 196, Batch: 0, Loss: 0.0023\n",
            "Epoch: 196, Batch: 1, Loss: 0.0622\n",
            "Epoch: 196, Batch: 2, Loss: 0.1052\n",
            "Epoch: 196, Batch: 3, Loss: 0.0165\n",
            "Epoch: 196, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 197, Batch: 0, Loss: 0.0159\n",
            "Epoch: 197, Batch: 1, Loss: 0.1130\n",
            "Epoch: 197, Batch: 2, Loss: 0.0816\n",
            "Epoch: 197, Batch: 3, Loss: 0.0400\n",
            "Epoch: 197, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 198, Batch: 0, Loss: 0.1157\n",
            "Epoch: 198, Batch: 1, Loss: 0.0122\n",
            "Epoch: 198, Batch: 2, Loss: 0.0285\n",
            "Epoch: 198, Batch: 3, Loss: 0.0443\n",
            "Epoch: 198, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 199, Batch: 0, Loss: 0.0299\n",
            "Epoch: 199, Batch: 1, Loss: 0.1140\n",
            "Epoch: 199, Batch: 2, Loss: 0.0433\n",
            "Epoch: 199, Batch: 3, Loss: 0.0132\n",
            "Epoch: 199, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 200, Batch: 0, Loss: 0.1144\n",
            "Epoch: 200, Batch: 1, Loss: 0.0178\n",
            "Epoch: 200, Batch: 2, Loss: 0.0259\n",
            "Epoch: 200, Batch: 3, Loss: 0.0578\n",
            "Epoch: 200, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 201, Batch: 0, Loss: 0.0355\n",
            "Epoch: 201, Batch: 1, Loss: 0.0182\n",
            "Epoch: 201, Batch: 2, Loss: 0.1032\n",
            "Epoch: 201, Batch: 3, Loss: 0.0519\n",
            "Epoch: 201, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 202, Batch: 0, Loss: 0.0023\n",
            "Epoch: 202, Batch: 1, Loss: 0.1038\n",
            "Epoch: 202, Batch: 2, Loss: 0.0396\n",
            "Epoch: 202, Batch: 3, Loss: 0.0500\n",
            "Epoch: 202, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 203, Batch: 0, Loss: 0.0705\n",
            "Epoch: 203, Batch: 1, Loss: 0.0360\n",
            "Epoch: 203, Batch: 2, Loss: 0.1149\n",
            "Epoch: 203, Batch: 3, Loss: 0.0201\n",
            "Epoch: 203, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 204, Batch: 0, Loss: 0.0434\n",
            "Epoch: 204, Batch: 1, Loss: 0.0872\n",
            "Epoch: 204, Batch: 2, Loss: 0.0412\n",
            "Epoch: 204, Batch: 3, Loss: 0.0318\n",
            "Epoch: 204, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 205, Batch: 0, Loss: 0.0157\n",
            "Epoch: 205, Batch: 1, Loss: 0.1637\n",
            "Epoch: 205, Batch: 2, Loss: 0.0058\n",
            "Epoch: 205, Batch: 3, Loss: 0.0482\n",
            "Epoch: 205, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 206, Batch: 0, Loss: 0.1393\n",
            "Epoch: 206, Batch: 1, Loss: 0.0269\n",
            "Epoch: 206, Batch: 2, Loss: 0.0194\n",
            "Epoch: 206, Batch: 3, Loss: 0.0038\n",
            "Epoch: 206, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 207, Batch: 0, Loss: 0.0190\n",
            "Epoch: 207, Batch: 1, Loss: 0.1079\n",
            "Epoch: 207, Batch: 2, Loss: 0.0524\n",
            "Epoch: 207, Batch: 3, Loss: 0.0029\n",
            "Epoch: 207, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 208, Batch: 0, Loss: 0.0418\n",
            "Epoch: 208, Batch: 1, Loss: 0.0302\n",
            "Epoch: 208, Batch: 2, Loss: 0.1039\n",
            "Epoch: 208, Batch: 3, Loss: 0.0105\n",
            "Epoch: 208, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 209, Batch: 0, Loss: 0.0174\n",
            "Epoch: 209, Batch: 1, Loss: 0.0493\n",
            "Epoch: 209, Batch: 2, Loss: 0.1450\n",
            "Epoch: 209, Batch: 3, Loss: 0.0250\n",
            "Epoch: 209, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 210, Batch: 0, Loss: 0.0216\n",
            "Epoch: 210, Batch: 1, Loss: 0.1109\n",
            "Epoch: 210, Batch: 2, Loss: 0.0441\n",
            "Epoch: 210, Batch: 3, Loss: 0.0243\n",
            "Epoch: 210, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 211, Batch: 0, Loss: 0.0352\n",
            "Epoch: 211, Batch: 1, Loss: 0.0064\n",
            "Epoch: 211, Batch: 2, Loss: 0.1107\n",
            "Epoch: 211, Batch: 3, Loss: 0.0581\n",
            "Epoch: 211, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 212, Batch: 0, Loss: 0.1126\n",
            "Epoch: 212, Batch: 1, Loss: 0.0174\n",
            "Epoch: 212, Batch: 2, Loss: 0.0301\n",
            "Epoch: 212, Batch: 3, Loss: 0.0502\n",
            "Epoch: 212, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 213, Batch: 0, Loss: 0.0368\n",
            "Epoch: 213, Batch: 1, Loss: 0.0226\n",
            "Epoch: 213, Batch: 2, Loss: 0.1661\n",
            "Epoch: 213, Batch: 3, Loss: 0.0031\n",
            "Epoch: 213, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 214, Batch: 0, Loss: 0.1387\n",
            "Epoch: 214, Batch: 1, Loss: 0.0179\n",
            "Epoch: 214, Batch: 2, Loss: 0.0205\n",
            "Epoch: 214, Batch: 3, Loss: 0.0206\n",
            "Epoch: 214, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 215, Batch: 0, Loss: 0.0056\n",
            "Epoch: 215, Batch: 1, Loss: 0.0126\n",
            "Epoch: 215, Batch: 2, Loss: 0.0375\n",
            "Epoch: 215, Batch: 3, Loss: 0.1672\n",
            "Epoch: 215, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 216, Batch: 0, Loss: 0.0468\n",
            "Epoch: 216, Batch: 1, Loss: 0.0256\n",
            "Epoch: 216, Batch: 2, Loss: 0.1106\n",
            "Epoch: 216, Batch: 3, Loss: 0.0132\n",
            "Epoch: 216, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 217, Batch: 0, Loss: 0.0431\n",
            "Epoch: 217, Batch: 1, Loss: 0.0086\n",
            "Epoch: 217, Batch: 2, Loss: 0.1123\n",
            "Epoch: 217, Batch: 3, Loss: 0.0859\n",
            "Epoch: 217, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 218, Batch: 0, Loss: 0.0513\n",
            "Epoch: 218, Batch: 1, Loss: 0.1358\n",
            "Epoch: 218, Batch: 2, Loss: 0.0142\n",
            "Epoch: 218, Batch: 3, Loss: 0.0112\n",
            "Epoch: 218, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 219, Batch: 0, Loss: 0.0111\n",
            "Epoch: 219, Batch: 1, Loss: 0.1198\n",
            "Epoch: 219, Batch: 2, Loss: 0.0639\n",
            "Epoch: 219, Batch: 3, Loss: 0.0095\n",
            "Epoch: 219, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 220, Batch: 0, Loss: 0.0142\n",
            "Epoch: 220, Batch: 1, Loss: 0.0209\n",
            "Epoch: 220, Batch: 2, Loss: 0.1489\n",
            "Epoch: 220, Batch: 3, Loss: 0.0224\n",
            "Epoch: 220, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 221, Batch: 0, Loss: 0.0120\n",
            "Epoch: 221, Batch: 1, Loss: 0.0845\n",
            "Epoch: 221, Batch: 2, Loss: 0.1056\n",
            "Epoch: 221, Batch: 3, Loss: 0.0157\n",
            "Epoch: 221, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 222, Batch: 0, Loss: 0.1328\n",
            "Epoch: 222, Batch: 1, Loss: 0.0208\n",
            "Epoch: 222, Batch: 2, Loss: 0.0093\n",
            "Epoch: 222, Batch: 3, Loss: 0.0241\n",
            "Epoch: 222, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 223, Batch: 0, Loss: 0.0928\n",
            "Epoch: 223, Batch: 1, Loss: 0.0487\n",
            "Epoch: 223, Batch: 2, Loss: 0.0297\n",
            "Epoch: 223, Batch: 3, Loss: 0.0259\n",
            "Epoch: 223, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 224, Batch: 0, Loss: 0.0490\n",
            "Epoch: 224, Batch: 1, Loss: 0.0120\n",
            "Epoch: 224, Batch: 2, Loss: 0.0220\n",
            "Epoch: 224, Batch: 3, Loss: 0.1274\n",
            "Epoch: 224, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 225, Batch: 0, Loss: 0.0064\n",
            "Epoch: 225, Batch: 1, Loss: 0.0465\n",
            "Epoch: 225, Batch: 2, Loss: 0.1261\n",
            "Epoch: 225, Batch: 3, Loss: 0.0759\n",
            "Epoch: 225, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 226, Batch: 0, Loss: 0.0028\n",
            "Epoch: 226, Batch: 1, Loss: 0.1198\n",
            "Epoch: 226, Batch: 2, Loss: 0.0549\n",
            "Epoch: 226, Batch: 3, Loss: 0.0152\n",
            "Epoch: 226, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 227, Batch: 0, Loss: 0.0504\n",
            "Epoch: 227, Batch: 1, Loss: 0.0091\n",
            "Epoch: 227, Batch: 2, Loss: 0.0031\n",
            "Epoch: 227, Batch: 3, Loss: 0.1758\n",
            "Epoch: 227, Training Accuracy: 97.52%, Validation Accuracy: 92.86%\n",
            "Epoch: 228, Batch: 0, Loss: 0.0094\n",
            "Epoch: 228, Batch: 1, Loss: 0.0365\n",
            "Epoch: 228, Batch: 2, Loss: 0.0843\n",
            "Epoch: 228, Batch: 3, Loss: 0.1445\n",
            "Epoch: 228, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 229, Batch: 0, Loss: 0.0514\n",
            "Epoch: 229, Batch: 1, Loss: 0.1250\n",
            "Epoch: 229, Batch: 2, Loss: 0.0492\n",
            "Epoch: 229, Batch: 3, Loss: 0.0075\n",
            "Epoch: 229, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 230, Batch: 0, Loss: 0.1462\n",
            "Epoch: 230, Batch: 1, Loss: 0.1056\n",
            "Epoch: 230, Batch: 2, Loss: 0.0072\n",
            "Epoch: 230, Batch: 3, Loss: 0.0103\n",
            "Epoch: 230, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 231, Batch: 0, Loss: 0.0252\n",
            "Epoch: 231, Batch: 1, Loss: 0.0188\n",
            "Epoch: 231, Batch: 2, Loss: 0.1395\n",
            "Epoch: 231, Batch: 3, Loss: 0.0120\n",
            "Epoch: 231, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 232, Batch: 0, Loss: 0.0859\n",
            "Epoch: 232, Batch: 1, Loss: 0.1250\n",
            "Epoch: 232, Batch: 2, Loss: 0.0135\n",
            "Epoch: 232, Batch: 3, Loss: 0.0206\n",
            "Epoch: 232, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 233, Batch: 0, Loss: 0.0242\n",
            "Epoch: 233, Batch: 1, Loss: 0.0385\n",
            "Epoch: 233, Batch: 2, Loss: 0.1240\n",
            "Epoch: 233, Batch: 3, Loss: 0.0028\n",
            "Epoch: 233, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 234, Batch: 0, Loss: 0.0601\n",
            "Epoch: 234, Batch: 1, Loss: 0.0245\n",
            "Epoch: 234, Batch: 2, Loss: 0.1222\n",
            "Epoch: 234, Batch: 3, Loss: 0.0108\n",
            "Epoch: 234, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 235, Batch: 0, Loss: 0.0313\n",
            "Epoch: 235, Batch: 1, Loss: 0.1060\n",
            "Epoch: 235, Batch: 2, Loss: 0.0748\n",
            "Epoch: 235, Batch: 3, Loss: 0.0059\n",
            "Epoch: 235, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 236, Batch: 0, Loss: 0.0179\n",
            "Epoch: 236, Batch: 1, Loss: 0.0036\n",
            "Epoch: 236, Batch: 2, Loss: 0.1574\n",
            "Epoch: 236, Batch: 3, Loss: 0.0178\n",
            "Epoch: 236, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 237, Batch: 0, Loss: 0.0173\n",
            "Epoch: 237, Batch: 1, Loss: 0.1268\n",
            "Epoch: 237, Batch: 2, Loss: 0.0199\n",
            "Epoch: 237, Batch: 3, Loss: 0.0203\n",
            "Epoch: 237, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 238, Batch: 0, Loss: 0.0144\n",
            "Epoch: 238, Batch: 1, Loss: 0.0034\n",
            "Epoch: 238, Batch: 2, Loss: 0.1469\n",
            "Epoch: 238, Batch: 3, Loss: 0.0134\n",
            "Epoch: 238, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 239, Batch: 0, Loss: 0.0113\n",
            "Epoch: 239, Batch: 1, Loss: 0.0814\n",
            "Epoch: 239, Batch: 2, Loss: 0.0762\n",
            "Epoch: 239, Batch: 3, Loss: 0.0246\n",
            "Epoch: 239, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 240, Batch: 0, Loss: 0.0029\n",
            "Epoch: 240, Batch: 1, Loss: 0.0067\n",
            "Epoch: 240, Batch: 2, Loss: 0.1618\n",
            "Epoch: 240, Batch: 3, Loss: 0.1434\n",
            "Epoch: 240, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 241, Batch: 0, Loss: 0.2461\n",
            "Epoch: 241, Batch: 1, Loss: 0.0684\n",
            "Epoch: 241, Batch: 2, Loss: 0.0079\n",
            "Epoch: 241, Batch: 3, Loss: 0.0064\n",
            "Epoch: 241, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 242, Batch: 0, Loss: 0.0113\n",
            "Epoch: 242, Batch: 1, Loss: 0.1294\n",
            "Epoch: 242, Batch: 2, Loss: 0.0204\n",
            "Epoch: 242, Batch: 3, Loss: 0.0182\n",
            "Epoch: 242, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 243, Batch: 0, Loss: 0.0028\n",
            "Epoch: 243, Batch: 1, Loss: 0.0389\n",
            "Epoch: 243, Batch: 2, Loss: 0.1215\n",
            "Epoch: 243, Batch: 3, Loss: 0.0297\n",
            "Epoch: 243, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 244, Batch: 0, Loss: 0.0131\n",
            "Epoch: 244, Batch: 1, Loss: 0.0058\n",
            "Epoch: 244, Batch: 2, Loss: 0.1270\n",
            "Epoch: 244, Batch: 3, Loss: 0.1781\n",
            "Epoch: 244, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 245, Batch: 0, Loss: 0.0312\n",
            "Epoch: 245, Batch: 1, Loss: 0.1341\n",
            "Epoch: 245, Batch: 2, Loss: 0.0513\n",
            "Epoch: 245, Batch: 3, Loss: 0.0069\n",
            "Epoch: 245, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 246, Batch: 0, Loss: 0.0212\n",
            "Epoch: 246, Batch: 1, Loss: 0.0049\n",
            "Epoch: 246, Batch: 2, Loss: 0.0440\n",
            "Epoch: 246, Batch: 3, Loss: 0.1485\n",
            "Epoch: 246, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 247, Batch: 0, Loss: 0.0101\n",
            "Epoch: 247, Batch: 1, Loss: 0.1029\n",
            "Epoch: 247, Batch: 2, Loss: 0.0520\n",
            "Epoch: 247, Batch: 3, Loss: 0.0285\n",
            "Epoch: 247, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 248, Batch: 0, Loss: 0.0244\n",
            "Epoch: 248, Batch: 1, Loss: 0.1102\n",
            "Epoch: 248, Batch: 2, Loss: 0.0366\n",
            "Epoch: 248, Batch: 3, Loss: 0.0333\n",
            "Epoch: 248, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 249, Batch: 0, Loss: 0.1241\n",
            "Epoch: 249, Batch: 1, Loss: 0.0321\n",
            "Epoch: 249, Batch: 2, Loss: 0.0105\n",
            "Epoch: 249, Batch: 3, Loss: 0.0232\n",
            "Epoch: 249, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 250, Batch: 0, Loss: 0.0147\n",
            "Epoch: 250, Batch: 1, Loss: 0.1330\n",
            "Epoch: 250, Batch: 2, Loss: 0.0555\n",
            "Epoch: 250, Batch: 3, Loss: 0.0252\n",
            "Epoch: 250, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 251, Batch: 0, Loss: 0.0022\n",
            "Epoch: 251, Batch: 1, Loss: 0.0164\n",
            "Epoch: 251, Batch: 2, Loss: 0.1237\n",
            "Epoch: 251, Batch: 3, Loss: 0.0503\n",
            "Epoch: 251, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 252, Batch: 0, Loss: 0.1152\n",
            "Epoch: 252, Batch: 1, Loss: 0.0529\n",
            "Epoch: 252, Batch: 2, Loss: 0.0359\n",
            "Epoch: 252, Batch: 3, Loss: 0.0034\n",
            "Epoch: 252, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 253, Batch: 0, Loss: 0.0298\n",
            "Epoch: 253, Batch: 1, Loss: 0.0276\n",
            "Epoch: 253, Batch: 2, Loss: 0.0279\n",
            "Epoch: 253, Batch: 3, Loss: 0.1300\n",
            "Epoch: 253, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 254, Batch: 0, Loss: 0.0434\n",
            "Epoch: 254, Batch: 1, Loss: 0.0053\n",
            "Epoch: 254, Batch: 2, Loss: 0.1228\n",
            "Epoch: 254, Batch: 3, Loss: 0.0376\n",
            "Epoch: 254, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 255, Batch: 0, Loss: 0.0247\n",
            "Epoch: 255, Batch: 1, Loss: 0.1090\n",
            "Epoch: 255, Batch: 2, Loss: 0.0097\n",
            "Epoch: 255, Batch: 3, Loss: 0.0484\n",
            "Epoch: 255, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 256, Batch: 0, Loss: 0.0352\n",
            "Epoch: 256, Batch: 1, Loss: 0.1098\n",
            "Epoch: 256, Batch: 2, Loss: 0.0385\n",
            "Epoch: 256, Batch: 3, Loss: 0.0084\n",
            "Epoch: 256, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 257, Batch: 0, Loss: 0.0040\n",
            "Epoch: 257, Batch: 1, Loss: 0.0325\n",
            "Epoch: 257, Batch: 2, Loss: 0.1286\n",
            "Epoch: 257, Batch: 3, Loss: 0.0249\n",
            "Epoch: 257, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 258, Batch: 0, Loss: 0.1223\n",
            "Epoch: 258, Batch: 1, Loss: 0.0202\n",
            "Epoch: 258, Batch: 2, Loss: 0.0228\n",
            "Epoch: 258, Batch: 3, Loss: 0.0235\n",
            "Epoch: 258, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 259, Batch: 0, Loss: 0.0197\n",
            "Epoch: 259, Batch: 1, Loss: 0.0311\n",
            "Epoch: 259, Batch: 2, Loss: 0.1128\n",
            "Epoch: 259, Batch: 3, Loss: 0.0199\n",
            "Epoch: 259, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 260, Batch: 0, Loss: 0.0974\n",
            "Epoch: 260, Batch: 1, Loss: 0.0190\n",
            "Epoch: 260, Batch: 2, Loss: 0.0114\n",
            "Epoch: 260, Batch: 3, Loss: 0.0763\n",
            "Epoch: 260, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 261, Batch: 0, Loss: 0.1231\n",
            "Epoch: 261, Batch: 1, Loss: 0.0263\n",
            "Epoch: 261, Batch: 2, Loss: 0.0540\n",
            "Epoch: 261, Batch: 3, Loss: 0.0161\n",
            "Epoch: 261, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 262, Batch: 0, Loss: 0.0171\n",
            "Epoch: 262, Batch: 1, Loss: 0.0123\n",
            "Epoch: 262, Batch: 2, Loss: 0.0225\n",
            "Epoch: 262, Batch: 3, Loss: 0.1839\n",
            "Epoch: 262, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 263, Batch: 0, Loss: 0.0978\n",
            "Epoch: 263, Batch: 1, Loss: 0.0544\n",
            "Epoch: 263, Batch: 2, Loss: 0.0194\n",
            "Epoch: 263, Batch: 3, Loss: 0.0055\n",
            "Epoch: 263, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 264, Batch: 0, Loss: 0.1433\n",
            "Epoch: 264, Batch: 1, Loss: 0.0452\n",
            "Epoch: 264, Batch: 2, Loss: 0.0313\n",
            "Epoch: 264, Batch: 3, Loss: 0.0038\n",
            "Epoch: 264, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 265, Batch: 0, Loss: 0.0128\n",
            "Epoch: 265, Batch: 1, Loss: 0.0113\n",
            "Epoch: 265, Batch: 2, Loss: 0.0699\n",
            "Epoch: 265, Batch: 3, Loss: 0.1202\n",
            "Epoch: 265, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 266, Batch: 0, Loss: 0.0409\n",
            "Epoch: 266, Batch: 1, Loss: 0.0933\n",
            "Epoch: 266, Batch: 2, Loss: 0.0646\n",
            "Epoch: 266, Batch: 3, Loss: 0.0326\n",
            "Epoch: 266, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 267, Batch: 0, Loss: 0.0352\n",
            "Epoch: 267, Batch: 1, Loss: 0.1370\n",
            "Epoch: 267, Batch: 2, Loss: 0.0347\n",
            "Epoch: 267, Batch: 3, Loss: 0.0213\n",
            "Epoch: 267, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 268, Batch: 0, Loss: 0.1367\n",
            "Epoch: 268, Batch: 1, Loss: 0.0294\n",
            "Epoch: 268, Batch: 2, Loss: 0.0069\n",
            "Epoch: 268, Batch: 3, Loss: 0.0287\n",
            "Epoch: 268, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 269, Batch: 0, Loss: 0.0084\n",
            "Epoch: 269, Batch: 1, Loss: 0.0282\n",
            "Epoch: 269, Batch: 2, Loss: 0.1329\n",
            "Epoch: 269, Batch: 3, Loss: 0.0083\n",
            "Epoch: 269, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 270, Batch: 0, Loss: 0.0161\n",
            "Epoch: 270, Batch: 1, Loss: 0.0127\n",
            "Epoch: 270, Batch: 2, Loss: 0.0324\n",
            "Epoch: 270, Batch: 3, Loss: 0.1478\n",
            "Epoch: 270, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 271, Batch: 0, Loss: 0.0406\n",
            "Epoch: 271, Batch: 1, Loss: 0.0225\n",
            "Epoch: 271, Batch: 2, Loss: 0.0073\n",
            "Epoch: 271, Batch: 3, Loss: 0.1724\n",
            "Epoch: 271, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 272, Batch: 0, Loss: 0.0788\n",
            "Epoch: 272, Batch: 1, Loss: 0.1256\n",
            "Epoch: 272, Batch: 2, Loss: 0.0100\n",
            "Epoch: 272, Batch: 3, Loss: 0.0168\n",
            "Epoch: 272, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 273, Batch: 0, Loss: 0.0118\n",
            "Epoch: 273, Batch: 1, Loss: 0.0216\n",
            "Epoch: 273, Batch: 2, Loss: 0.0275\n",
            "Epoch: 273, Batch: 3, Loss: 0.1496\n",
            "Epoch: 273, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 274, Batch: 0, Loss: 0.0098\n",
            "Epoch: 274, Batch: 1, Loss: 0.1268\n",
            "Epoch: 274, Batch: 2, Loss: 0.0162\n",
            "Epoch: 274, Batch: 3, Loss: 0.0223\n",
            "Epoch: 274, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 275, Batch: 0, Loss: 0.0294\n",
            "Epoch: 275, Batch: 1, Loss: 0.1161\n",
            "Epoch: 275, Batch: 2, Loss: 0.0165\n",
            "Epoch: 275, Batch: 3, Loss: 0.0476\n",
            "Epoch: 275, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 276, Batch: 0, Loss: 0.1675\n",
            "Epoch: 276, Batch: 1, Loss: 0.0588\n",
            "Epoch: 276, Batch: 2, Loss: 0.0077\n",
            "Epoch: 276, Batch: 3, Loss: 0.0078\n",
            "Epoch: 276, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 277, Batch: 0, Loss: 0.0126\n",
            "Epoch: 277, Batch: 1, Loss: 0.0419\n",
            "Epoch: 277, Batch: 2, Loss: 0.1132\n",
            "Epoch: 277, Batch: 3, Loss: 0.0171\n",
            "Epoch: 277, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 278, Batch: 0, Loss: 0.0141\n",
            "Epoch: 278, Batch: 1, Loss: 0.0341\n",
            "Epoch: 278, Batch: 2, Loss: 0.1244\n",
            "Epoch: 278, Batch: 3, Loss: 0.0435\n",
            "Epoch: 278, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 279, Batch: 0, Loss: 0.1105\n",
            "Epoch: 279, Batch: 1, Loss: 0.0049\n",
            "Epoch: 279, Batch: 2, Loss: 0.0374\n",
            "Epoch: 279, Batch: 3, Loss: 0.0500\n",
            "Epoch: 279, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 280, Batch: 0, Loss: 0.0761\n",
            "Epoch: 280, Batch: 1, Loss: 0.0374\n",
            "Epoch: 280, Batch: 2, Loss: 0.0370\n",
            "Epoch: 280, Batch: 3, Loss: 0.0436\n",
            "Epoch: 280, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 281, Batch: 0, Loss: 0.0219\n",
            "Epoch: 281, Batch: 1, Loss: 0.0240\n",
            "Epoch: 281, Batch: 2, Loss: 0.1263\n",
            "Epoch: 281, Batch: 3, Loss: 0.0200\n",
            "Epoch: 281, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 282, Batch: 0, Loss: 0.0190\n",
            "Epoch: 282, Batch: 1, Loss: 0.0282\n",
            "Epoch: 282, Batch: 2, Loss: 0.1286\n",
            "Epoch: 282, Batch: 3, Loss: 0.0151\n",
            "Epoch: 282, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 283, Batch: 0, Loss: 0.0957\n",
            "Epoch: 283, Batch: 1, Loss: 0.0176\n",
            "Epoch: 283, Batch: 2, Loss: 0.0339\n",
            "Epoch: 283, Batch: 3, Loss: 0.0373\n",
            "Epoch: 283, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 284, Batch: 0, Loss: 0.0314\n",
            "Epoch: 284, Batch: 1, Loss: 0.1092\n",
            "Epoch: 284, Batch: 2, Loss: 0.0490\n",
            "Epoch: 284, Batch: 3, Loss: 0.0034\n",
            "Epoch: 284, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 285, Batch: 0, Loss: 0.0340\n",
            "Epoch: 285, Batch: 1, Loss: 0.1280\n",
            "Epoch: 285, Batch: 2, Loss: 0.0056\n",
            "Epoch: 285, Batch: 3, Loss: 0.0144\n",
            "Epoch: 285, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 286, Batch: 0, Loss: 0.1152\n",
            "Epoch: 286, Batch: 1, Loss: 0.0189\n",
            "Epoch: 286, Batch: 2, Loss: 0.0471\n",
            "Epoch: 286, Batch: 3, Loss: 0.0181\n",
            "Epoch: 286, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 287, Batch: 0, Loss: 0.0343\n",
            "Epoch: 287, Batch: 1, Loss: 0.0226\n",
            "Epoch: 287, Batch: 2, Loss: 0.0301\n",
            "Epoch: 287, Batch: 3, Loss: 0.1277\n",
            "Epoch: 287, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 288, Batch: 0, Loss: 0.0131\n",
            "Epoch: 288, Batch: 1, Loss: 0.0207\n",
            "Epoch: 288, Batch: 2, Loss: 0.1241\n",
            "Epoch: 288, Batch: 3, Loss: 0.0430\n",
            "Epoch: 288, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 289, Batch: 0, Loss: 0.0185\n",
            "Epoch: 289, Batch: 1, Loss: 0.1349\n",
            "Epoch: 289, Batch: 2, Loss: 0.0288\n",
            "Epoch: 289, Batch: 3, Loss: 0.0102\n",
            "Epoch: 289, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 290, Batch: 0, Loss: 0.0074\n",
            "Epoch: 290, Batch: 1, Loss: 0.1364\n",
            "Epoch: 290, Batch: 2, Loss: 0.0527\n",
            "Epoch: 290, Batch: 3, Loss: 0.0065\n",
            "Epoch: 290, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 291, Batch: 0, Loss: 0.0191\n",
            "Epoch: 291, Batch: 1, Loss: 0.1137\n",
            "Epoch: 291, Batch: 2, Loss: 0.0127\n",
            "Epoch: 291, Batch: 3, Loss: 0.0553\n",
            "Epoch: 291, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 292, Batch: 0, Loss: 0.1285\n",
            "Epoch: 292, Batch: 1, Loss: 0.0394\n",
            "Epoch: 292, Batch: 2, Loss: 0.0334\n",
            "Epoch: 292, Batch: 3, Loss: 0.0088\n",
            "Epoch: 292, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 293, Batch: 0, Loss: 0.0466\n",
            "Epoch: 293, Batch: 1, Loss: 0.1171\n",
            "Epoch: 293, Batch: 2, Loss: 0.0117\n",
            "Epoch: 293, Batch: 3, Loss: 0.0107\n",
            "Epoch: 293, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 294, Batch: 0, Loss: 0.0879\n",
            "Epoch: 294, Batch: 1, Loss: 0.0663\n",
            "Epoch: 294, Batch: 2, Loss: 0.0388\n",
            "Epoch: 294, Batch: 3, Loss: 0.0026\n",
            "Epoch: 294, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 295, Batch: 0, Loss: 0.0227\n",
            "Epoch: 295, Batch: 1, Loss: 0.0380\n",
            "Epoch: 295, Batch: 2, Loss: 0.1120\n",
            "Epoch: 295, Batch: 3, Loss: 0.0479\n",
            "Epoch: 295, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 296, Batch: 0, Loss: 0.0391\n",
            "Epoch: 296, Batch: 1, Loss: 0.1231\n",
            "Epoch: 296, Batch: 2, Loss: 0.0133\n",
            "Epoch: 296, Batch: 3, Loss: 0.0087\n",
            "Epoch: 296, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 297, Batch: 0, Loss: 0.1182\n",
            "Epoch: 297, Batch: 1, Loss: 0.0037\n",
            "Epoch: 297, Batch: 2, Loss: 0.0557\n",
            "Epoch: 297, Batch: 3, Loss: 0.0050\n",
            "Epoch: 297, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 298, Batch: 0, Loss: 0.0234\n",
            "Epoch: 298, Batch: 1, Loss: 0.0448\n",
            "Epoch: 298, Batch: 2, Loss: 0.1532\n",
            "Epoch: 298, Batch: 3, Loss: 0.0231\n",
            "Epoch: 298, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 299, Batch: 0, Loss: 0.0327\n",
            "Epoch: 299, Batch: 1, Loss: 0.1460\n",
            "Epoch: 299, Batch: 2, Loss: 0.0105\n",
            "Epoch: 299, Batch: 3, Loss: 0.0532\n",
            "Epoch: 299, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 300, Batch: 0, Loss: 0.0266\n",
            "Epoch: 300, Batch: 1, Loss: 0.1442\n",
            "Epoch: 300, Batch: 2, Loss: 0.0084\n",
            "Epoch: 300, Batch: 3, Loss: 0.0123\n",
            "Epoch: 300, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 301, Batch: 0, Loss: 0.0773\n",
            "Epoch: 301, Batch: 1, Loss: 0.1013\n",
            "Epoch: 301, Batch: 2, Loss: 0.0288\n",
            "Epoch: 301, Batch: 3, Loss: 0.0301\n",
            "Epoch: 301, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 302, Batch: 0, Loss: 0.1127\n",
            "Epoch: 302, Batch: 1, Loss: 0.0747\n",
            "Epoch: 302, Batch: 2, Loss: 0.0176\n",
            "Epoch: 302, Batch: 3, Loss: 0.0066\n",
            "Epoch: 302, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 303, Batch: 0, Loss: 0.1219\n",
            "Epoch: 303, Batch: 1, Loss: 0.0245\n",
            "Epoch: 303, Batch: 2, Loss: 0.0524\n",
            "Epoch: 303, Batch: 3, Loss: 0.0042\n",
            "Epoch: 303, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 304, Batch: 0, Loss: 0.0158\n",
            "Epoch: 304, Batch: 1, Loss: 0.0276\n",
            "Epoch: 304, Batch: 2, Loss: 0.1039\n",
            "Epoch: 304, Batch: 3, Loss: 0.0547\n",
            "Epoch: 304, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 305, Batch: 0, Loss: 0.0242\n",
            "Epoch: 305, Batch: 1, Loss: 0.0369\n",
            "Epoch: 305, Batch: 2, Loss: 0.0181\n",
            "Epoch: 305, Batch: 3, Loss: 0.1406\n",
            "Epoch: 305, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 306, Batch: 0, Loss: 0.0167\n",
            "Epoch: 306, Batch: 1, Loss: 0.0538\n",
            "Epoch: 306, Batch: 2, Loss: 0.1219\n",
            "Epoch: 306, Batch: 3, Loss: 0.0195\n",
            "Epoch: 306, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 307, Batch: 0, Loss: 0.0194\n",
            "Epoch: 307, Batch: 1, Loss: 0.1071\n",
            "Epoch: 307, Batch: 2, Loss: 0.0072\n",
            "Epoch: 307, Batch: 3, Loss: 0.0884\n",
            "Epoch: 307, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 308, Batch: 0, Loss: 0.1815\n",
            "Epoch: 308, Batch: 1, Loss: 0.0108\n",
            "Epoch: 308, Batch: 2, Loss: 0.0102\n",
            "Epoch: 308, Batch: 3, Loss: 0.0392\n",
            "Epoch: 308, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 309, Batch: 0, Loss: 0.0378\n",
            "Epoch: 309, Batch: 1, Loss: 0.1034\n",
            "Epoch: 309, Batch: 2, Loss: 0.0326\n",
            "Epoch: 309, Batch: 3, Loss: 0.0291\n",
            "Epoch: 309, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 310, Batch: 0, Loss: 0.1259\n",
            "Epoch: 310, Batch: 1, Loss: 0.0064\n",
            "Epoch: 310, Batch: 2, Loss: 0.0198\n",
            "Epoch: 310, Batch: 3, Loss: 0.0618\n",
            "Epoch: 310, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 311, Batch: 0, Loss: 0.0526\n",
            "Epoch: 311, Batch: 1, Loss: 0.0250\n",
            "Epoch: 311, Batch: 2, Loss: 0.1183\n",
            "Epoch: 311, Batch: 3, Loss: 0.0115\n",
            "Epoch: 311, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 312, Batch: 0, Loss: 0.0509\n",
            "Epoch: 312, Batch: 1, Loss: 0.1310\n",
            "Epoch: 312, Batch: 2, Loss: 0.0113\n",
            "Epoch: 312, Batch: 3, Loss: 0.0252\n",
            "Epoch: 312, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 313, Batch: 0, Loss: 0.0994\n",
            "Epoch: 313, Batch: 1, Loss: 0.0509\n",
            "Epoch: 313, Batch: 2, Loss: 0.0050\n",
            "Epoch: 313, Batch: 3, Loss: 0.0351\n",
            "Epoch: 313, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 314, Batch: 0, Loss: 0.0379\n",
            "Epoch: 314, Batch: 1, Loss: 0.1179\n",
            "Epoch: 314, Batch: 2, Loss: 0.0431\n",
            "Epoch: 314, Batch: 3, Loss: 0.0050\n",
            "Epoch: 314, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 315, Batch: 0, Loss: 0.1297\n",
            "Epoch: 315, Batch: 1, Loss: 0.0171\n",
            "Epoch: 315, Batch: 2, Loss: 0.0401\n",
            "Epoch: 315, Batch: 3, Loss: 0.0046\n",
            "Epoch: 315, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 316, Batch: 0, Loss: 0.1101\n",
            "Epoch: 316, Batch: 1, Loss: 0.0483\n",
            "Epoch: 316, Batch: 2, Loss: 0.0306\n",
            "Epoch: 316, Batch: 3, Loss: 0.0030\n",
            "Epoch: 316, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 317, Batch: 0, Loss: 0.0075\n",
            "Epoch: 317, Batch: 1, Loss: 0.0058\n",
            "Epoch: 317, Batch: 2, Loss: 0.0459\n",
            "Epoch: 317, Batch: 3, Loss: 0.1720\n",
            "Epoch: 317, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 318, Batch: 0, Loss: 0.0403\n",
            "Epoch: 318, Batch: 1, Loss: 0.1235\n",
            "Epoch: 318, Batch: 2, Loss: 0.0333\n",
            "Epoch: 318, Batch: 3, Loss: 0.0216\n",
            "Epoch: 318, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 319, Batch: 0, Loss: 0.0133\n",
            "Epoch: 319, Batch: 1, Loss: 0.1007\n",
            "Epoch: 319, Batch: 2, Loss: 0.0755\n",
            "Epoch: 319, Batch: 3, Loss: 0.0302\n",
            "Epoch: 319, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 320, Batch: 0, Loss: 0.1285\n",
            "Epoch: 320, Batch: 1, Loss: 0.0064\n",
            "Epoch: 320, Batch: 2, Loss: 0.0233\n",
            "Epoch: 320, Batch: 3, Loss: 0.0282\n",
            "Epoch: 320, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 321, Batch: 0, Loss: 0.1023\n",
            "Epoch: 321, Batch: 1, Loss: 0.0637\n",
            "Epoch: 321, Batch: 2, Loss: 0.0346\n",
            "Epoch: 321, Batch: 3, Loss: 0.0064\n",
            "Epoch: 321, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 322, Batch: 0, Loss: 0.1222\n",
            "Epoch: 322, Batch: 1, Loss: 0.0327\n",
            "Epoch: 322, Batch: 2, Loss: 0.0138\n",
            "Epoch: 322, Batch: 3, Loss: 0.0189\n",
            "Epoch: 322, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 323, Batch: 0, Loss: 0.1281\n",
            "Epoch: 323, Batch: 1, Loss: 0.0508\n",
            "Epoch: 323, Batch: 2, Loss: 0.0078\n",
            "Epoch: 323, Batch: 3, Loss: 0.0266\n",
            "Epoch: 323, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 324, Batch: 0, Loss: 0.0416\n",
            "Epoch: 324, Batch: 1, Loss: 0.0303\n",
            "Epoch: 324, Batch: 2, Loss: 0.0224\n",
            "Epoch: 324, Batch: 3, Loss: 0.1157\n",
            "Epoch: 324, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 325, Batch: 0, Loss: 0.0719\n",
            "Epoch: 325, Batch: 1, Loss: 0.0741\n",
            "Epoch: 325, Batch: 2, Loss: 0.0238\n",
            "Epoch: 325, Batch: 3, Loss: 0.0308\n",
            "Epoch: 325, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 326, Batch: 0, Loss: 0.0282\n",
            "Epoch: 326, Batch: 1, Loss: 0.0338\n",
            "Epoch: 326, Batch: 2, Loss: 0.1258\n",
            "Epoch: 326, Batch: 3, Loss: 0.0044\n",
            "Epoch: 326, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 327, Batch: 0, Loss: 0.0219\n",
            "Epoch: 327, Batch: 1, Loss: 0.0283\n",
            "Epoch: 327, Batch: 2, Loss: 0.0341\n",
            "Epoch: 327, Batch: 3, Loss: 0.1606\n",
            "Epoch: 327, Training Accuracy: 97.52%, Validation Accuracy: 92.86%\n",
            "Epoch: 328, Batch: 0, Loss: 0.0705\n",
            "Epoch: 328, Batch: 1, Loss: 0.0360\n",
            "Epoch: 328, Batch: 2, Loss: 0.0185\n",
            "Epoch: 328, Batch: 3, Loss: 0.1224\n",
            "Epoch: 328, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 329, Batch: 0, Loss: 0.1109\n",
            "Epoch: 329, Batch: 1, Loss: 0.0097\n",
            "Epoch: 329, Batch: 2, Loss: 0.0050\n",
            "Epoch: 329, Batch: 3, Loss: 0.2461\n",
            "Epoch: 329, Training Accuracy: 94.21%, Validation Accuracy: 92.86%\n",
            "Epoch: 330, Batch: 0, Loss: 0.0311\n",
            "Epoch: 330, Batch: 1, Loss: 0.1629\n",
            "Epoch: 330, Batch: 2, Loss: 0.0421\n",
            "Epoch: 330, Batch: 3, Loss: 0.0074\n",
            "Epoch: 330, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 331, Batch: 0, Loss: 0.0196\n",
            "Epoch: 331, Batch: 1, Loss: 0.1471\n",
            "Epoch: 331, Batch: 2, Loss: 0.0225\n",
            "Epoch: 331, Batch: 3, Loss: 0.0049\n",
            "Epoch: 331, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 332, Batch: 0, Loss: 0.0370\n",
            "Epoch: 332, Batch: 1, Loss: 0.0039\n",
            "Epoch: 332, Batch: 2, Loss: 0.1446\n",
            "Epoch: 332, Batch: 3, Loss: 0.0200\n",
            "Epoch: 332, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 333, Batch: 0, Loss: 0.0152\n",
            "Epoch: 333, Batch: 1, Loss: 0.0150\n",
            "Epoch: 333, Batch: 2, Loss: 0.0112\n",
            "Epoch: 333, Batch: 3, Loss: 0.1698\n",
            "Epoch: 333, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 334, Batch: 0, Loss: 0.0240\n",
            "Epoch: 334, Batch: 1, Loss: 0.0077\n",
            "Epoch: 334, Batch: 2, Loss: 0.1465\n",
            "Epoch: 334, Batch: 3, Loss: 0.0094\n",
            "Epoch: 334, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 335, Batch: 0, Loss: 0.0364\n",
            "Epoch: 335, Batch: 1, Loss: 0.0195\n",
            "Epoch: 335, Batch: 2, Loss: 0.1184\n",
            "Epoch: 335, Batch: 3, Loss: 0.0350\n",
            "Epoch: 335, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 336, Batch: 0, Loss: 0.0195\n",
            "Epoch: 336, Batch: 1, Loss: 0.0071\n",
            "Epoch: 336, Batch: 2, Loss: 0.1417\n",
            "Epoch: 336, Batch: 3, Loss: 0.0119\n",
            "Epoch: 336, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 337, Batch: 0, Loss: 0.0914\n",
            "Epoch: 337, Batch: 1, Loss: 0.0823\n",
            "Epoch: 337, Batch: 2, Loss: 0.0539\n",
            "Epoch: 337, Batch: 3, Loss: 0.0152\n",
            "Epoch: 337, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 338, Batch: 0, Loss: 0.0194\n",
            "Epoch: 338, Batch: 1, Loss: 0.0125\n",
            "Epoch: 338, Batch: 2, Loss: 0.0048\n",
            "Epoch: 338, Batch: 3, Loss: 0.1794\n",
            "Epoch: 338, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 339, Batch: 0, Loss: 0.0227\n",
            "Epoch: 339, Batch: 1, Loss: 0.0104\n",
            "Epoch: 339, Batch: 2, Loss: 0.1151\n",
            "Epoch: 339, Batch: 3, Loss: 0.0370\n",
            "Epoch: 339, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 340, Batch: 0, Loss: 0.0239\n",
            "Epoch: 340, Batch: 1, Loss: 0.0268\n",
            "Epoch: 340, Batch: 2, Loss: 0.1208\n",
            "Epoch: 340, Batch: 3, Loss: 0.0028\n",
            "Epoch: 340, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 341, Batch: 0, Loss: 0.0326\n",
            "Epoch: 341, Batch: 1, Loss: 0.0264\n",
            "Epoch: 341, Batch: 2, Loss: 0.1172\n",
            "Epoch: 341, Batch: 3, Loss: 0.0290\n",
            "Epoch: 341, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 342, Batch: 0, Loss: 0.1171\n",
            "Epoch: 342, Batch: 1, Loss: 0.0580\n",
            "Epoch: 342, Batch: 2, Loss: 0.0154\n",
            "Epoch: 342, Batch: 3, Loss: 0.0052\n",
            "Epoch: 342, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 343, Batch: 0, Loss: 0.1089\n",
            "Epoch: 343, Batch: 1, Loss: 0.0179\n",
            "Epoch: 343, Batch: 2, Loss: 0.0503\n",
            "Epoch: 343, Batch: 3, Loss: 0.0262\n",
            "Epoch: 343, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 344, Batch: 0, Loss: 0.0373\n",
            "Epoch: 344, Batch: 1, Loss: 0.0051\n",
            "Epoch: 344, Batch: 2, Loss: 0.1446\n",
            "Epoch: 344, Batch: 3, Loss: 0.0069\n",
            "Epoch: 344, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 345, Batch: 0, Loss: 0.0103\n",
            "Epoch: 345, Batch: 1, Loss: 0.1045\n",
            "Epoch: 345, Batch: 2, Loss: 0.0292\n",
            "Epoch: 345, Batch: 3, Loss: 0.0352\n",
            "Epoch: 345, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 346, Batch: 0, Loss: 0.0086\n",
            "Epoch: 346, Batch: 1, Loss: 0.0341\n",
            "Epoch: 346, Batch: 2, Loss: 0.1394\n",
            "Epoch: 346, Batch: 3, Loss: 0.0187\n",
            "Epoch: 346, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 347, Batch: 0, Loss: 0.0509\n",
            "Epoch: 347, Batch: 1, Loss: 0.0275\n",
            "Epoch: 347, Batch: 2, Loss: 0.1048\n",
            "Epoch: 347, Batch: 3, Loss: 0.0045\n",
            "Epoch: 347, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 348, Batch: 0, Loss: 0.0223\n",
            "Epoch: 348, Batch: 1, Loss: 0.0400\n",
            "Epoch: 348, Batch: 2, Loss: 0.0058\n",
            "Epoch: 348, Batch: 3, Loss: 0.1711\n",
            "Epoch: 348, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 349, Batch: 0, Loss: 0.0283\n",
            "Epoch: 349, Batch: 1, Loss: 0.0347\n",
            "Epoch: 349, Batch: 2, Loss: 0.0453\n",
            "Epoch: 349, Batch: 3, Loss: 0.1250\n",
            "Epoch: 349, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 350, Batch: 0, Loss: 0.0202\n",
            "Epoch: 350, Batch: 1, Loss: 0.0796\n",
            "Epoch: 350, Batch: 2, Loss: 0.1243\n",
            "Epoch: 350, Batch: 3, Loss: 0.0506\n",
            "Epoch: 350, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 351, Batch: 0, Loss: 0.0042\n",
            "Epoch: 351, Batch: 1, Loss: 0.0998\n",
            "Epoch: 351, Batch: 2, Loss: 0.0190\n",
            "Epoch: 351, Batch: 3, Loss: 0.0875\n",
            "Epoch: 351, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 352, Batch: 0, Loss: 0.0122\n",
            "Epoch: 352, Batch: 1, Loss: 0.0152\n",
            "Epoch: 352, Batch: 2, Loss: 0.0119\n",
            "Epoch: 352, Batch: 3, Loss: 0.2442\n",
            "Epoch: 352, Training Accuracy: 94.21%, Validation Accuracy: 92.86%\n",
            "Epoch: 353, Batch: 0, Loss: 0.1034\n",
            "Epoch: 353, Batch: 1, Loss: 0.0228\n",
            "Epoch: 353, Batch: 2, Loss: 0.1715\n",
            "Epoch: 353, Batch: 3, Loss: 0.0090\n",
            "Epoch: 353, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 354, Batch: 0, Loss: 0.0479\n",
            "Epoch: 354, Batch: 1, Loss: 0.0070\n",
            "Epoch: 354, Batch: 2, Loss: 0.0356\n",
            "Epoch: 354, Batch: 3, Loss: 0.1335\n",
            "Epoch: 354, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 355, Batch: 0, Loss: 0.0885\n",
            "Epoch: 355, Batch: 1, Loss: 0.0457\n",
            "Epoch: 355, Batch: 2, Loss: 0.0469\n",
            "Epoch: 355, Batch: 3, Loss: 0.0052\n",
            "Epoch: 355, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 356, Batch: 0, Loss: 0.1342\n",
            "Epoch: 356, Batch: 1, Loss: 0.0461\n",
            "Epoch: 356, Batch: 2, Loss: 0.0202\n",
            "Epoch: 356, Batch: 3, Loss: 0.0361\n",
            "Epoch: 356, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 357, Batch: 0, Loss: 0.0570\n",
            "Epoch: 357, Batch: 1, Loss: 0.0082\n",
            "Epoch: 357, Batch: 2, Loss: 0.1078\n",
            "Epoch: 357, Batch: 3, Loss: 0.0218\n",
            "Epoch: 357, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 358, Batch: 0, Loss: 0.0016\n",
            "Epoch: 358, Batch: 1, Loss: 0.0097\n",
            "Epoch: 358, Batch: 2, Loss: 0.0245\n",
            "Epoch: 358, Batch: 3, Loss: 0.2117\n",
            "Epoch: 358, Training Accuracy: 97.52%, Validation Accuracy: 92.86%\n",
            "Epoch: 359, Batch: 0, Loss: 0.1145\n",
            "Epoch: 359, Batch: 1, Loss: 0.0112\n",
            "Epoch: 359, Batch: 2, Loss: 0.0563\n",
            "Epoch: 359, Batch: 3, Loss: 0.0367\n",
            "Epoch: 359, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 360, Batch: 0, Loss: 0.0086\n",
            "Epoch: 360, Batch: 1, Loss: 0.0053\n",
            "Epoch: 360, Batch: 2, Loss: 0.1361\n",
            "Epoch: 360, Batch: 3, Loss: 0.0541\n",
            "Epoch: 360, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 361, Batch: 0, Loss: 0.1011\n",
            "Epoch: 361, Batch: 1, Loss: 0.0517\n",
            "Epoch: 361, Batch: 2, Loss: 0.0294\n",
            "Epoch: 361, Batch: 3, Loss: 0.0257\n",
            "Epoch: 361, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 362, Batch: 0, Loss: 0.0061\n",
            "Epoch: 362, Batch: 1, Loss: 0.1213\n",
            "Epoch: 362, Batch: 2, Loss: 0.0056\n",
            "Epoch: 362, Batch: 3, Loss: 0.0530\n",
            "Epoch: 362, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 363, Batch: 0, Loss: 0.0822\n",
            "Epoch: 363, Batch: 1, Loss: 0.0735\n",
            "Epoch: 363, Batch: 2, Loss: 0.0205\n",
            "Epoch: 363, Batch: 3, Loss: 0.0263\n",
            "Epoch: 363, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 364, Batch: 0, Loss: 0.0393\n",
            "Epoch: 364, Batch: 1, Loss: 0.0843\n",
            "Epoch: 364, Batch: 2, Loss: 0.0906\n",
            "Epoch: 364, Batch: 3, Loss: 0.0097\n",
            "Epoch: 364, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 365, Batch: 0, Loss: 0.0551\n",
            "Epoch: 365, Batch: 1, Loss: 0.1063\n",
            "Epoch: 365, Batch: 2, Loss: 0.0508\n",
            "Epoch: 365, Batch: 3, Loss: 0.0044\n",
            "Epoch: 365, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 366, Batch: 0, Loss: 0.0283\n",
            "Epoch: 366, Batch: 1, Loss: 0.1270\n",
            "Epoch: 366, Batch: 2, Loss: 0.0201\n",
            "Epoch: 366, Batch: 3, Loss: 0.0083\n",
            "Epoch: 366, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 367, Batch: 0, Loss: 0.0080\n",
            "Epoch: 367, Batch: 1, Loss: 0.1292\n",
            "Epoch: 367, Batch: 2, Loss: 0.0473\n",
            "Epoch: 367, Batch: 3, Loss: 0.0059\n",
            "Epoch: 367, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 368, Batch: 0, Loss: 0.0051\n",
            "Epoch: 368, Batch: 1, Loss: 0.0449\n",
            "Epoch: 368, Batch: 2, Loss: 0.0277\n",
            "Epoch: 368, Batch: 3, Loss: 0.1259\n",
            "Epoch: 368, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 369, Batch: 0, Loss: 0.0510\n",
            "Epoch: 369, Batch: 1, Loss: 0.0959\n",
            "Epoch: 369, Batch: 2, Loss: 0.0618\n",
            "Epoch: 369, Batch: 3, Loss: 0.0287\n",
            "Epoch: 369, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 370, Batch: 0, Loss: 0.0380\n",
            "Epoch: 370, Batch: 1, Loss: 0.0234\n",
            "Epoch: 370, Batch: 2, Loss: 0.0046\n",
            "Epoch: 370, Batch: 3, Loss: 0.1427\n",
            "Epoch: 370, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 371, Batch: 0, Loss: 0.0032\n",
            "Epoch: 371, Batch: 1, Loss: 0.1063\n",
            "Epoch: 371, Batch: 2, Loss: 0.0664\n",
            "Epoch: 371, Batch: 3, Loss: 0.0332\n",
            "Epoch: 371, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 372, Batch: 0, Loss: 0.1084\n",
            "Epoch: 372, Batch: 1, Loss: 0.0570\n",
            "Epoch: 372, Batch: 2, Loss: 0.0351\n",
            "Epoch: 372, Batch: 3, Loss: 0.0106\n",
            "Epoch: 372, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 373, Batch: 0, Loss: 0.0315\n",
            "Epoch: 373, Batch: 1, Loss: 0.0305\n",
            "Epoch: 373, Batch: 2, Loss: 0.1305\n",
            "Epoch: 373, Batch: 3, Loss: 0.0076\n",
            "Epoch: 373, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 374, Batch: 0, Loss: 0.0142\n",
            "Epoch: 374, Batch: 1, Loss: 0.0844\n",
            "Epoch: 374, Batch: 2, Loss: 0.1066\n",
            "Epoch: 374, Batch: 3, Loss: 0.0169\n",
            "Epoch: 374, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 375, Batch: 0, Loss: 0.0148\n",
            "Epoch: 375, Batch: 1, Loss: 0.0117\n",
            "Epoch: 375, Batch: 2, Loss: 0.1562\n",
            "Epoch: 375, Batch: 3, Loss: 0.0169\n",
            "Epoch: 375, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 376, Batch: 0, Loss: 0.1041\n",
            "Epoch: 376, Batch: 1, Loss: 0.0255\n",
            "Epoch: 376, Batch: 2, Loss: 0.0056\n",
            "Epoch: 376, Batch: 3, Loss: 0.0481\n",
            "Epoch: 376, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 377, Batch: 0, Loss: 0.1333\n",
            "Epoch: 377, Batch: 1, Loss: 0.0681\n",
            "Epoch: 377, Batch: 2, Loss: 0.0047\n",
            "Epoch: 377, Batch: 3, Loss: 0.0086\n",
            "Epoch: 377, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 378, Batch: 0, Loss: 0.0497\n",
            "Epoch: 378, Batch: 1, Loss: 0.0169\n",
            "Epoch: 378, Batch: 2, Loss: 0.0178\n",
            "Epoch: 378, Batch: 3, Loss: 0.1523\n",
            "Epoch: 378, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 379, Batch: 0, Loss: 0.0483\n",
            "Epoch: 379, Batch: 1, Loss: 0.0200\n",
            "Epoch: 379, Batch: 2, Loss: 0.1132\n",
            "Epoch: 379, Batch: 3, Loss: 0.0222\n",
            "Epoch: 379, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 380, Batch: 0, Loss: 0.0259\n",
            "Epoch: 380, Batch: 1, Loss: 0.0353\n",
            "Epoch: 380, Batch: 2, Loss: 0.0060\n",
            "Epoch: 380, Batch: 3, Loss: 0.1605\n",
            "Epoch: 380, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 381, Batch: 0, Loss: 0.0243\n",
            "Epoch: 381, Batch: 1, Loss: 0.0179\n",
            "Epoch: 381, Batch: 2, Loss: 0.0608\n",
            "Epoch: 381, Batch: 3, Loss: 0.0957\n",
            "Epoch: 381, Training Accuracy: 97.52%, Validation Accuracy: 92.86%\n",
            "Epoch: 382, Batch: 0, Loss: 0.0339\n",
            "Epoch: 382, Batch: 1, Loss: 0.0232\n",
            "Epoch: 382, Batch: 2, Loss: 0.1350\n",
            "Epoch: 382, Batch: 3, Loss: 0.0042\n",
            "Epoch: 382, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 383, Batch: 0, Loss: 0.0064\n",
            "Epoch: 383, Batch: 1, Loss: 0.0322\n",
            "Epoch: 383, Batch: 2, Loss: 0.0400\n",
            "Epoch: 383, Batch: 3, Loss: 0.1626\n",
            "Epoch: 383, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 384, Batch: 0, Loss: 0.0403\n",
            "Epoch: 384, Batch: 1, Loss: 0.0224\n",
            "Epoch: 384, Batch: 2, Loss: 0.0074\n",
            "Epoch: 384, Batch: 3, Loss: 0.1779\n",
            "Epoch: 384, Training Accuracy: 97.52%, Validation Accuracy: 92.86%\n",
            "Epoch: 385, Batch: 0, Loss: 0.0251\n",
            "Epoch: 385, Batch: 1, Loss: 0.0137\n",
            "Epoch: 385, Batch: 2, Loss: 0.1219\n",
            "Epoch: 385, Batch: 3, Loss: 0.0400\n",
            "Epoch: 385, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 386, Batch: 0, Loss: 0.0209\n",
            "Epoch: 386, Batch: 1, Loss: 0.0927\n",
            "Epoch: 386, Batch: 2, Loss: 0.0641\n",
            "Epoch: 386, Batch: 3, Loss: 0.0144\n",
            "Epoch: 386, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 387, Batch: 0, Loss: 0.0168\n",
            "Epoch: 387, Batch: 1, Loss: 0.1496\n",
            "Epoch: 387, Batch: 2, Loss: 0.0191\n",
            "Epoch: 387, Batch: 3, Loss: 0.0197\n",
            "Epoch: 387, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 388, Batch: 0, Loss: 0.0373\n",
            "Epoch: 388, Batch: 1, Loss: 0.0013\n",
            "Epoch: 388, Batch: 2, Loss: 0.1283\n",
            "Epoch: 388, Batch: 3, Loss: 0.0982\n",
            "Epoch: 388, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 389, Batch: 0, Loss: 0.1289\n",
            "Epoch: 389, Batch: 1, Loss: 0.0306\n",
            "Epoch: 389, Batch: 2, Loss: 0.0230\n",
            "Epoch: 389, Batch: 3, Loss: 0.0351\n",
            "Epoch: 389, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 390, Batch: 0, Loss: 0.0051\n",
            "Epoch: 390, Batch: 1, Loss: 0.0344\n",
            "Epoch: 390, Batch: 2, Loss: 0.1870\n",
            "Epoch: 390, Batch: 3, Loss: 0.0429\n",
            "Epoch: 390, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 391, Batch: 0, Loss: 0.0083\n",
            "Epoch: 391, Batch: 1, Loss: 0.0032\n",
            "Epoch: 391, Batch: 2, Loss: 0.0370\n",
            "Epoch: 391, Batch: 3, Loss: 0.2346\n",
            "Epoch: 391, Training Accuracy: 94.21%, Validation Accuracy: 92.86%\n",
            "Epoch: 392, Batch: 0, Loss: 0.1317\n",
            "Epoch: 392, Batch: 1, Loss: 0.0352\n",
            "Epoch: 392, Batch: 2, Loss: 0.0216\n",
            "Epoch: 392, Batch: 3, Loss: 0.1412\n",
            "Epoch: 392, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 393, Batch: 0, Loss: 0.0134\n",
            "Epoch: 393, Batch: 1, Loss: 0.0290\n",
            "Epoch: 393, Batch: 2, Loss: 0.0397\n",
            "Epoch: 393, Batch: 3, Loss: 0.1457\n",
            "Epoch: 393, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 394, Batch: 0, Loss: 0.0476\n",
            "Epoch: 394, Batch: 1, Loss: 0.0247\n",
            "Epoch: 394, Batch: 2, Loss: 0.0922\n",
            "Epoch: 394, Batch: 3, Loss: 0.0614\n",
            "Epoch: 394, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 395, Batch: 0, Loss: 0.0206\n",
            "Epoch: 395, Batch: 1, Loss: 0.0339\n",
            "Epoch: 395, Batch: 2, Loss: 0.1108\n",
            "Epoch: 395, Batch: 3, Loss: 0.0115\n",
            "Epoch: 395, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 396, Batch: 0, Loss: 0.0115\n",
            "Epoch: 396, Batch: 1, Loss: 0.0173\n",
            "Epoch: 396, Batch: 2, Loss: 0.0314\n",
            "Epoch: 396, Batch: 3, Loss: 0.1520\n",
            "Epoch: 396, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 397, Batch: 0, Loss: 0.0069\n",
            "Epoch: 397, Batch: 1, Loss: 0.0137\n",
            "Epoch: 397, Batch: 2, Loss: 0.0374\n",
            "Epoch: 397, Batch: 3, Loss: 0.1859\n",
            "Epoch: 397, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 398, Batch: 0, Loss: 0.0166\n",
            "Epoch: 398, Batch: 1, Loss: 0.0543\n",
            "Epoch: 398, Batch: 2, Loss: 0.1129\n",
            "Epoch: 398, Batch: 3, Loss: 0.0078\n",
            "Epoch: 398, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 399, Batch: 0, Loss: 0.0087\n",
            "Epoch: 399, Batch: 1, Loss: 0.1261\n",
            "Epoch: 399, Batch: 2, Loss: 0.0214\n",
            "Epoch: 399, Batch: 3, Loss: 0.0382\n",
            "Epoch: 399, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 400, Batch: 0, Loss: 0.0059\n",
            "Epoch: 400, Batch: 1, Loss: 0.0423\n",
            "Epoch: 400, Batch: 2, Loss: 0.0240\n",
            "Epoch: 400, Batch: 3, Loss: 0.1359\n",
            "Epoch: 400, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 401, Batch: 0, Loss: 0.0770\n",
            "Epoch: 401, Batch: 1, Loss: 0.0231\n",
            "Epoch: 401, Batch: 2, Loss: 0.0366\n",
            "Epoch: 401, Batch: 3, Loss: 0.0634\n",
            "Epoch: 401, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 402, Batch: 0, Loss: 0.1041\n",
            "Epoch: 402, Batch: 1, Loss: 0.0182\n",
            "Epoch: 402, Batch: 2, Loss: 0.0330\n",
            "Epoch: 402, Batch: 3, Loss: 0.0382\n",
            "Epoch: 402, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 403, Batch: 0, Loss: 0.0283\n",
            "Epoch: 403, Batch: 1, Loss: 0.1069\n",
            "Epoch: 403, Batch: 2, Loss: 0.0283\n",
            "Epoch: 403, Batch: 3, Loss: 0.0368\n",
            "Epoch: 403, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 404, Batch: 0, Loss: 0.0064\n",
            "Epoch: 404, Batch: 1, Loss: 0.1168\n",
            "Epoch: 404, Batch: 2, Loss: 0.0615\n",
            "Epoch: 404, Batch: 3, Loss: 0.0325\n",
            "Epoch: 404, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 405, Batch: 0, Loss: 0.0362\n",
            "Epoch: 405, Batch: 1, Loss: 0.1133\n",
            "Epoch: 405, Batch: 2, Loss: 0.0396\n",
            "Epoch: 405, Batch: 3, Loss: 0.0014\n",
            "Epoch: 405, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 406, Batch: 0, Loss: 0.0368\n",
            "Epoch: 406, Batch: 1, Loss: 0.0322\n",
            "Epoch: 406, Batch: 2, Loss: 0.0106\n",
            "Epoch: 406, Batch: 3, Loss: 0.1307\n",
            "Epoch: 406, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 407, Batch: 0, Loss: 0.0253\n",
            "Epoch: 407, Batch: 1, Loss: 0.0803\n",
            "Epoch: 407, Batch: 2, Loss: 0.0362\n",
            "Epoch: 407, Batch: 3, Loss: 0.0630\n",
            "Epoch: 407, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 408, Batch: 0, Loss: 0.0131\n",
            "Epoch: 408, Batch: 1, Loss: 0.1380\n",
            "Epoch: 408, Batch: 2, Loss: 0.0382\n",
            "Epoch: 408, Batch: 3, Loss: 0.0010\n",
            "Epoch: 408, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 409, Batch: 0, Loss: 0.0254\n",
            "Epoch: 409, Batch: 1, Loss: 0.0234\n",
            "Epoch: 409, Batch: 2, Loss: 0.1133\n",
            "Epoch: 409, Batch: 3, Loss: 0.0201\n",
            "Epoch: 409, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 410, Batch: 0, Loss: 0.0263\n",
            "Epoch: 410, Batch: 1, Loss: 0.0110\n",
            "Epoch: 410, Batch: 2, Loss: 0.1189\n",
            "Epoch: 410, Batch: 3, Loss: 0.0569\n",
            "Epoch: 410, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 411, Batch: 0, Loss: 0.0248\n",
            "Epoch: 411, Batch: 1, Loss: 0.1132\n",
            "Epoch: 411, Batch: 2, Loss: 0.0163\n",
            "Epoch: 411, Batch: 3, Loss: 0.0338\n",
            "Epoch: 411, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 412, Batch: 0, Loss: 0.0327\n",
            "Epoch: 412, Batch: 1, Loss: 0.0193\n",
            "Epoch: 412, Batch: 2, Loss: 0.1320\n",
            "Epoch: 412, Batch: 3, Loss: 0.0123\n",
            "Epoch: 412, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 413, Batch: 0, Loss: 0.0882\n",
            "Epoch: 413, Batch: 1, Loss: 0.0410\n",
            "Epoch: 413, Batch: 2, Loss: 0.0363\n",
            "Epoch: 413, Batch: 3, Loss: 0.0279\n",
            "Epoch: 413, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 414, Batch: 0, Loss: 0.0341\n",
            "Epoch: 414, Batch: 1, Loss: 0.0179\n",
            "Epoch: 414, Batch: 2, Loss: 0.0354\n",
            "Epoch: 414, Batch: 3, Loss: 0.1181\n",
            "Epoch: 414, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 415, Batch: 0, Loss: 0.0458\n",
            "Epoch: 415, Batch: 1, Loss: 0.0205\n",
            "Epoch: 415, Batch: 2, Loss: 0.0305\n",
            "Epoch: 415, Batch: 3, Loss: 0.1489\n",
            "Epoch: 415, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 416, Batch: 0, Loss: 0.0154\n",
            "Epoch: 416, Batch: 1, Loss: 0.0071\n",
            "Epoch: 416, Batch: 2, Loss: 0.0674\n",
            "Epoch: 416, Batch: 3, Loss: 0.1518\n",
            "Epoch: 416, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 417, Batch: 0, Loss: 0.0939\n",
            "Epoch: 417, Batch: 1, Loss: 0.1074\n",
            "Epoch: 417, Batch: 2, Loss: 0.0072\n",
            "Epoch: 417, Batch: 3, Loss: 0.0186\n",
            "Epoch: 417, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 418, Batch: 0, Loss: 0.0194\n",
            "Epoch: 418, Batch: 1, Loss: 0.0490\n",
            "Epoch: 418, Batch: 2, Loss: 0.0979\n",
            "Epoch: 418, Batch: 3, Loss: 0.0343\n",
            "Epoch: 418, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 419, Batch: 0, Loss: 0.1154\n",
            "Epoch: 419, Batch: 1, Loss: 0.0061\n",
            "Epoch: 419, Batch: 2, Loss: 0.0437\n",
            "Epoch: 419, Batch: 3, Loss: 0.0207\n",
            "Epoch: 419, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 420, Batch: 0, Loss: 0.0373\n",
            "Epoch: 420, Batch: 1, Loss: 0.0100\n",
            "Epoch: 420, Batch: 2, Loss: 0.1288\n",
            "Epoch: 420, Batch: 3, Loss: 0.0107\n",
            "Epoch: 420, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 421, Batch: 0, Loss: 0.0616\n",
            "Epoch: 421, Batch: 1, Loss: 0.1147\n",
            "Epoch: 421, Batch: 2, Loss: 0.0212\n",
            "Epoch: 421, Batch: 3, Loss: 0.0031\n",
            "Epoch: 421, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 422, Batch: 0, Loss: 0.1090\n",
            "Epoch: 422, Batch: 1, Loss: 0.0223\n",
            "Epoch: 422, Batch: 2, Loss: 0.0215\n",
            "Epoch: 422, Batch: 3, Loss: 0.0300\n",
            "Epoch: 422, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 423, Batch: 0, Loss: 0.0073\n",
            "Epoch: 423, Batch: 1, Loss: 0.1165\n",
            "Epoch: 423, Batch: 2, Loss: 0.0362\n",
            "Epoch: 423, Batch: 3, Loss: 0.0701\n",
            "Epoch: 423, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 424, Batch: 0, Loss: 0.0943\n",
            "Epoch: 424, Batch: 1, Loss: 0.1059\n",
            "Epoch: 424, Batch: 2, Loss: 0.0071\n",
            "Epoch: 424, Batch: 3, Loss: 0.0037\n",
            "Epoch: 424, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 425, Batch: 0, Loss: 0.0052\n",
            "Epoch: 425, Batch: 1, Loss: 0.1149\n",
            "Epoch: 425, Batch: 2, Loss: 0.0361\n",
            "Epoch: 425, Batch: 3, Loss: 0.0538\n",
            "Epoch: 425, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 426, Batch: 0, Loss: 0.0033\n",
            "Epoch: 426, Batch: 1, Loss: 0.1464\n",
            "Epoch: 426, Batch: 2, Loss: 0.0623\n",
            "Epoch: 426, Batch: 3, Loss: 0.0044\n",
            "Epoch: 426, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 427, Batch: 0, Loss: 0.0592\n",
            "Epoch: 427, Batch: 1, Loss: 0.0076\n",
            "Epoch: 427, Batch: 2, Loss: 0.0058\n",
            "Epoch: 427, Batch: 3, Loss: 0.1380\n",
            "Epoch: 427, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 428, Batch: 0, Loss: 0.0348\n",
            "Epoch: 428, Batch: 1, Loss: 0.1125\n",
            "Epoch: 428, Batch: 2, Loss: 0.0106\n",
            "Epoch: 428, Batch: 3, Loss: 0.0572\n",
            "Epoch: 428, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 429, Batch: 0, Loss: 0.0285\n",
            "Epoch: 429, Batch: 1, Loss: 0.0463\n",
            "Epoch: 429, Batch: 2, Loss: 0.1159\n",
            "Epoch: 429, Batch: 3, Loss: 0.0493\n",
            "Epoch: 429, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 430, Batch: 0, Loss: 0.0329\n",
            "Epoch: 430, Batch: 1, Loss: 0.0256\n",
            "Epoch: 430, Batch: 2, Loss: 0.1144\n",
            "Epoch: 430, Batch: 3, Loss: 0.0456\n",
            "Epoch: 430, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 431, Batch: 0, Loss: 0.0041\n",
            "Epoch: 431, Batch: 1, Loss: 0.0223\n",
            "Epoch: 431, Batch: 2, Loss: 0.1469\n",
            "Epoch: 431, Batch: 3, Loss: 0.0009\n",
            "Epoch: 431, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 432, Batch: 0, Loss: 0.0213\n",
            "Epoch: 432, Batch: 1, Loss: 0.0422\n",
            "Epoch: 432, Batch: 2, Loss: 0.0033\n",
            "Epoch: 432, Batch: 3, Loss: 0.1459\n",
            "Epoch: 432, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 433, Batch: 0, Loss: 0.0252\n",
            "Epoch: 433, Batch: 1, Loss: 0.0337\n",
            "Epoch: 433, Batch: 2, Loss: 0.1400\n",
            "Epoch: 433, Batch: 3, Loss: 0.0230\n",
            "Epoch: 433, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 434, Batch: 0, Loss: 0.0373\n",
            "Epoch: 434, Batch: 1, Loss: 0.0102\n",
            "Epoch: 434, Batch: 2, Loss: 0.0038\n",
            "Epoch: 434, Batch: 3, Loss: 0.1671\n",
            "Epoch: 434, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 435, Batch: 0, Loss: 0.0827\n",
            "Epoch: 435, Batch: 1, Loss: 0.1424\n",
            "Epoch: 435, Batch: 2, Loss: 0.0520\n",
            "Epoch: 435, Batch: 3, Loss: 0.0070\n",
            "Epoch: 435, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 436, Batch: 0, Loss: 0.0319\n",
            "Epoch: 436, Batch: 1, Loss: 0.1045\n",
            "Epoch: 436, Batch: 2, Loss: 0.0678\n",
            "Epoch: 436, Batch: 3, Loss: 0.0057\n",
            "Epoch: 436, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 437, Batch: 0, Loss: 0.0087\n",
            "Epoch: 437, Batch: 1, Loss: 0.1124\n",
            "Epoch: 437, Batch: 2, Loss: 0.0801\n",
            "Epoch: 437, Batch: 3, Loss: 0.0047\n",
            "Epoch: 437, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 438, Batch: 0, Loss: 0.1145\n",
            "Epoch: 438, Batch: 1, Loss: 0.0246\n",
            "Epoch: 438, Batch: 2, Loss: 0.0407\n",
            "Epoch: 438, Batch: 3, Loss: 0.0269\n",
            "Epoch: 438, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 439, Batch: 0, Loss: 0.0051\n",
            "Epoch: 439, Batch: 1, Loss: 0.0132\n",
            "Epoch: 439, Batch: 2, Loss: 0.1793\n",
            "Epoch: 439, Batch: 3, Loss: 0.1017\n",
            "Epoch: 439, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 440, Batch: 0, Loss: 0.1576\n",
            "Epoch: 440, Batch: 1, Loss: 0.0388\n",
            "Epoch: 440, Batch: 2, Loss: 0.0479\n",
            "Epoch: 440, Batch: 3, Loss: 0.0061\n",
            "Epoch: 440, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 441, Batch: 0, Loss: 0.0168\n",
            "Epoch: 441, Batch: 1, Loss: 0.0073\n",
            "Epoch: 441, Batch: 2, Loss: 0.1596\n",
            "Epoch: 441, Batch: 3, Loss: 0.0990\n",
            "Epoch: 441, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 442, Batch: 0, Loss: 0.0102\n",
            "Epoch: 442, Batch: 1, Loss: 0.0257\n",
            "Epoch: 442, Batch: 2, Loss: 0.0142\n",
            "Epoch: 442, Batch: 3, Loss: 0.1791\n",
            "Epoch: 442, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 443, Batch: 0, Loss: 0.0806\n",
            "Epoch: 443, Batch: 1, Loss: 0.0743\n",
            "Epoch: 443, Batch: 2, Loss: 0.0342\n",
            "Epoch: 443, Batch: 3, Loss: 0.0045\n",
            "Epoch: 443, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 444, Batch: 0, Loss: 0.0133\n",
            "Epoch: 444, Batch: 1, Loss: 0.0681\n",
            "Epoch: 444, Batch: 2, Loss: 0.1069\n",
            "Epoch: 444, Batch: 3, Loss: 0.0180\n",
            "Epoch: 444, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 445, Batch: 0, Loss: 0.0988\n",
            "Epoch: 445, Batch: 1, Loss: 0.0360\n",
            "Epoch: 445, Batch: 2, Loss: 0.0352\n",
            "Epoch: 445, Batch: 3, Loss: 0.0236\n",
            "Epoch: 445, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 446, Batch: 0, Loss: 0.0181\n",
            "Epoch: 446, Batch: 1, Loss: 0.0090\n",
            "Epoch: 446, Batch: 2, Loss: 0.2019\n",
            "Epoch: 446, Batch: 3, Loss: 0.0134\n",
            "Epoch: 446, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 447, Batch: 0, Loss: 0.0141\n",
            "Epoch: 447, Batch: 1, Loss: 0.0656\n",
            "Epoch: 447, Batch: 2, Loss: 0.1979\n",
            "Epoch: 447, Batch: 3, Loss: 0.0054\n",
            "Epoch: 447, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 448, Batch: 0, Loss: 0.1279\n",
            "Epoch: 448, Batch: 1, Loss: 0.0055\n",
            "Epoch: 448, Batch: 2, Loss: 0.0224\n",
            "Epoch: 448, Batch: 3, Loss: 0.0656\n",
            "Epoch: 448, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 449, Batch: 0, Loss: 0.0337\n",
            "Epoch: 449, Batch: 1, Loss: 0.1102\n",
            "Epoch: 449, Batch: 2, Loss: 0.0549\n",
            "Epoch: 449, Batch: 3, Loss: 0.0050\n",
            "Epoch: 449, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 450, Batch: 0, Loss: 0.0033\n",
            "Epoch: 450, Batch: 1, Loss: 0.0476\n",
            "Epoch: 450, Batch: 2, Loss: 0.1218\n",
            "Epoch: 450, Batch: 3, Loss: 0.0090\n",
            "Epoch: 450, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 451, Batch: 0, Loss: 0.0917\n",
            "Epoch: 451, Batch: 1, Loss: 0.0645\n",
            "Epoch: 451, Batch: 2, Loss: 0.0239\n",
            "Epoch: 451, Batch: 3, Loss: 0.0049\n",
            "Epoch: 451, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 452, Batch: 0, Loss: 0.0311\n",
            "Epoch: 452, Batch: 1, Loss: 0.1201\n",
            "Epoch: 452, Batch: 2, Loss: 0.0029\n",
            "Epoch: 452, Batch: 3, Loss: 0.0874\n",
            "Epoch: 452, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 453, Batch: 0, Loss: 0.0065\n",
            "Epoch: 453, Batch: 1, Loss: 0.1606\n",
            "Epoch: 453, Batch: 2, Loss: 0.0349\n",
            "Epoch: 453, Batch: 3, Loss: 0.0073\n",
            "Epoch: 453, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 454, Batch: 0, Loss: 0.1096\n",
            "Epoch: 454, Batch: 1, Loss: 0.0273\n",
            "Epoch: 454, Batch: 2, Loss: 0.0672\n",
            "Epoch: 454, Batch: 3, Loss: 0.0045\n",
            "Epoch: 454, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 455, Batch: 0, Loss: 0.0532\n",
            "Epoch: 455, Batch: 1, Loss: 0.0814\n",
            "Epoch: 455, Batch: 2, Loss: 0.1062\n",
            "Epoch: 455, Batch: 3, Loss: 0.0053\n",
            "Epoch: 455, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 456, Batch: 0, Loss: 0.0328\n",
            "Epoch: 456, Batch: 1, Loss: 0.1257\n",
            "Epoch: 456, Batch: 2, Loss: 0.0690\n",
            "Epoch: 456, Batch: 3, Loss: 0.0176\n",
            "Epoch: 456, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 457, Batch: 0, Loss: 0.1278\n",
            "Epoch: 457, Batch: 1, Loss: 0.0171\n",
            "Epoch: 457, Batch: 2, Loss: 0.0449\n",
            "Epoch: 457, Batch: 3, Loss: 0.0108\n",
            "Epoch: 457, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 458, Batch: 0, Loss: 0.0029\n",
            "Epoch: 458, Batch: 1, Loss: 0.0291\n",
            "Epoch: 458, Batch: 2, Loss: 0.1089\n",
            "Epoch: 458, Batch: 3, Loss: 0.1056\n",
            "Epoch: 458, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 459, Batch: 0, Loss: 0.0185\n",
            "Epoch: 459, Batch: 1, Loss: 0.0120\n",
            "Epoch: 459, Batch: 2, Loss: 0.1836\n",
            "Epoch: 459, Batch: 3, Loss: 0.0238\n",
            "Epoch: 459, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 460, Batch: 0, Loss: 0.0614\n",
            "Epoch: 460, Batch: 1, Loss: 0.1744\n",
            "Epoch: 460, Batch: 2, Loss: 0.0017\n",
            "Epoch: 460, Batch: 3, Loss: 0.0577\n",
            "Epoch: 460, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 461, Batch: 0, Loss: 0.0178\n",
            "Epoch: 461, Batch: 1, Loss: 0.1209\n",
            "Epoch: 461, Batch: 2, Loss: 0.0790\n",
            "Epoch: 461, Batch: 3, Loss: 0.0305\n",
            "Epoch: 461, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 462, Batch: 0, Loss: 0.0335\n",
            "Epoch: 462, Batch: 1, Loss: 0.0464\n",
            "Epoch: 462, Batch: 2, Loss: 0.0035\n",
            "Epoch: 462, Batch: 3, Loss: 0.1608\n",
            "Epoch: 462, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 463, Batch: 0, Loss: 0.0163\n",
            "Epoch: 463, Batch: 1, Loss: 0.0890\n",
            "Epoch: 463, Batch: 2, Loss: 0.0698\n",
            "Epoch: 463, Batch: 3, Loss: 0.0255\n",
            "Epoch: 463, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 464, Batch: 0, Loss: 0.0161\n",
            "Epoch: 464, Batch: 1, Loss: 0.1377\n",
            "Epoch: 464, Batch: 2, Loss: 0.0280\n",
            "Epoch: 464, Batch: 3, Loss: 0.0247\n",
            "Epoch: 464, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 465, Batch: 0, Loss: 0.0174\n",
            "Epoch: 465, Batch: 1, Loss: 0.0486\n",
            "Epoch: 465, Batch: 2, Loss: 0.1352\n",
            "Epoch: 465, Batch: 3, Loss: 0.0054\n",
            "Epoch: 465, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 466, Batch: 0, Loss: 0.0255\n",
            "Epoch: 466, Batch: 1, Loss: 0.0524\n",
            "Epoch: 466, Batch: 2, Loss: 0.1149\n",
            "Epoch: 466, Batch: 3, Loss: 0.0018\n",
            "Epoch: 466, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 467, Batch: 0, Loss: 0.0327\n",
            "Epoch: 467, Batch: 1, Loss: 0.0385\n",
            "Epoch: 467, Batch: 2, Loss: 0.0023\n",
            "Epoch: 467, Batch: 3, Loss: 0.1381\n",
            "Epoch: 467, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 468, Batch: 0, Loss: 0.0469\n",
            "Epoch: 468, Batch: 1, Loss: 0.1165\n",
            "Epoch: 468, Batch: 2, Loss: 0.0166\n",
            "Epoch: 468, Batch: 3, Loss: 0.0195\n",
            "Epoch: 468, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 469, Batch: 0, Loss: 0.0992\n",
            "Epoch: 469, Batch: 1, Loss: 0.0226\n",
            "Epoch: 469, Batch: 2, Loss: 0.0412\n",
            "Epoch: 469, Batch: 3, Loss: 0.0229\n",
            "Epoch: 469, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 470, Batch: 0, Loss: 0.0319\n",
            "Epoch: 470, Batch: 1, Loss: 0.0067\n",
            "Epoch: 470, Batch: 2, Loss: 0.1303\n",
            "Epoch: 470, Batch: 3, Loss: 0.0668\n",
            "Epoch: 470, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 471, Batch: 0, Loss: 0.0400\n",
            "Epoch: 471, Batch: 1, Loss: 0.0038\n",
            "Epoch: 471, Batch: 2, Loss: 0.0182\n",
            "Epoch: 471, Batch: 3, Loss: 0.1735\n",
            "Epoch: 471, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 472, Batch: 0, Loss: 0.0041\n",
            "Epoch: 472, Batch: 1, Loss: 0.0917\n",
            "Epoch: 472, Batch: 2, Loss: 0.0113\n",
            "Epoch: 472, Batch: 3, Loss: 0.1499\n",
            "Epoch: 472, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 473, Batch: 0, Loss: 0.1167\n",
            "Epoch: 473, Batch: 1, Loss: 0.0171\n",
            "Epoch: 473, Batch: 2, Loss: 0.0301\n",
            "Epoch: 473, Batch: 3, Loss: 0.0118\n",
            "Epoch: 473, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 474, Batch: 0, Loss: 0.0253\n",
            "Epoch: 474, Batch: 1, Loss: 0.1391\n",
            "Epoch: 474, Batch: 2, Loss: 0.0013\n",
            "Epoch: 474, Batch: 3, Loss: 0.0206\n",
            "Epoch: 474, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 475, Batch: 0, Loss: 0.0411\n",
            "Epoch: 475, Batch: 1, Loss: 0.0032\n",
            "Epoch: 475, Batch: 2, Loss: 0.0157\n",
            "Epoch: 475, Batch: 3, Loss: 0.1625\n",
            "Epoch: 475, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 476, Batch: 0, Loss: 0.0070\n",
            "Epoch: 476, Batch: 1, Loss: 0.0168\n",
            "Epoch: 476, Batch: 2, Loss: 0.1458\n",
            "Epoch: 476, Batch: 3, Loss: 0.0050\n",
            "Epoch: 476, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 477, Batch: 0, Loss: 0.1168\n",
            "Epoch: 477, Batch: 1, Loss: 0.0365\n",
            "Epoch: 477, Batch: 2, Loss: 0.0216\n",
            "Epoch: 477, Batch: 3, Loss: 0.0091\n",
            "Epoch: 477, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 478, Batch: 0, Loss: 0.0271\n",
            "Epoch: 478, Batch: 1, Loss: 0.1013\n",
            "Epoch: 478, Batch: 2, Loss: 0.1054\n",
            "Epoch: 478, Batch: 3, Loss: 0.0033\n",
            "Epoch: 478, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 479, Batch: 0, Loss: 0.0326\n",
            "Epoch: 479, Batch: 1, Loss: 0.0425\n",
            "Epoch: 479, Batch: 2, Loss: 0.1041\n",
            "Epoch: 479, Batch: 3, Loss: 0.0137\n",
            "Epoch: 479, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 480, Batch: 0, Loss: 0.0359\n",
            "Epoch: 480, Batch: 1, Loss: 0.0200\n",
            "Epoch: 480, Batch: 2, Loss: 0.0889\n",
            "Epoch: 480, Batch: 3, Loss: 0.0909\n",
            "Epoch: 480, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 481, Batch: 0, Loss: 0.0048\n",
            "Epoch: 481, Batch: 1, Loss: 0.0062\n",
            "Epoch: 481, Batch: 2, Loss: 0.1979\n",
            "Epoch: 481, Batch: 3, Loss: 0.0038\n",
            "Epoch: 481, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 482, Batch: 0, Loss: 0.0171\n",
            "Epoch: 482, Batch: 1, Loss: 0.0955\n",
            "Epoch: 482, Batch: 2, Loss: 0.0119\n",
            "Epoch: 482, Batch: 3, Loss: 0.0908\n",
            "Epoch: 482, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 483, Batch: 0, Loss: 0.0407\n",
            "Epoch: 483, Batch: 1, Loss: 0.1502\n",
            "Epoch: 483, Batch: 2, Loss: 0.0218\n",
            "Epoch: 483, Batch: 3, Loss: 0.0111\n",
            "Epoch: 483, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 484, Batch: 0, Loss: 0.0403\n",
            "Epoch: 484, Batch: 1, Loss: 0.1029\n",
            "Epoch: 484, Batch: 2, Loss: 0.0276\n",
            "Epoch: 484, Batch: 3, Loss: 0.0247\n",
            "Epoch: 484, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 485, Batch: 0, Loss: 0.0228\n",
            "Epoch: 485, Batch: 1, Loss: 0.1082\n",
            "Epoch: 485, Batch: 2, Loss: 0.0221\n",
            "Epoch: 485, Batch: 3, Loss: 0.0336\n",
            "Epoch: 485, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 486, Batch: 0, Loss: 0.0230\n",
            "Epoch: 486, Batch: 1, Loss: 0.0197\n",
            "Epoch: 486, Batch: 2, Loss: 0.0897\n",
            "Epoch: 486, Batch: 3, Loss: 0.1004\n",
            "Epoch: 486, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 487, Batch: 0, Loss: 0.1639\n",
            "Epoch: 487, Batch: 1, Loss: 0.0422\n",
            "Epoch: 487, Batch: 2, Loss: 0.0150\n",
            "Epoch: 487, Batch: 3, Loss: 0.0036\n",
            "Epoch: 487, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 488, Batch: 0, Loss: 0.0152\n",
            "Epoch: 488, Batch: 1, Loss: 0.0156\n",
            "Epoch: 488, Batch: 2, Loss: 0.1592\n",
            "Epoch: 488, Batch: 3, Loss: 0.0201\n",
            "Epoch: 488, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 489, Batch: 0, Loss: 0.1247\n",
            "Epoch: 489, Batch: 1, Loss: 0.0019\n",
            "Epoch: 489, Batch: 2, Loss: 0.0339\n",
            "Epoch: 489, Batch: 3, Loss: 0.0212\n",
            "Epoch: 489, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 490, Batch: 0, Loss: 0.0071\n",
            "Epoch: 490, Batch: 1, Loss: 0.0086\n",
            "Epoch: 490, Batch: 2, Loss: 0.1262\n",
            "Epoch: 490, Batch: 3, Loss: 0.0561\n",
            "Epoch: 490, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 491, Batch: 0, Loss: 0.1198\n",
            "Epoch: 491, Batch: 1, Loss: 0.0431\n",
            "Epoch: 491, Batch: 2, Loss: 0.0075\n",
            "Epoch: 491, Batch: 3, Loss: 0.0080\n",
            "Epoch: 491, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 492, Batch: 0, Loss: 0.0940\n",
            "Epoch: 492, Batch: 1, Loss: 0.0630\n",
            "Epoch: 492, Batch: 2, Loss: 0.0160\n",
            "Epoch: 492, Batch: 3, Loss: 0.0268\n",
            "Epoch: 492, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 493, Batch: 0, Loss: 0.0094\n",
            "Epoch: 493, Batch: 1, Loss: 0.0210\n",
            "Epoch: 493, Batch: 2, Loss: 0.1377\n",
            "Epoch: 493, Batch: 3, Loss: 0.0071\n",
            "Epoch: 493, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 494, Batch: 0, Loss: 0.0024\n",
            "Epoch: 494, Batch: 1, Loss: 0.1030\n",
            "Epoch: 494, Batch: 2, Loss: 0.1113\n",
            "Epoch: 494, Batch: 3, Loss: 0.0689\n",
            "Epoch: 494, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 495, Batch: 0, Loss: 0.0048\n",
            "Epoch: 495, Batch: 1, Loss: 0.1152\n",
            "Epoch: 495, Batch: 2, Loss: 0.0229\n",
            "Epoch: 495, Batch: 3, Loss: 0.0520\n",
            "Epoch: 495, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 496, Batch: 0, Loss: 0.0049\n",
            "Epoch: 496, Batch: 1, Loss: 0.1341\n",
            "Epoch: 496, Batch: 2, Loss: 0.0305\n",
            "Epoch: 496, Batch: 3, Loss: 0.0227\n",
            "Epoch: 496, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 497, Batch: 0, Loss: 0.1248\n",
            "Epoch: 497, Batch: 1, Loss: 0.0504\n",
            "Epoch: 497, Batch: 2, Loss: 0.0034\n",
            "Epoch: 497, Batch: 3, Loss: 0.0054\n",
            "Epoch: 497, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 498, Batch: 0, Loss: 0.0217\n",
            "Epoch: 498, Batch: 1, Loss: 0.0187\n",
            "Epoch: 498, Batch: 2, Loss: 0.1236\n",
            "Epoch: 498, Batch: 3, Loss: 0.0229\n",
            "Epoch: 498, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 499, Batch: 0, Loss: 0.1074\n",
            "Epoch: 499, Batch: 1, Loss: 0.0065\n",
            "Epoch: 499, Batch: 2, Loss: 0.0058\n",
            "Epoch: 499, Batch: 3, Loss: 0.0884\n",
            "Epoch: 499, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 500, Batch: 0, Loss: 0.1660\n",
            "Epoch: 500, Batch: 1, Loss: 0.0157\n",
            "Epoch: 500, Batch: 2, Loss: 0.0380\n",
            "Epoch: 500, Batch: 3, Loss: 0.0098\n",
            "Epoch: 500, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 501, Batch: 0, Loss: 0.0169\n",
            "Epoch: 501, Batch: 1, Loss: 0.0544\n",
            "Epoch: 501, Batch: 2, Loss: 0.0242\n",
            "Epoch: 501, Batch: 3, Loss: 0.1451\n",
            "Epoch: 501, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 502, Batch: 0, Loss: 0.0986\n",
            "Epoch: 502, Batch: 1, Loss: 0.0189\n",
            "Epoch: 502, Batch: 2, Loss: 0.0189\n",
            "Epoch: 502, Batch: 3, Loss: 0.0534\n",
            "Epoch: 502, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 503, Batch: 0, Loss: 0.0484\n",
            "Epoch: 503, Batch: 1, Loss: 0.0097\n",
            "Epoch: 503, Batch: 2, Loss: 0.1084\n",
            "Epoch: 503, Batch: 3, Loss: 0.0285\n",
            "Epoch: 503, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 504, Batch: 0, Loss: 0.0036\n",
            "Epoch: 504, Batch: 1, Loss: 0.0329\n",
            "Epoch: 504, Batch: 2, Loss: 0.1316\n",
            "Epoch: 504, Batch: 3, Loss: 0.0084\n",
            "Epoch: 504, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 505, Batch: 0, Loss: 0.1012\n",
            "Epoch: 505, Batch: 1, Loss: 0.0681\n",
            "Epoch: 505, Batch: 2, Loss: 0.0285\n",
            "Epoch: 505, Batch: 3, Loss: 0.0078\n",
            "Epoch: 505, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 506, Batch: 0, Loss: 0.1174\n",
            "Epoch: 506, Batch: 1, Loss: 0.0113\n",
            "Epoch: 506, Batch: 2, Loss: 0.0233\n",
            "Epoch: 506, Batch: 3, Loss: 0.0535\n",
            "Epoch: 506, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 507, Batch: 0, Loss: 0.0916\n",
            "Epoch: 507, Batch: 1, Loss: 0.0262\n",
            "Epoch: 507, Batch: 2, Loss: 0.0580\n",
            "Epoch: 507, Batch: 3, Loss: 0.0045\n",
            "Epoch: 507, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 508, Batch: 0, Loss: 0.0362\n",
            "Epoch: 508, Batch: 1, Loss: 0.0402\n",
            "Epoch: 508, Batch: 2, Loss: 0.0073\n",
            "Epoch: 508, Batch: 3, Loss: 0.1373\n",
            "Epoch: 508, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 509, Batch: 0, Loss: 0.0430\n",
            "Epoch: 509, Batch: 1, Loss: 0.0897\n",
            "Epoch: 509, Batch: 2, Loss: 0.0723\n",
            "Epoch: 509, Batch: 3, Loss: 0.0067\n",
            "Epoch: 509, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 510, Batch: 0, Loss: 0.0258\n",
            "Epoch: 510, Batch: 1, Loss: 0.0182\n",
            "Epoch: 510, Batch: 2, Loss: 0.0189\n",
            "Epoch: 510, Batch: 3, Loss: 0.1587\n",
            "Epoch: 510, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 511, Batch: 0, Loss: 0.0211\n",
            "Epoch: 511, Batch: 1, Loss: 0.1064\n",
            "Epoch: 511, Batch: 2, Loss: 0.0104\n",
            "Epoch: 511, Batch: 3, Loss: 0.0637\n",
            "Epoch: 511, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 512, Batch: 0, Loss: 0.0183\n",
            "Epoch: 512, Batch: 1, Loss: 0.0932\n",
            "Epoch: 512, Batch: 2, Loss: 0.0477\n",
            "Epoch: 512, Batch: 3, Loss: 0.0403\n",
            "Epoch: 512, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 513, Batch: 0, Loss: 0.0430\n",
            "Epoch: 513, Batch: 1, Loss: 0.0094\n",
            "Epoch: 513, Batch: 2, Loss: 0.0287\n",
            "Epoch: 513, Batch: 3, Loss: 0.1455\n",
            "Epoch: 513, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 514, Batch: 0, Loss: 0.1004\n",
            "Epoch: 514, Batch: 1, Loss: 0.0093\n",
            "Epoch: 514, Batch: 2, Loss: 0.0367\n",
            "Epoch: 514, Batch: 3, Loss: 0.0349\n",
            "Epoch: 514, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 515, Batch: 0, Loss: 0.1286\n",
            "Epoch: 515, Batch: 1, Loss: 0.0044\n",
            "Epoch: 515, Batch: 2, Loss: 0.0266\n",
            "Epoch: 515, Batch: 3, Loss: 0.0228\n",
            "Epoch: 515, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 516, Batch: 0, Loss: 0.0204\n",
            "Epoch: 516, Batch: 1, Loss: 0.1202\n",
            "Epoch: 516, Batch: 2, Loss: 0.0307\n",
            "Epoch: 516, Batch: 3, Loss: 0.0116\n",
            "Epoch: 516, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 517, Batch: 0, Loss: 0.1186\n",
            "Epoch: 517, Batch: 1, Loss: 0.0334\n",
            "Epoch: 517, Batch: 2, Loss: 0.0249\n",
            "Epoch: 517, Batch: 3, Loss: 0.0219\n",
            "Epoch: 517, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 518, Batch: 0, Loss: 0.0268\n",
            "Epoch: 518, Batch: 1, Loss: 0.0062\n",
            "Epoch: 518, Batch: 2, Loss: 0.0550\n",
            "Epoch: 518, Batch: 3, Loss: 0.1564\n",
            "Epoch: 518, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 519, Batch: 0, Loss: 0.0362\n",
            "Epoch: 519, Batch: 1, Loss: 0.0038\n",
            "Epoch: 519, Batch: 2, Loss: 0.0247\n",
            "Epoch: 519, Batch: 3, Loss: 0.1443\n",
            "Epoch: 519, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 520, Batch: 0, Loss: 0.0895\n",
            "Epoch: 520, Batch: 1, Loss: 0.0761\n",
            "Epoch: 520, Batch: 2, Loss: 0.0229\n",
            "Epoch: 520, Batch: 3, Loss: 0.0063\n",
            "Epoch: 520, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 521, Batch: 0, Loss: 0.0118\n",
            "Epoch: 521, Batch: 1, Loss: 0.0335\n",
            "Epoch: 521, Batch: 2, Loss: 0.0050\n",
            "Epoch: 521, Batch: 3, Loss: 0.1732\n",
            "Epoch: 521, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 522, Batch: 0, Loss: 0.0665\n",
            "Epoch: 522, Batch: 1, Loss: 0.1172\n",
            "Epoch: 522, Batch: 2, Loss: 0.0189\n",
            "Epoch: 522, Batch: 3, Loss: 0.0090\n",
            "Epoch: 522, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 523, Batch: 0, Loss: 0.1146\n",
            "Epoch: 523, Batch: 1, Loss: 0.0068\n",
            "Epoch: 523, Batch: 2, Loss: 0.0391\n",
            "Epoch: 523, Batch: 3, Loss: 0.0468\n",
            "Epoch: 523, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 524, Batch: 0, Loss: 0.0046\n",
            "Epoch: 524, Batch: 1, Loss: 0.1402\n",
            "Epoch: 524, Batch: 2, Loss: 0.0512\n",
            "Epoch: 524, Batch: 3, Loss: 0.0066\n",
            "Epoch: 524, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 525, Batch: 0, Loss: 0.0223\n",
            "Epoch: 525, Batch: 1, Loss: 0.0313\n",
            "Epoch: 525, Batch: 2, Loss: 0.0307\n",
            "Epoch: 525, Batch: 3, Loss: 0.1238\n",
            "Epoch: 525, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 526, Batch: 0, Loss: 0.0313\n",
            "Epoch: 526, Batch: 1, Loss: 0.0062\n",
            "Epoch: 526, Batch: 2, Loss: 0.1098\n",
            "Epoch: 526, Batch: 3, Loss: 0.0386\n",
            "Epoch: 526, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 527, Batch: 0, Loss: 0.1436\n",
            "Epoch: 527, Batch: 1, Loss: 0.0405\n",
            "Epoch: 527, Batch: 2, Loss: 0.0100\n",
            "Epoch: 527, Batch: 3, Loss: 0.0246\n",
            "Epoch: 527, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 528, Batch: 0, Loss: 0.0023\n",
            "Epoch: 528, Batch: 1, Loss: 0.0118\n",
            "Epoch: 528, Batch: 2, Loss: 0.0503\n",
            "Epoch: 528, Batch: 3, Loss: 0.1789\n",
            "Epoch: 528, Training Accuracy: 97.52%, Validation Accuracy: 92.86%\n",
            "Epoch: 529, Batch: 0, Loss: 0.0119\n",
            "Epoch: 529, Batch: 1, Loss: 0.0797\n",
            "Epoch: 529, Batch: 2, Loss: 0.1321\n",
            "Epoch: 529, Batch: 3, Loss: 0.0503\n",
            "Epoch: 529, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 530, Batch: 0, Loss: 0.0085\n",
            "Epoch: 530, Batch: 1, Loss: 0.1199\n",
            "Epoch: 530, Batch: 2, Loss: 0.0233\n",
            "Epoch: 530, Batch: 3, Loss: 0.0511\n",
            "Epoch: 530, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 531, Batch: 0, Loss: 0.0137\n",
            "Epoch: 531, Batch: 1, Loss: 0.0037\n",
            "Epoch: 531, Batch: 2, Loss: 0.0406\n",
            "Epoch: 531, Batch: 3, Loss: 0.1712\n",
            "Epoch: 531, Training Accuracy: 97.52%, Validation Accuracy: 92.86%\n",
            "Epoch: 532, Batch: 0, Loss: 0.0905\n",
            "Epoch: 532, Batch: 1, Loss: 0.0209\n",
            "Epoch: 532, Batch: 2, Loss: 0.0077\n",
            "Epoch: 532, Batch: 3, Loss: 0.0687\n",
            "Epoch: 532, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 533, Batch: 0, Loss: 0.1648\n",
            "Epoch: 533, Batch: 1, Loss: 0.0579\n",
            "Epoch: 533, Batch: 2, Loss: 0.0153\n",
            "Epoch: 533, Batch: 3, Loss: 0.0038\n",
            "Epoch: 533, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 534, Batch: 0, Loss: 0.1408\n",
            "Epoch: 534, Batch: 1, Loss: 0.0505\n",
            "Epoch: 534, Batch: 2, Loss: 0.0104\n",
            "Epoch: 534, Batch: 3, Loss: 0.0012\n",
            "Epoch: 534, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 535, Batch: 0, Loss: 0.0251\n",
            "Epoch: 535, Batch: 1, Loss: 0.0361\n",
            "Epoch: 535, Batch: 2, Loss: 0.1222\n",
            "Epoch: 535, Batch: 3, Loss: 0.0199\n",
            "Epoch: 535, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 536, Batch: 0, Loss: 0.0286\n",
            "Epoch: 536, Batch: 1, Loss: 0.1146\n",
            "Epoch: 536, Batch: 2, Loss: 0.0078\n",
            "Epoch: 536, Batch: 3, Loss: 0.0276\n",
            "Epoch: 536, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 537, Batch: 0, Loss: 0.0046\n",
            "Epoch: 537, Batch: 1, Loss: 0.0411\n",
            "Epoch: 537, Batch: 2, Loss: 0.0101\n",
            "Epoch: 537, Batch: 3, Loss: 0.1883\n",
            "Epoch: 537, Training Accuracy: 97.52%, Validation Accuracy: 92.86%\n",
            "Epoch: 538, Batch: 0, Loss: 0.0866\n",
            "Epoch: 538, Batch: 1, Loss: 0.0316\n",
            "Epoch: 538, Batch: 2, Loss: 0.0054\n",
            "Epoch: 538, Batch: 3, Loss: 0.1471\n",
            "Epoch: 538, Training Accuracy: 97.52%, Validation Accuracy: 92.86%\n",
            "Epoch: 539, Batch: 0, Loss: 0.0264\n",
            "Epoch: 539, Batch: 1, Loss: 0.0608\n",
            "Epoch: 539, Batch: 2, Loss: 0.1177\n",
            "Epoch: 539, Batch: 3, Loss: 0.0027\n",
            "Epoch: 539, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 540, Batch: 0, Loss: 0.0148\n",
            "Epoch: 540, Batch: 1, Loss: 0.0189\n",
            "Epoch: 540, Batch: 2, Loss: 0.1453\n",
            "Epoch: 540, Batch: 3, Loss: 0.0816\n",
            "Epoch: 540, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 541, Batch: 0, Loss: 0.0199\n",
            "Epoch: 541, Batch: 1, Loss: 0.0096\n",
            "Epoch: 541, Batch: 2, Loss: 0.1304\n",
            "Epoch: 541, Batch: 3, Loss: 0.0178\n",
            "Epoch: 541, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 542, Batch: 0, Loss: 0.0091\n",
            "Epoch: 542, Batch: 1, Loss: 0.1022\n",
            "Epoch: 542, Batch: 2, Loss: 0.1141\n",
            "Epoch: 542, Batch: 3, Loss: 0.0189\n",
            "Epoch: 542, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 543, Batch: 0, Loss: 0.0105\n",
            "Epoch: 543, Batch: 1, Loss: 0.0094\n",
            "Epoch: 543, Batch: 2, Loss: 0.0500\n",
            "Epoch: 543, Batch: 3, Loss: 0.1475\n",
            "Epoch: 543, Training Accuracy: 97.52%, Validation Accuracy: 92.86%\n",
            "Epoch: 544, Batch: 0, Loss: 0.0331\n",
            "Epoch: 544, Batch: 1, Loss: 0.0214\n",
            "Epoch: 544, Batch: 2, Loss: 0.1157\n",
            "Epoch: 544, Batch: 3, Loss: 0.0669\n",
            "Epoch: 544, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 545, Batch: 0, Loss: 0.0189\n",
            "Epoch: 545, Batch: 1, Loss: 0.0070\n",
            "Epoch: 545, Batch: 2, Loss: 0.0079\n",
            "Epoch: 545, Batch: 3, Loss: 0.2472\n",
            "Epoch: 545, Training Accuracy: 94.21%, Validation Accuracy: 92.86%\n",
            "Epoch: 546, Batch: 0, Loss: 0.1786\n",
            "Epoch: 546, Batch: 1, Loss: 0.1125\n",
            "Epoch: 546, Batch: 2, Loss: 0.0349\n",
            "Epoch: 546, Batch: 3, Loss: 0.0107\n",
            "Epoch: 546, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 547, Batch: 0, Loss: 0.0211\n",
            "Epoch: 547, Batch: 1, Loss: 0.0319\n",
            "Epoch: 547, Batch: 2, Loss: 0.1105\n",
            "Epoch: 547, Batch: 3, Loss: 0.0733\n",
            "Epoch: 547, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 548, Batch: 0, Loss: 0.1190\n",
            "Epoch: 548, Batch: 1, Loss: 0.0232\n",
            "Epoch: 548, Batch: 2, Loss: 0.0386\n",
            "Epoch: 548, Batch: 3, Loss: 0.0052\n",
            "Epoch: 548, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 549, Batch: 0, Loss: 0.0084\n",
            "Epoch: 549, Batch: 1, Loss: 0.1106\n",
            "Epoch: 549, Batch: 2, Loss: 0.0180\n",
            "Epoch: 549, Batch: 3, Loss: 0.0559\n",
            "Epoch: 549, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 550, Batch: 0, Loss: 0.0032\n",
            "Epoch: 550, Batch: 1, Loss: 0.0045\n",
            "Epoch: 550, Batch: 2, Loss: 0.0192\n",
            "Epoch: 550, Batch: 3, Loss: 0.2131\n",
            "Epoch: 550, Training Accuracy: 97.52%, Validation Accuracy: 92.86%\n",
            "Epoch: 551, Batch: 0, Loss: 0.0487\n",
            "Epoch: 551, Batch: 1, Loss: 0.0832\n",
            "Epoch: 551, Batch: 2, Loss: 0.0629\n",
            "Epoch: 551, Batch: 3, Loss: 0.0457\n",
            "Epoch: 551, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 552, Batch: 0, Loss: 0.0063\n",
            "Epoch: 552, Batch: 1, Loss: 0.0322\n",
            "Epoch: 552, Batch: 2, Loss: 0.1136\n",
            "Epoch: 552, Batch: 3, Loss: 0.0295\n",
            "Epoch: 552, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 553, Batch: 0, Loss: 0.0855\n",
            "Epoch: 553, Batch: 1, Loss: 0.0111\n",
            "Epoch: 553, Batch: 2, Loss: 0.0413\n",
            "Epoch: 553, Batch: 3, Loss: 0.0565\n",
            "Epoch: 553, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 554, Batch: 0, Loss: 0.1284\n",
            "Epoch: 554, Batch: 1, Loss: 0.0085\n",
            "Epoch: 554, Batch: 2, Loss: 0.0078\n",
            "Epoch: 554, Batch: 3, Loss: 0.0605\n",
            "Epoch: 554, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 555, Batch: 0, Loss: 0.0353\n",
            "Epoch: 555, Batch: 1, Loss: 0.1447\n",
            "Epoch: 555, Batch: 2, Loss: 0.0110\n",
            "Epoch: 555, Batch: 3, Loss: 0.0311\n",
            "Epoch: 555, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 556, Batch: 0, Loss: 0.1191\n",
            "Epoch: 556, Batch: 1, Loss: 0.0300\n",
            "Epoch: 556, Batch: 2, Loss: 0.0250\n",
            "Epoch: 556, Batch: 3, Loss: 0.0190\n",
            "Epoch: 556, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 557, Batch: 0, Loss: 0.0318\n",
            "Epoch: 557, Batch: 1, Loss: 0.0236\n",
            "Epoch: 557, Batch: 2, Loss: 0.0319\n",
            "Epoch: 557, Batch: 3, Loss: 0.1325\n",
            "Epoch: 557, Training Accuracy: 97.52%, Validation Accuracy: 92.86%\n",
            "Epoch: 558, Batch: 0, Loss: 0.0232\n",
            "Epoch: 558, Batch: 1, Loss: 0.1377\n",
            "Epoch: 558, Batch: 2, Loss: 0.0149\n",
            "Epoch: 558, Batch: 3, Loss: 0.0269\n",
            "Epoch: 558, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 559, Batch: 0, Loss: 0.0299\n",
            "Epoch: 559, Batch: 1, Loss: 0.0394\n",
            "Epoch: 559, Batch: 2, Loss: 0.0211\n",
            "Epoch: 559, Batch: 3, Loss: 0.1144\n",
            "Epoch: 559, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 560, Batch: 0, Loss: 0.0151\n",
            "Epoch: 560, Batch: 1, Loss: 0.0867\n",
            "Epoch: 560, Batch: 2, Loss: 0.1307\n",
            "Epoch: 560, Batch: 3, Loss: 0.0139\n",
            "Epoch: 560, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 561, Batch: 0, Loss: 0.0199\n",
            "Epoch: 561, Batch: 1, Loss: 0.1006\n",
            "Epoch: 561, Batch: 2, Loss: 0.0318\n",
            "Epoch: 561, Batch: 3, Loss: 0.0523\n",
            "Epoch: 561, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 562, Batch: 0, Loss: 0.0099\n",
            "Epoch: 562, Batch: 1, Loss: 0.1534\n",
            "Epoch: 562, Batch: 2, Loss: 0.0132\n",
            "Epoch: 562, Batch: 3, Loss: 0.0011\n",
            "Epoch: 562, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 563, Batch: 0, Loss: 0.0972\n",
            "Epoch: 563, Batch: 1, Loss: 0.0792\n",
            "Epoch: 563, Batch: 2, Loss: 0.0083\n",
            "Epoch: 563, Batch: 3, Loss: 0.0221\n",
            "Epoch: 563, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 564, Batch: 0, Loss: 0.0178\n",
            "Epoch: 564, Batch: 1, Loss: 0.0052\n",
            "Epoch: 564, Batch: 2, Loss: 0.1178\n",
            "Epoch: 564, Batch: 3, Loss: 0.0690\n",
            "Epoch: 564, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 565, Batch: 0, Loss: 0.1291\n",
            "Epoch: 565, Batch: 1, Loss: 0.0171\n",
            "Epoch: 565, Batch: 2, Loss: 0.0201\n",
            "Epoch: 565, Batch: 3, Loss: 0.0097\n",
            "Epoch: 565, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 566, Batch: 0, Loss: 0.1017\n",
            "Epoch: 566, Batch: 1, Loss: 0.0747\n",
            "Epoch: 566, Batch: 2, Loss: 0.0211\n",
            "Epoch: 566, Batch: 3, Loss: 0.0090\n",
            "Epoch: 566, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 567, Batch: 0, Loss: 0.0338\n",
            "Epoch: 567, Batch: 1, Loss: 0.1045\n",
            "Epoch: 567, Batch: 2, Loss: 0.0510\n",
            "Epoch: 567, Batch: 3, Loss: 0.0070\n",
            "Epoch: 567, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 568, Batch: 0, Loss: 0.1618\n",
            "Epoch: 568, Batch: 1, Loss: 0.0088\n",
            "Epoch: 568, Batch: 2, Loss: 0.0112\n",
            "Epoch: 568, Batch: 3, Loss: 0.0122\n",
            "Epoch: 568, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 569, Batch: 0, Loss: 0.0070\n",
            "Epoch: 569, Batch: 1, Loss: 0.0183\n",
            "Epoch: 569, Batch: 2, Loss: 0.1300\n",
            "Epoch: 569, Batch: 3, Loss: 0.0561\n",
            "Epoch: 569, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 570, Batch: 0, Loss: 0.0435\n",
            "Epoch: 570, Batch: 1, Loss: 0.1277\n",
            "Epoch: 570, Batch: 2, Loss: 0.0153\n",
            "Epoch: 570, Batch: 3, Loss: 0.0159\n",
            "Epoch: 570, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 571, Batch: 0, Loss: 0.0364\n",
            "Epoch: 571, Batch: 1, Loss: 0.0236\n",
            "Epoch: 571, Batch: 2, Loss: 0.0252\n",
            "Epoch: 571, Batch: 3, Loss: 0.1331\n",
            "Epoch: 571, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 572, Batch: 0, Loss: 0.0128\n",
            "Epoch: 572, Batch: 1, Loss: 0.0441\n",
            "Epoch: 572, Batch: 2, Loss: 0.0280\n",
            "Epoch: 572, Batch: 3, Loss: 0.1382\n",
            "Epoch: 572, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 573, Batch: 0, Loss: 0.0994\n",
            "Epoch: 573, Batch: 1, Loss: 0.0404\n",
            "Epoch: 573, Batch: 2, Loss: 0.0276\n",
            "Epoch: 573, Batch: 3, Loss: 0.0241\n",
            "Epoch: 573, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 574, Batch: 0, Loss: 0.0157\n",
            "Epoch: 574, Batch: 1, Loss: 0.0242\n",
            "Epoch: 574, Batch: 2, Loss: 0.1019\n",
            "Epoch: 574, Batch: 3, Loss: 0.0771\n",
            "Epoch: 574, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 575, Batch: 0, Loss: 0.0276\n",
            "Epoch: 575, Batch: 1, Loss: 0.0144\n",
            "Epoch: 575, Batch: 2, Loss: 0.1392\n",
            "Epoch: 575, Batch: 3, Loss: 0.0069\n",
            "Epoch: 575, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 576, Batch: 0, Loss: 0.0243\n",
            "Epoch: 576, Batch: 1, Loss: 0.0154\n",
            "Epoch: 576, Batch: 2, Loss: 0.1359\n",
            "Epoch: 576, Batch: 3, Loss: 0.0236\n",
            "Epoch: 576, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 577, Batch: 0, Loss: 0.0260\n",
            "Epoch: 577, Batch: 1, Loss: 0.0070\n",
            "Epoch: 577, Batch: 2, Loss: 0.1429\n",
            "Epoch: 577, Batch: 3, Loss: 0.0082\n",
            "Epoch: 577, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 578, Batch: 0, Loss: 0.0401\n",
            "Epoch: 578, Batch: 1, Loss: 0.0145\n",
            "Epoch: 578, Batch: 2, Loss: 0.1185\n",
            "Epoch: 578, Batch: 3, Loss: 0.0143\n",
            "Epoch: 578, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 579, Batch: 0, Loss: 0.0434\n",
            "Epoch: 579, Batch: 1, Loss: 0.0221\n",
            "Epoch: 579, Batch: 2, Loss: 0.0327\n",
            "Epoch: 579, Batch: 3, Loss: 0.1274\n",
            "Epoch: 579, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 580, Batch: 0, Loss: 0.0309\n",
            "Epoch: 580, Batch: 1, Loss: 0.0063\n",
            "Epoch: 580, Batch: 2, Loss: 0.1199\n",
            "Epoch: 580, Batch: 3, Loss: 0.0283\n",
            "Epoch: 580, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 581, Batch: 0, Loss: 0.0088\n",
            "Epoch: 581, Batch: 1, Loss: 0.1212\n",
            "Epoch: 581, Batch: 2, Loss: 0.0945\n",
            "Epoch: 581, Batch: 3, Loss: 0.0344\n",
            "Epoch: 581, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 582, Batch: 0, Loss: 0.1330\n",
            "Epoch: 582, Batch: 1, Loss: 0.0136\n",
            "Epoch: 582, Batch: 2, Loss: 0.0240\n",
            "Epoch: 582, Batch: 3, Loss: 0.0221\n",
            "Epoch: 582, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 583, Batch: 0, Loss: 0.0054\n",
            "Epoch: 583, Batch: 1, Loss: 0.0086\n",
            "Epoch: 583, Batch: 2, Loss: 0.1389\n",
            "Epoch: 583, Batch: 3, Loss: 0.0370\n",
            "Epoch: 583, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 584, Batch: 0, Loss: 0.0923\n",
            "Epoch: 584, Batch: 1, Loss: 0.0486\n",
            "Epoch: 584, Batch: 2, Loss: 0.0282\n",
            "Epoch: 584, Batch: 3, Loss: 0.0255\n",
            "Epoch: 584, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 585, Batch: 0, Loss: 0.0287\n",
            "Epoch: 585, Batch: 1, Loss: 0.0231\n",
            "Epoch: 585, Batch: 2, Loss: 0.1083\n",
            "Epoch: 585, Batch: 3, Loss: 0.0318\n",
            "Epoch: 585, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 586, Batch: 0, Loss: 0.0507\n",
            "Epoch: 586, Batch: 1, Loss: 0.0085\n",
            "Epoch: 586, Batch: 2, Loss: 0.1121\n",
            "Epoch: 586, Batch: 3, Loss: 0.0133\n",
            "Epoch: 586, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 587, Batch: 0, Loss: 0.0352\n",
            "Epoch: 587, Batch: 1, Loss: 0.0254\n",
            "Epoch: 587, Batch: 2, Loss: 0.0209\n",
            "Epoch: 587, Batch: 3, Loss: 0.1557\n",
            "Epoch: 587, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 588, Batch: 0, Loss: 0.0688\n",
            "Epoch: 588, Batch: 1, Loss: 0.1058\n",
            "Epoch: 588, Batch: 2, Loss: 0.0122\n",
            "Epoch: 588, Batch: 3, Loss: 0.0229\n",
            "Epoch: 588, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 589, Batch: 0, Loss: 0.0101\n",
            "Epoch: 589, Batch: 1, Loss: 0.0043\n",
            "Epoch: 589, Batch: 2, Loss: 0.1332\n",
            "Epoch: 589, Batch: 3, Loss: 0.0609\n",
            "Epoch: 589, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 590, Batch: 0, Loss: 0.1166\n",
            "Epoch: 590, Batch: 1, Loss: 0.0436\n",
            "Epoch: 590, Batch: 2, Loss: 0.0070\n",
            "Epoch: 590, Batch: 3, Loss: 0.0123\n",
            "Epoch: 590, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 591, Batch: 0, Loss: 0.0096\n",
            "Epoch: 591, Batch: 1, Loss: 0.1321\n",
            "Epoch: 591, Batch: 2, Loss: 0.0060\n",
            "Epoch: 591, Batch: 3, Loss: 0.0610\n",
            "Epoch: 591, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 592, Batch: 0, Loss: 0.0149\n",
            "Epoch: 592, Batch: 1, Loss: 0.0233\n",
            "Epoch: 592, Batch: 2, Loss: 0.1351\n",
            "Epoch: 592, Batch: 3, Loss: 0.0111\n",
            "Epoch: 592, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 593, Batch: 0, Loss: 0.0042\n",
            "Epoch: 593, Batch: 1, Loss: 0.0372\n",
            "Epoch: 593, Batch: 2, Loss: 0.0314\n",
            "Epoch: 593, Batch: 3, Loss: 0.1542\n",
            "Epoch: 593, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 594, Batch: 0, Loss: 0.0656\n",
            "Epoch: 594, Batch: 1, Loss: 0.0247\n",
            "Epoch: 594, Batch: 2, Loss: 0.1266\n",
            "Epoch: 594, Batch: 3, Loss: 0.0086\n",
            "Epoch: 594, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 595, Batch: 0, Loss: 0.0584\n",
            "Epoch: 595, Batch: 1, Loss: 0.1333\n",
            "Epoch: 595, Batch: 2, Loss: 0.0111\n",
            "Epoch: 595, Batch: 3, Loss: 0.0690\n",
            "Epoch: 595, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 596, Batch: 0, Loss: 0.0381\n",
            "Epoch: 596, Batch: 1, Loss: 0.0060\n",
            "Epoch: 596, Batch: 2, Loss: 0.0104\n",
            "Epoch: 596, Batch: 3, Loss: 0.1663\n",
            "Epoch: 596, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 597, Batch: 0, Loss: 0.0517\n",
            "Epoch: 597, Batch: 1, Loss: 0.0221\n",
            "Epoch: 597, Batch: 2, Loss: 0.0940\n",
            "Epoch: 597, Batch: 3, Loss: 0.0391\n",
            "Epoch: 597, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 598, Batch: 0, Loss: 0.0992\n",
            "Epoch: 598, Batch: 1, Loss: 0.0399\n",
            "Epoch: 598, Batch: 2, Loss: 0.0063\n",
            "Epoch: 598, Batch: 3, Loss: 0.0477\n",
            "Epoch: 598, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 599, Batch: 0, Loss: 0.0164\n",
            "Epoch: 599, Batch: 1, Loss: 0.0285\n",
            "Epoch: 599, Batch: 2, Loss: 0.1299\n",
            "Epoch: 599, Batch: 3, Loss: 0.0095\n",
            "Epoch: 599, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 600, Batch: 0, Loss: 0.0281\n",
            "Epoch: 600, Batch: 1, Loss: 0.1133\n",
            "Epoch: 600, Batch: 2, Loss: 0.0316\n",
            "Epoch: 600, Batch: 3, Loss: 0.0050\n",
            "Epoch: 600, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 601, Batch: 0, Loss: 0.0114\n",
            "Epoch: 601, Batch: 1, Loss: 0.0199\n",
            "Epoch: 601, Batch: 2, Loss: 0.1256\n",
            "Epoch: 601, Batch: 3, Loss: 0.0325\n",
            "Epoch: 601, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 602, Batch: 0, Loss: 0.0185\n",
            "Epoch: 602, Batch: 1, Loss: 0.1137\n",
            "Epoch: 602, Batch: 2, Loss: 0.0341\n",
            "Epoch: 602, Batch: 3, Loss: 0.0100\n",
            "Epoch: 602, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 603, Batch: 0, Loss: 0.1114\n",
            "Epoch: 603, Batch: 1, Loss: 0.0142\n",
            "Epoch: 603, Batch: 2, Loss: 0.0390\n",
            "Epoch: 603, Batch: 3, Loss: 0.0237\n",
            "Epoch: 603, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 604, Batch: 0, Loss: 0.0179\n",
            "Epoch: 604, Batch: 1, Loss: 0.0919\n",
            "Epoch: 604, Batch: 2, Loss: 0.1232\n",
            "Epoch: 604, Batch: 3, Loss: 0.0062\n",
            "Epoch: 604, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 605, Batch: 0, Loss: 0.0133\n",
            "Epoch: 605, Batch: 1, Loss: 0.0365\n",
            "Epoch: 605, Batch: 2, Loss: 0.0176\n",
            "Epoch: 605, Batch: 3, Loss: 0.1814\n",
            "Epoch: 605, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 606, Batch: 0, Loss: 0.1258\n",
            "Epoch: 606, Batch: 1, Loss: 0.0429\n",
            "Epoch: 606, Batch: 2, Loss: 0.0056\n",
            "Epoch: 606, Batch: 3, Loss: 0.1224\n",
            "Epoch: 606, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 607, Batch: 0, Loss: 0.0421\n",
            "Epoch: 607, Batch: 1, Loss: 0.0175\n",
            "Epoch: 607, Batch: 2, Loss: 0.1092\n",
            "Epoch: 607, Batch: 3, Loss: 0.0283\n",
            "Epoch: 607, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 608, Batch: 0, Loss: 0.1069\n",
            "Epoch: 608, Batch: 1, Loss: 0.0459\n",
            "Epoch: 608, Batch: 2, Loss: 0.0254\n",
            "Epoch: 608, Batch: 3, Loss: 0.0118\n",
            "Epoch: 608, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 609, Batch: 0, Loss: 0.0316\n",
            "Epoch: 609, Batch: 1, Loss: 0.1028\n",
            "Epoch: 609, Batch: 2, Loss: 0.0250\n",
            "Epoch: 609, Batch: 3, Loss: 0.0434\n",
            "Epoch: 609, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 610, Batch: 0, Loss: 0.0037\n",
            "Epoch: 610, Batch: 1, Loss: 0.0109\n",
            "Epoch: 610, Batch: 2, Loss: 0.0374\n",
            "Epoch: 610, Batch: 3, Loss: 0.1644\n",
            "Epoch: 610, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 611, Batch: 0, Loss: 0.0202\n",
            "Epoch: 611, Batch: 1, Loss: 0.0749\n",
            "Epoch: 611, Batch: 2, Loss: 0.0365\n",
            "Epoch: 611, Batch: 3, Loss: 0.1319\n",
            "Epoch: 611, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 612, Batch: 0, Loss: 0.0626\n",
            "Epoch: 612, Batch: 1, Loss: 0.0332\n",
            "Epoch: 612, Batch: 2, Loss: 0.0575\n",
            "Epoch: 612, Batch: 3, Loss: 0.0503\n",
            "Epoch: 612, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 613, Batch: 0, Loss: 0.0499\n",
            "Epoch: 613, Batch: 1, Loss: 0.1201\n",
            "Epoch: 613, Batch: 2, Loss: 0.0150\n",
            "Epoch: 613, Batch: 3, Loss: 0.0199\n",
            "Epoch: 613, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 614, Batch: 0, Loss: 0.0160\n",
            "Epoch: 614, Batch: 1, Loss: 0.0881\n",
            "Epoch: 614, Batch: 2, Loss: 0.0938\n",
            "Epoch: 614, Batch: 3, Loss: 0.0136\n",
            "Epoch: 614, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 615, Batch: 0, Loss: 0.0067\n",
            "Epoch: 615, Batch: 1, Loss: 0.0421\n",
            "Epoch: 615, Batch: 2, Loss: 0.1131\n",
            "Epoch: 615, Batch: 3, Loss: 0.0524\n",
            "Epoch: 615, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 616, Batch: 0, Loss: 0.0237\n",
            "Epoch: 616, Batch: 1, Loss: 0.0548\n",
            "Epoch: 616, Batch: 2, Loss: 0.0017\n",
            "Epoch: 616, Batch: 3, Loss: 0.1604\n",
            "Epoch: 616, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 617, Batch: 0, Loss: 0.0292\n",
            "Epoch: 617, Batch: 1, Loss: 0.0030\n",
            "Epoch: 617, Batch: 2, Loss: 0.1263\n",
            "Epoch: 617, Batch: 3, Loss: 0.0320\n",
            "Epoch: 617, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 618, Batch: 0, Loss: 0.0076\n",
            "Epoch: 618, Batch: 1, Loss: 0.1336\n",
            "Epoch: 618, Batch: 2, Loss: 0.0178\n",
            "Epoch: 618, Batch: 3, Loss: 0.0156\n",
            "Epoch: 618, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 619, Batch: 0, Loss: 0.0429\n",
            "Epoch: 619, Batch: 1, Loss: 0.0155\n",
            "Epoch: 619, Batch: 2, Loss: 0.1191\n",
            "Epoch: 619, Batch: 3, Loss: 0.0064\n",
            "Epoch: 619, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 620, Batch: 0, Loss: 0.0295\n",
            "Epoch: 620, Batch: 1, Loss: 0.0572\n",
            "Epoch: 620, Batch: 2, Loss: 0.1161\n",
            "Epoch: 620, Batch: 3, Loss: 0.0152\n",
            "Epoch: 620, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 621, Batch: 0, Loss: 0.0961\n",
            "Epoch: 621, Batch: 1, Loss: 0.0046\n",
            "Epoch: 621, Batch: 2, Loss: 0.0937\n",
            "Epoch: 621, Batch: 3, Loss: 0.0427\n",
            "Epoch: 621, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 622, Batch: 0, Loss: 0.0021\n",
            "Epoch: 622, Batch: 1, Loss: 0.0363\n",
            "Epoch: 622, Batch: 2, Loss: 0.0170\n",
            "Epoch: 622, Batch: 3, Loss: 0.1830\n",
            "Epoch: 622, Training Accuracy: 97.52%, Validation Accuracy: 92.86%\n",
            "Epoch: 623, Batch: 0, Loss: 0.0263\n",
            "Epoch: 623, Batch: 1, Loss: 0.1449\n",
            "Epoch: 623, Batch: 2, Loss: 0.0195\n",
            "Epoch: 623, Batch: 3, Loss: 0.0200\n",
            "Epoch: 623, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 624, Batch: 0, Loss: 0.0098\n",
            "Epoch: 624, Batch: 1, Loss: 0.0523\n",
            "Epoch: 624, Batch: 2, Loss: 0.0288\n",
            "Epoch: 624, Batch: 3, Loss: 0.1264\n",
            "Epoch: 624, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 625, Batch: 0, Loss: 0.0080\n",
            "Epoch: 625, Batch: 1, Loss: 0.0730\n",
            "Epoch: 625, Batch: 2, Loss: 0.1123\n",
            "Epoch: 625, Batch: 3, Loss: 0.0193\n",
            "Epoch: 625, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 626, Batch: 0, Loss: 0.0250\n",
            "Epoch: 626, Batch: 1, Loss: 0.0015\n",
            "Epoch: 626, Batch: 2, Loss: 0.1435\n",
            "Epoch: 626, Batch: 3, Loss: 0.0197\n",
            "Epoch: 626, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 627, Batch: 0, Loss: 0.0301\n",
            "Epoch: 627, Batch: 1, Loss: 0.1138\n",
            "Epoch: 627, Batch: 2, Loss: 0.0064\n",
            "Epoch: 627, Batch: 3, Loss: 0.0661\n",
            "Epoch: 627, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 628, Batch: 0, Loss: 0.1159\n",
            "Epoch: 628, Batch: 1, Loss: 0.0684\n",
            "Epoch: 628, Batch: 2, Loss: 0.0088\n",
            "Epoch: 628, Batch: 3, Loss: 0.0304\n",
            "Epoch: 628, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 629, Batch: 0, Loss: 0.0925\n",
            "Epoch: 629, Batch: 1, Loss: 0.0548\n",
            "Epoch: 629, Batch: 2, Loss: 0.0360\n",
            "Epoch: 629, Batch: 3, Loss: 0.0261\n",
            "Epoch: 629, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 630, Batch: 0, Loss: 0.0315\n",
            "Epoch: 630, Batch: 1, Loss: 0.1027\n",
            "Epoch: 630, Batch: 2, Loss: 0.0289\n",
            "Epoch: 630, Batch: 3, Loss: 0.0434\n",
            "Epoch: 630, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 631, Batch: 0, Loss: 0.1271\n",
            "Epoch: 631, Batch: 1, Loss: 0.0561\n",
            "Epoch: 631, Batch: 2, Loss: 0.0113\n",
            "Epoch: 631, Batch: 3, Loss: 0.0023\n",
            "Epoch: 631, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 632, Batch: 0, Loss: 0.0365\n",
            "Epoch: 632, Batch: 1, Loss: 0.0764\n",
            "Epoch: 632, Batch: 2, Loss: 0.0013\n",
            "Epoch: 632, Batch: 3, Loss: 0.1900\n",
            "Epoch: 632, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 633, Batch: 0, Loss: 0.0159\n",
            "Epoch: 633, Batch: 1, Loss: 0.0668\n",
            "Epoch: 633, Batch: 2, Loss: 0.1192\n",
            "Epoch: 633, Batch: 3, Loss: 0.0028\n",
            "Epoch: 633, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 634, Batch: 0, Loss: 0.0037\n",
            "Epoch: 634, Batch: 1, Loss: 0.0988\n",
            "Epoch: 634, Batch: 2, Loss: 0.0333\n",
            "Epoch: 634, Batch: 3, Loss: 0.0537\n",
            "Epoch: 634, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 635, Batch: 0, Loss: 0.0091\n",
            "Epoch: 635, Batch: 1, Loss: 0.1399\n",
            "Epoch: 635, Batch: 2, Loss: 0.0328\n",
            "Epoch: 635, Batch: 3, Loss: 0.0218\n",
            "Epoch: 635, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 636, Batch: 0, Loss: 0.0019\n",
            "Epoch: 636, Batch: 1, Loss: 0.0539\n",
            "Epoch: 636, Batch: 2, Loss: 0.1509\n",
            "Epoch: 636, Batch: 3, Loss: 0.0241\n",
            "Epoch: 636, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 637, Batch: 0, Loss: 0.0331\n",
            "Epoch: 637, Batch: 1, Loss: 0.1244\n",
            "Epoch: 637, Batch: 2, Loss: 0.0224\n",
            "Epoch: 637, Batch: 3, Loss: 0.0200\n",
            "Epoch: 637, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 638, Batch: 0, Loss: 0.0104\n",
            "Epoch: 638, Batch: 1, Loss: 0.0771\n",
            "Epoch: 638, Batch: 2, Loss: 0.1299\n",
            "Epoch: 638, Batch: 3, Loss: 0.0181\n",
            "Epoch: 638, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 639, Batch: 0, Loss: 0.0253\n",
            "Epoch: 639, Batch: 1, Loss: 0.0330\n",
            "Epoch: 639, Batch: 2, Loss: 0.1263\n",
            "Epoch: 639, Batch: 3, Loss: 0.0138\n",
            "Epoch: 639, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 640, Batch: 0, Loss: 0.0085\n",
            "Epoch: 640, Batch: 1, Loss: 0.0550\n",
            "Epoch: 640, Batch: 2, Loss: 0.1133\n",
            "Epoch: 640, Batch: 3, Loss: 0.0202\n",
            "Epoch: 640, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 641, Batch: 0, Loss: 0.0445\n",
            "Epoch: 641, Batch: 1, Loss: 0.1024\n",
            "Epoch: 641, Batch: 2, Loss: 0.0253\n",
            "Epoch: 641, Batch: 3, Loss: 0.0434\n",
            "Epoch: 641, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 642, Batch: 0, Loss: 0.1000\n",
            "Epoch: 642, Batch: 1, Loss: 0.0656\n",
            "Epoch: 642, Batch: 2, Loss: 0.0203\n",
            "Epoch: 642, Batch: 3, Loss: 0.0030\n",
            "Epoch: 642, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 643, Batch: 0, Loss: 0.0119\n",
            "Epoch: 643, Batch: 1, Loss: 0.0220\n",
            "Epoch: 643, Batch: 2, Loss: 0.1271\n",
            "Epoch: 643, Batch: 3, Loss: 0.0369\n",
            "Epoch: 643, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 644, Batch: 0, Loss: 0.1112\n",
            "Epoch: 644, Batch: 1, Loss: 0.0380\n",
            "Epoch: 644, Batch: 2, Loss: 0.0033\n",
            "Epoch: 644, Batch: 3, Loss: 0.0348\n",
            "Epoch: 644, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 645, Batch: 0, Loss: 0.1225\n",
            "Epoch: 645, Batch: 1, Loss: 0.0315\n",
            "Epoch: 645, Batch: 2, Loss: 0.0206\n",
            "Epoch: 645, Batch: 3, Loss: 0.0225\n",
            "Epoch: 645, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 646, Batch: 0, Loss: 0.0930\n",
            "Epoch: 646, Batch: 1, Loss: 0.0218\n",
            "Epoch: 646, Batch: 2, Loss: 0.0349\n",
            "Epoch: 646, Batch: 3, Loss: 0.0308\n",
            "Epoch: 646, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 647, Batch: 0, Loss: 0.0080\n",
            "Epoch: 647, Batch: 1, Loss: 0.1357\n",
            "Epoch: 647, Batch: 2, Loss: 0.0630\n",
            "Epoch: 647, Batch: 3, Loss: 0.0211\n",
            "Epoch: 647, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 648, Batch: 0, Loss: 0.0289\n",
            "Epoch: 648, Batch: 1, Loss: 0.1162\n",
            "Epoch: 648, Batch: 2, Loss: 0.0277\n",
            "Epoch: 648, Batch: 3, Loss: 0.0643\n",
            "Epoch: 648, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 649, Batch: 0, Loss: 0.1300\n",
            "Epoch: 649, Batch: 1, Loss: 0.0394\n",
            "Epoch: 649, Batch: 2, Loss: 0.0179\n",
            "Epoch: 649, Batch: 3, Loss: 0.0395\n",
            "Epoch: 649, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 650, Batch: 0, Loss: 0.0184\n",
            "Epoch: 650, Batch: 1, Loss: 0.0096\n",
            "Epoch: 650, Batch: 2, Loss: 0.1499\n",
            "Epoch: 650, Batch: 3, Loss: 0.0118\n",
            "Epoch: 650, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 651, Batch: 0, Loss: 0.0151\n",
            "Epoch: 651, Batch: 1, Loss: 0.0413\n",
            "Epoch: 651, Batch: 2, Loss: 0.1275\n",
            "Epoch: 651, Batch: 3, Loss: 0.0796\n",
            "Epoch: 651, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 652, Batch: 0, Loss: 0.1288\n",
            "Epoch: 652, Batch: 1, Loss: 0.0076\n",
            "Epoch: 652, Batch: 2, Loss: 0.0194\n",
            "Epoch: 652, Batch: 3, Loss: 0.0549\n",
            "Epoch: 652, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 653, Batch: 0, Loss: 0.0683\n",
            "Epoch: 653, Batch: 1, Loss: 0.0872\n",
            "Epoch: 653, Batch: 2, Loss: 0.0238\n",
            "Epoch: 653, Batch: 3, Loss: 0.0359\n",
            "Epoch: 653, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 654, Batch: 0, Loss: 0.0966\n",
            "Epoch: 654, Batch: 1, Loss: 0.0522\n",
            "Epoch: 654, Batch: 2, Loss: 0.0142\n",
            "Epoch: 654, Batch: 3, Loss: 0.0457\n",
            "Epoch: 654, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 655, Batch: 0, Loss: 0.0403\n",
            "Epoch: 655, Batch: 1, Loss: 0.0067\n",
            "Epoch: 655, Batch: 2, Loss: 0.0364\n",
            "Epoch: 655, Batch: 3, Loss: 0.1283\n",
            "Epoch: 655, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 656, Batch: 0, Loss: 0.0944\n",
            "Epoch: 656, Batch: 1, Loss: 0.0047\n",
            "Epoch: 656, Batch: 2, Loss: 0.0282\n",
            "Epoch: 656, Batch: 3, Loss: 0.1244\n",
            "Epoch: 656, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 657, Batch: 0, Loss: 0.0881\n",
            "Epoch: 657, Batch: 1, Loss: 0.0513\n",
            "Epoch: 657, Batch: 2, Loss: 0.0298\n",
            "Epoch: 657, Batch: 3, Loss: 0.0069\n",
            "Epoch: 657, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 658, Batch: 0, Loss: 0.0211\n",
            "Epoch: 658, Batch: 1, Loss: 0.1437\n",
            "Epoch: 658, Batch: 2, Loss: 0.0502\n",
            "Epoch: 658, Batch: 3, Loss: 0.0252\n",
            "Epoch: 658, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 659, Batch: 0, Loss: 0.0160\n",
            "Epoch: 659, Batch: 1, Loss: 0.1244\n",
            "Epoch: 659, Batch: 2, Loss: 0.0289\n",
            "Epoch: 659, Batch: 3, Loss: 0.0366\n",
            "Epoch: 659, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 660, Batch: 0, Loss: 0.0352\n",
            "Epoch: 660, Batch: 1, Loss: 0.0252\n",
            "Epoch: 660, Batch: 2, Loss: 0.1007\n",
            "Epoch: 660, Batch: 3, Loss: 0.0377\n",
            "Epoch: 660, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 661, Batch: 0, Loss: 0.0050\n",
            "Epoch: 661, Batch: 1, Loss: 0.0491\n",
            "Epoch: 661, Batch: 2, Loss: 0.1193\n",
            "Epoch: 661, Batch: 3, Loss: 0.0210\n",
            "Epoch: 661, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 662, Batch: 0, Loss: 0.0668\n",
            "Epoch: 662, Batch: 1, Loss: 0.0365\n",
            "Epoch: 662, Batch: 2, Loss: 0.1115\n",
            "Epoch: 662, Batch: 3, Loss: 0.0106\n",
            "Epoch: 662, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 663, Batch: 0, Loss: 0.1119\n",
            "Epoch: 663, Batch: 1, Loss: 0.0239\n",
            "Epoch: 663, Batch: 2, Loss: 0.0356\n",
            "Epoch: 663, Batch: 3, Loss: 0.0024\n",
            "Epoch: 663, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 664, Batch: 0, Loss: 0.0233\n",
            "Epoch: 664, Batch: 1, Loss: 0.0271\n",
            "Epoch: 664, Batch: 2, Loss: 0.0345\n",
            "Epoch: 664, Batch: 3, Loss: 0.1318\n",
            "Epoch: 664, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 665, Batch: 0, Loss: 0.0143\n",
            "Epoch: 665, Batch: 1, Loss: 0.0374\n",
            "Epoch: 665, Batch: 2, Loss: 0.1276\n",
            "Epoch: 665, Batch: 3, Loss: 0.0113\n",
            "Epoch: 665, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 666, Batch: 0, Loss: 0.0318\n",
            "Epoch: 666, Batch: 1, Loss: 0.1206\n",
            "Epoch: 666, Batch: 2, Loss: 0.0058\n",
            "Epoch: 666, Batch: 3, Loss: 0.0353\n",
            "Epoch: 666, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 667, Batch: 0, Loss: 0.0063\n",
            "Epoch: 667, Batch: 1, Loss: 0.0353\n",
            "Epoch: 667, Batch: 2, Loss: 0.1017\n",
            "Epoch: 667, Batch: 3, Loss: 0.0700\n",
            "Epoch: 667, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 668, Batch: 0, Loss: 0.0060\n",
            "Epoch: 668, Batch: 1, Loss: 0.1272\n",
            "Epoch: 668, Batch: 2, Loss: 0.0348\n",
            "Epoch: 668, Batch: 3, Loss: 0.0365\n",
            "Epoch: 668, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 669, Batch: 0, Loss: 0.0080\n",
            "Epoch: 669, Batch: 1, Loss: 0.0042\n",
            "Epoch: 669, Batch: 2, Loss: 0.0444\n",
            "Epoch: 669, Batch: 3, Loss: 0.1676\n",
            "Epoch: 669, Training Accuracy: 97.52%, Validation Accuracy: 92.86%\n",
            "Epoch: 670, Batch: 0, Loss: 0.1087\n",
            "Epoch: 670, Batch: 1, Loss: 0.0071\n",
            "Epoch: 670, Batch: 2, Loss: 0.0424\n",
            "Epoch: 670, Batch: 3, Loss: 0.0677\n",
            "Epoch: 670, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 671, Batch: 0, Loss: 0.0381\n",
            "Epoch: 671, Batch: 1, Loss: 0.0986\n",
            "Epoch: 671, Batch: 2, Loss: 0.0838\n",
            "Epoch: 671, Batch: 3, Loss: 0.0098\n",
            "Epoch: 671, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 672, Batch: 0, Loss: 0.1354\n",
            "Epoch: 672, Batch: 1, Loss: 0.0295\n",
            "Epoch: 672, Batch: 2, Loss: 0.0292\n",
            "Epoch: 672, Batch: 3, Loss: 0.0054\n",
            "Epoch: 672, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 673, Batch: 0, Loss: 0.1112\n",
            "Epoch: 673, Batch: 1, Loss: 0.0078\n",
            "Epoch: 673, Batch: 2, Loss: 0.0474\n",
            "Epoch: 673, Batch: 3, Loss: 0.0335\n",
            "Epoch: 673, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 674, Batch: 0, Loss: 0.0367\n",
            "Epoch: 674, Batch: 1, Loss: 0.1179\n",
            "Epoch: 674, Batch: 2, Loss: 0.0137\n",
            "Epoch: 674, Batch: 3, Loss: 0.0475\n",
            "Epoch: 674, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 675, Batch: 0, Loss: 0.0083\n",
            "Epoch: 675, Batch: 1, Loss: 0.1360\n",
            "Epoch: 675, Batch: 2, Loss: 0.0575\n",
            "Epoch: 675, Batch: 3, Loss: 0.0046\n",
            "Epoch: 675, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 676, Batch: 0, Loss: 0.0079\n",
            "Epoch: 676, Batch: 1, Loss: 0.0264\n",
            "Epoch: 676, Batch: 2, Loss: 0.1390\n",
            "Epoch: 676, Batch: 3, Loss: 0.0044\n",
            "Epoch: 676, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 677, Batch: 0, Loss: 0.0136\n",
            "Epoch: 677, Batch: 1, Loss: 0.0177\n",
            "Epoch: 677, Batch: 2, Loss: 0.0406\n",
            "Epoch: 677, Batch: 3, Loss: 0.1436\n",
            "Epoch: 677, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 678, Batch: 0, Loss: 0.0068\n",
            "Epoch: 678, Batch: 1, Loss: 0.0825\n",
            "Epoch: 678, Batch: 2, Loss: 0.0050\n",
            "Epoch: 678, Batch: 3, Loss: 0.1484\n",
            "Epoch: 678, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 679, Batch: 0, Loss: 0.0135\n",
            "Epoch: 679, Batch: 1, Loss: 0.0467\n",
            "Epoch: 679, Batch: 2, Loss: 0.0225\n",
            "Epoch: 679, Batch: 3, Loss: 0.1514\n",
            "Epoch: 679, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 680, Batch: 0, Loss: 0.1124\n",
            "Epoch: 680, Batch: 1, Loss: 0.0107\n",
            "Epoch: 680, Batch: 2, Loss: 0.0177\n",
            "Epoch: 680, Batch: 3, Loss: 0.0478\n",
            "Epoch: 680, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 681, Batch: 0, Loss: 0.1391\n",
            "Epoch: 681, Batch: 1, Loss: 0.0514\n",
            "Epoch: 681, Batch: 2, Loss: 0.0323\n",
            "Epoch: 681, Batch: 3, Loss: 0.0082\n",
            "Epoch: 681, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 682, Batch: 0, Loss: 0.0171\n",
            "Epoch: 682, Batch: 1, Loss: 0.0062\n",
            "Epoch: 682, Batch: 2, Loss: 0.0142\n",
            "Epoch: 682, Batch: 3, Loss: 0.2331\n",
            "Epoch: 682, Training Accuracy: 94.21%, Validation Accuracy: 92.86%\n",
            "Epoch: 683, Batch: 0, Loss: 0.1389\n",
            "Epoch: 683, Batch: 1, Loss: 0.0127\n",
            "Epoch: 683, Batch: 2, Loss: 0.0104\n",
            "Epoch: 683, Batch: 3, Loss: 0.1843\n",
            "Epoch: 683, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 684, Batch: 0, Loss: 0.0225\n",
            "Epoch: 684, Batch: 1, Loss: 0.1351\n",
            "Epoch: 684, Batch: 2, Loss: 0.0205\n",
            "Epoch: 684, Batch: 3, Loss: 0.0067\n",
            "Epoch: 684, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 685, Batch: 0, Loss: 0.0213\n",
            "Epoch: 685, Batch: 1, Loss: 0.1027\n",
            "Epoch: 685, Batch: 2, Loss: 0.0466\n",
            "Epoch: 685, Batch: 3, Loss: 0.0283\n",
            "Epoch: 685, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 686, Batch: 0, Loss: 0.0317\n",
            "Epoch: 686, Batch: 1, Loss: 0.0047\n",
            "Epoch: 686, Batch: 2, Loss: 0.1182\n",
            "Epoch: 686, Batch: 3, Loss: 0.0231\n",
            "Epoch: 686, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 687, Batch: 0, Loss: 0.0411\n",
            "Epoch: 687, Batch: 1, Loss: 0.1180\n",
            "Epoch: 687, Batch: 2, Loss: 0.0169\n",
            "Epoch: 687, Batch: 3, Loss: 0.0065\n",
            "Epoch: 687, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 688, Batch: 0, Loss: 0.0366\n",
            "Epoch: 688, Batch: 1, Loss: 0.1387\n",
            "Epoch: 688, Batch: 2, Loss: 0.0494\n",
            "Epoch: 688, Batch: 3, Loss: 0.0022\n",
            "Epoch: 688, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 689, Batch: 0, Loss: 0.0199\n",
            "Epoch: 689, Batch: 1, Loss: 0.1032\n",
            "Epoch: 689, Batch: 2, Loss: 0.0118\n",
            "Epoch: 689, Batch: 3, Loss: 0.0549\n",
            "Epoch: 689, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 690, Batch: 0, Loss: 0.0232\n",
            "Epoch: 690, Batch: 1, Loss: 0.0336\n",
            "Epoch: 690, Batch: 2, Loss: 0.0243\n",
            "Epoch: 690, Batch: 3, Loss: 0.1402\n",
            "Epoch: 690, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 691, Batch: 0, Loss: 0.0392\n",
            "Epoch: 691, Batch: 1, Loss: 0.1185\n",
            "Epoch: 691, Batch: 2, Loss: 0.0926\n",
            "Epoch: 691, Batch: 3, Loss: 0.0323\n",
            "Epoch: 691, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 692, Batch: 0, Loss: 0.0403\n",
            "Epoch: 692, Batch: 1, Loss: 0.1230\n",
            "Epoch: 692, Batch: 2, Loss: 0.0284\n",
            "Epoch: 692, Batch: 3, Loss: 0.0048\n",
            "Epoch: 692, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 693, Batch: 0, Loss: 0.1276\n",
            "Epoch: 693, Batch: 1, Loss: 0.0151\n",
            "Epoch: 693, Batch: 2, Loss: 0.0252\n",
            "Epoch: 693, Batch: 3, Loss: 0.0143\n",
            "Epoch: 693, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 694, Batch: 0, Loss: 0.0266\n",
            "Epoch: 694, Batch: 1, Loss: 0.1203\n",
            "Epoch: 694, Batch: 2, Loss: 0.0380\n",
            "Epoch: 694, Batch: 3, Loss: 0.0115\n",
            "Epoch: 694, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 695, Batch: 0, Loss: 0.1279\n",
            "Epoch: 695, Batch: 1, Loss: 0.0133\n",
            "Epoch: 695, Batch: 2, Loss: 0.0139\n",
            "Epoch: 695, Batch: 3, Loss: 0.0249\n",
            "Epoch: 695, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 696, Batch: 0, Loss: 0.0872\n",
            "Epoch: 696, Batch: 1, Loss: 0.0783\n",
            "Epoch: 696, Batch: 2, Loss: 0.0219\n",
            "Epoch: 696, Batch: 3, Loss: 0.0156\n",
            "Epoch: 696, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 697, Batch: 0, Loss: 0.0160\n",
            "Epoch: 697, Batch: 1, Loss: 0.0349\n",
            "Epoch: 697, Batch: 2, Loss: 0.0264\n",
            "Epoch: 697, Batch: 3, Loss: 0.1225\n",
            "Epoch: 697, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 698, Batch: 0, Loss: 0.0681\n",
            "Epoch: 698, Batch: 1, Loss: 0.0326\n",
            "Epoch: 698, Batch: 2, Loss: 0.0075\n",
            "Epoch: 698, Batch: 3, Loss: 0.1444\n",
            "Epoch: 698, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 699, Batch: 0, Loss: 0.0325\n",
            "Epoch: 699, Batch: 1, Loss: 0.0085\n",
            "Epoch: 699, Batch: 2, Loss: 0.0979\n",
            "Epoch: 699, Batch: 3, Loss: 0.0815\n",
            "Epoch: 699, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 700, Batch: 0, Loss: 0.1559\n",
            "Epoch: 700, Batch: 1, Loss: 0.0088\n",
            "Epoch: 700, Batch: 2, Loss: 0.0178\n",
            "Epoch: 700, Batch: 3, Loss: 0.0308\n",
            "Epoch: 700, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 701, Batch: 0, Loss: 0.0211\n",
            "Epoch: 701, Batch: 1, Loss: 0.1260\n",
            "Epoch: 701, Batch: 2, Loss: 0.0084\n",
            "Epoch: 701, Batch: 3, Loss: 0.0250\n",
            "Epoch: 701, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 702, Batch: 0, Loss: 0.0031\n",
            "Epoch: 702, Batch: 1, Loss: 0.0171\n",
            "Epoch: 702, Batch: 2, Loss: 0.1318\n",
            "Epoch: 702, Batch: 3, Loss: 0.0321\n",
            "Epoch: 702, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 703, Batch: 0, Loss: 0.1209\n",
            "Epoch: 703, Batch: 1, Loss: 0.0102\n",
            "Epoch: 703, Batch: 2, Loss: 0.0355\n",
            "Epoch: 703, Batch: 3, Loss: 0.0228\n",
            "Epoch: 703, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 704, Batch: 0, Loss: 0.0174\n",
            "Epoch: 704, Batch: 1, Loss: 0.1161\n",
            "Epoch: 704, Batch: 2, Loss: 0.0254\n",
            "Epoch: 704, Batch: 3, Loss: 0.0539\n",
            "Epoch: 704, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 705, Batch: 0, Loss: 0.0279\n",
            "Epoch: 705, Batch: 1, Loss: 0.1067\n",
            "Epoch: 705, Batch: 2, Loss: 0.0228\n",
            "Epoch: 705, Batch: 3, Loss: 0.0413\n",
            "Epoch: 705, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 706, Batch: 0, Loss: 0.0046\n",
            "Epoch: 706, Batch: 1, Loss: 0.1402\n",
            "Epoch: 706, Batch: 2, Loss: 0.0138\n",
            "Epoch: 706, Batch: 3, Loss: 0.0619\n",
            "Epoch: 706, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 707, Batch: 0, Loss: 0.0287\n",
            "Epoch: 707, Batch: 1, Loss: 0.0912\n",
            "Epoch: 707, Batch: 2, Loss: 0.0466\n",
            "Epoch: 707, Batch: 3, Loss: 0.0327\n",
            "Epoch: 707, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 708, Batch: 0, Loss: 0.0273\n",
            "Epoch: 708, Batch: 1, Loss: 0.1117\n",
            "Epoch: 708, Batch: 2, Loss: 0.0405\n",
            "Epoch: 708, Batch: 3, Loss: 0.0121\n",
            "Epoch: 708, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 709, Batch: 0, Loss: 0.0421\n",
            "Epoch: 709, Batch: 1, Loss: 0.1110\n",
            "Epoch: 709, Batch: 2, Loss: 0.0354\n",
            "Epoch: 709, Batch: 3, Loss: 0.0054\n",
            "Epoch: 709, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 710, Batch: 0, Loss: 0.0888\n",
            "Epoch: 710, Batch: 1, Loss: 0.0785\n",
            "Epoch: 710, Batch: 2, Loss: 0.0400\n",
            "Epoch: 710, Batch: 3, Loss: 0.0030\n",
            "Epoch: 710, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 711, Batch: 0, Loss: 0.0249\n",
            "Epoch: 711, Batch: 1, Loss: 0.1188\n",
            "Epoch: 711, Batch: 2, Loss: 0.0324\n",
            "Epoch: 711, Batch: 3, Loss: 0.0024\n",
            "Epoch: 711, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 712, Batch: 0, Loss: 0.1014\n",
            "Epoch: 712, Batch: 1, Loss: 0.0110\n",
            "Epoch: 712, Batch: 2, Loss: 0.0636\n",
            "Epoch: 712, Batch: 3, Loss: 0.0253\n",
            "Epoch: 712, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 713, Batch: 0, Loss: 0.0945\n",
            "Epoch: 713, Batch: 1, Loss: 0.0936\n",
            "Epoch: 713, Batch: 2, Loss: 0.0067\n",
            "Epoch: 713, Batch: 3, Loss: 0.0332\n",
            "Epoch: 713, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 714, Batch: 0, Loss: 0.0182\n",
            "Epoch: 714, Batch: 1, Loss: 0.1195\n",
            "Epoch: 714, Batch: 2, Loss: 0.0394\n",
            "Epoch: 714, Batch: 3, Loss: 0.0462\n",
            "Epoch: 714, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 715, Batch: 0, Loss: 0.0047\n",
            "Epoch: 715, Batch: 1, Loss: 0.0509\n",
            "Epoch: 715, Batch: 2, Loss: 0.0934\n",
            "Epoch: 715, Batch: 3, Loss: 0.0647\n",
            "Epoch: 715, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 716, Batch: 0, Loss: 0.0357\n",
            "Epoch: 716, Batch: 1, Loss: 0.0339\n",
            "Epoch: 716, Batch: 2, Loss: 0.1244\n",
            "Epoch: 716, Batch: 3, Loss: 0.0180\n",
            "Epoch: 716, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 717, Batch: 0, Loss: 0.1025\n",
            "Epoch: 717, Batch: 1, Loss: 0.0392\n",
            "Epoch: 717, Batch: 2, Loss: 0.0094\n",
            "Epoch: 717, Batch: 3, Loss: 0.0314\n",
            "Epoch: 717, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 718, Batch: 0, Loss: 0.1391\n",
            "Epoch: 718, Batch: 1, Loss: 0.0409\n",
            "Epoch: 718, Batch: 2, Loss: 0.0093\n",
            "Epoch: 718, Batch: 3, Loss: 0.0486\n",
            "Epoch: 718, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 719, Batch: 0, Loss: 0.0278\n",
            "Epoch: 719, Batch: 1, Loss: 0.1262\n",
            "Epoch: 719, Batch: 2, Loss: 0.0097\n",
            "Epoch: 719, Batch: 3, Loss: 0.0388\n",
            "Epoch: 719, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 720, Batch: 0, Loss: 0.0704\n",
            "Epoch: 720, Batch: 1, Loss: 0.0535\n",
            "Epoch: 720, Batch: 2, Loss: 0.0347\n",
            "Epoch: 720, Batch: 3, Loss: 0.0416\n",
            "Epoch: 720, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 721, Batch: 0, Loss: 0.1199\n",
            "Epoch: 721, Batch: 1, Loss: 0.0111\n",
            "Epoch: 721, Batch: 2, Loss: 0.0419\n",
            "Epoch: 721, Batch: 3, Loss: 0.0065\n",
            "Epoch: 721, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 722, Batch: 0, Loss: 0.0927\n",
            "Epoch: 722, Batch: 1, Loss: 0.0599\n",
            "Epoch: 722, Batch: 2, Loss: 0.0037\n",
            "Epoch: 722, Batch: 3, Loss: 0.0500\n",
            "Epoch: 722, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 723, Batch: 0, Loss: 0.1318\n",
            "Epoch: 723, Batch: 1, Loss: 0.0738\n",
            "Epoch: 723, Batch: 2, Loss: 0.0217\n",
            "Epoch: 723, Batch: 3, Loss: 0.0179\n",
            "Epoch: 723, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 724, Batch: 0, Loss: 0.0454\n",
            "Epoch: 724, Batch: 1, Loss: 0.1164\n",
            "Epoch: 724, Batch: 2, Loss: 0.0054\n",
            "Epoch: 724, Batch: 3, Loss: 0.0288\n",
            "Epoch: 724, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 725, Batch: 0, Loss: 0.0182\n",
            "Epoch: 725, Batch: 1, Loss: 0.1525\n",
            "Epoch: 725, Batch: 2, Loss: 0.0098\n",
            "Epoch: 725, Batch: 3, Loss: 0.0288\n",
            "Epoch: 725, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 726, Batch: 0, Loss: 0.0044\n",
            "Epoch: 726, Batch: 1, Loss: 0.0310\n",
            "Epoch: 726, Batch: 2, Loss: 0.0420\n",
            "Epoch: 726, Batch: 3, Loss: 0.1365\n",
            "Epoch: 726, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 727, Batch: 0, Loss: 0.0734\n",
            "Epoch: 727, Batch: 1, Loss: 0.0181\n",
            "Epoch: 727, Batch: 2, Loss: 0.0749\n",
            "Epoch: 727, Batch: 3, Loss: 0.0174\n",
            "Epoch: 727, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 728, Batch: 0, Loss: 0.1541\n",
            "Epoch: 728, Batch: 1, Loss: 0.0017\n",
            "Epoch: 728, Batch: 2, Loss: 0.0271\n",
            "Epoch: 728, Batch: 3, Loss: 0.0314\n",
            "Epoch: 728, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 729, Batch: 0, Loss: 0.0190\n",
            "Epoch: 729, Batch: 1, Loss: 0.1208\n",
            "Epoch: 729, Batch: 2, Loss: 0.0166\n",
            "Epoch: 729, Batch: 3, Loss: 0.0230\n",
            "Epoch: 729, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 730, Batch: 0, Loss: 0.0351\n",
            "Epoch: 730, Batch: 1, Loss: 0.0491\n",
            "Epoch: 730, Batch: 2, Loss: 0.0816\n",
            "Epoch: 730, Batch: 3, Loss: 0.0589\n",
            "Epoch: 730, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 731, Batch: 0, Loss: 0.0465\n",
            "Epoch: 731, Batch: 1, Loss: 0.0347\n",
            "Epoch: 731, Batch: 2, Loss: 0.0091\n",
            "Epoch: 731, Batch: 3, Loss: 0.1406\n",
            "Epoch: 731, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 732, Batch: 0, Loss: 0.0098\n",
            "Epoch: 732, Batch: 1, Loss: 0.1269\n",
            "Epoch: 732, Batch: 2, Loss: 0.0269\n",
            "Epoch: 732, Batch: 3, Loss: 0.0233\n",
            "Epoch: 732, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 733, Batch: 0, Loss: 0.1175\n",
            "Epoch: 733, Batch: 1, Loss: 0.0272\n",
            "Epoch: 733, Batch: 2, Loss: 0.0352\n",
            "Epoch: 733, Batch: 3, Loss: 0.0017\n",
            "Epoch: 733, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 734, Batch: 0, Loss: 0.0431\n",
            "Epoch: 734, Batch: 1, Loss: 0.0910\n",
            "Epoch: 734, Batch: 2, Loss: 0.0731\n",
            "Epoch: 734, Batch: 3, Loss: 0.0104\n",
            "Epoch: 734, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 735, Batch: 0, Loss: 0.0229\n",
            "Epoch: 735, Batch: 1, Loss: 0.1415\n",
            "Epoch: 735, Batch: 2, Loss: 0.0451\n",
            "Epoch: 735, Batch: 3, Loss: 0.0080\n",
            "Epoch: 735, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 736, Batch: 0, Loss: 0.1201\n",
            "Epoch: 736, Batch: 1, Loss: 0.0401\n",
            "Epoch: 736, Batch: 2, Loss: 0.0119\n",
            "Epoch: 736, Batch: 3, Loss: 0.0546\n",
            "Epoch: 736, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 737, Batch: 0, Loss: 0.0079\n",
            "Epoch: 737, Batch: 1, Loss: 0.0299\n",
            "Epoch: 737, Batch: 2, Loss: 0.1313\n",
            "Epoch: 737, Batch: 3, Loss: 0.0249\n",
            "Epoch: 737, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 738, Batch: 0, Loss: 0.0910\n",
            "Epoch: 738, Batch: 1, Loss: 0.0273\n",
            "Epoch: 738, Batch: 2, Loss: 0.0374\n",
            "Epoch: 738, Batch: 3, Loss: 0.0208\n",
            "Epoch: 738, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 739, Batch: 0, Loss: 0.0228\n",
            "Epoch: 739, Batch: 1, Loss: 0.0078\n",
            "Epoch: 739, Batch: 2, Loss: 0.1389\n",
            "Epoch: 739, Batch: 3, Loss: 0.0206\n",
            "Epoch: 739, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 740, Batch: 0, Loss: 0.0078\n",
            "Epoch: 740, Batch: 1, Loss: 0.0415\n",
            "Epoch: 740, Batch: 2, Loss: 0.0386\n",
            "Epoch: 740, Batch: 3, Loss: 0.1308\n",
            "Epoch: 740, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 741, Batch: 0, Loss: 0.0534\n",
            "Epoch: 741, Batch: 1, Loss: 0.0395\n",
            "Epoch: 741, Batch: 2, Loss: 0.1169\n",
            "Epoch: 741, Batch: 3, Loss: 0.0069\n",
            "Epoch: 741, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 742, Batch: 0, Loss: 0.0334\n",
            "Epoch: 742, Batch: 1, Loss: 0.0338\n",
            "Epoch: 742, Batch: 2, Loss: 0.0029\n",
            "Epoch: 742, Batch: 3, Loss: 0.1535\n",
            "Epoch: 742, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 743, Batch: 0, Loss: 0.0713\n",
            "Epoch: 743, Batch: 1, Loss: 0.0218\n",
            "Epoch: 743, Batch: 2, Loss: 0.1413\n",
            "Epoch: 743, Batch: 3, Loss: 0.0340\n",
            "Epoch: 743, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 744, Batch: 0, Loss: 0.0313\n",
            "Epoch: 744, Batch: 1, Loss: 0.1012\n",
            "Epoch: 744, Batch: 2, Loss: 0.0421\n",
            "Epoch: 744, Batch: 3, Loss: 0.0251\n",
            "Epoch: 744, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 745, Batch: 0, Loss: 0.0023\n",
            "Epoch: 745, Batch: 1, Loss: 0.0170\n",
            "Epoch: 745, Batch: 2, Loss: 0.0559\n",
            "Epoch: 745, Batch: 3, Loss: 0.1418\n",
            "Epoch: 745, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 746, Batch: 0, Loss: 0.1116\n",
            "Epoch: 746, Batch: 1, Loss: 0.0483\n",
            "Epoch: 746, Batch: 2, Loss: 0.0044\n",
            "Epoch: 746, Batch: 3, Loss: 0.0276\n",
            "Epoch: 746, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 747, Batch: 0, Loss: 0.0026\n",
            "Epoch: 747, Batch: 1, Loss: 0.0470\n",
            "Epoch: 747, Batch: 2, Loss: 0.1151\n",
            "Epoch: 747, Batch: 3, Loss: 0.0233\n",
            "Epoch: 747, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 748, Batch: 0, Loss: 0.0107\n",
            "Epoch: 748, Batch: 1, Loss: 0.1419\n",
            "Epoch: 748, Batch: 2, Loss: 0.0206\n",
            "Epoch: 748, Batch: 3, Loss: 0.0061\n",
            "Epoch: 748, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 749, Batch: 0, Loss: 0.0077\n",
            "Epoch: 749, Batch: 1, Loss: 0.0207\n",
            "Epoch: 749, Batch: 2, Loss: 0.1552\n",
            "Epoch: 749, Batch: 3, Loss: 0.0901\n",
            "Epoch: 749, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 750, Batch: 0, Loss: 0.0228\n",
            "Epoch: 750, Batch: 1, Loss: 0.0134\n",
            "Epoch: 750, Batch: 2, Loss: 0.1866\n",
            "Epoch: 750, Batch: 3, Loss: 0.0124\n",
            "Epoch: 750, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 751, Batch: 0, Loss: 0.0141\n",
            "Epoch: 751, Batch: 1, Loss: 0.1188\n",
            "Epoch: 751, Batch: 2, Loss: 0.0483\n",
            "Epoch: 751, Batch: 3, Loss: 0.0070\n",
            "Epoch: 751, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 752, Batch: 0, Loss: 0.0196\n",
            "Epoch: 752, Batch: 1, Loss: 0.0377\n",
            "Epoch: 752, Batch: 2, Loss: 0.0068\n",
            "Epoch: 752, Batch: 3, Loss: 0.1628\n",
            "Epoch: 752, Training Accuracy: 97.52%, Validation Accuracy: 92.86%\n",
            "Epoch: 753, Batch: 0, Loss: 0.0563\n",
            "Epoch: 753, Batch: 1, Loss: 0.0811\n",
            "Epoch: 753, Batch: 2, Loss: 0.0429\n",
            "Epoch: 753, Batch: 3, Loss: 0.0424\n",
            "Epoch: 753, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 754, Batch: 0, Loss: 0.0209\n",
            "Epoch: 754, Batch: 1, Loss: 0.1003\n",
            "Epoch: 754, Batch: 2, Loss: 0.0991\n",
            "Epoch: 754, Batch: 3, Loss: 0.0049\n",
            "Epoch: 754, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 755, Batch: 0, Loss: 0.0094\n",
            "Epoch: 755, Batch: 1, Loss: 0.0568\n",
            "Epoch: 755, Batch: 2, Loss: 0.0847\n",
            "Epoch: 755, Batch: 3, Loss: 0.0946\n",
            "Epoch: 755, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 756, Batch: 0, Loss: 0.0131\n",
            "Epoch: 756, Batch: 1, Loss: 0.1372\n",
            "Epoch: 756, Batch: 2, Loss: 0.0036\n",
            "Epoch: 756, Batch: 3, Loss: 0.0436\n",
            "Epoch: 756, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 757, Batch: 0, Loss: 0.0517\n",
            "Epoch: 757, Batch: 1, Loss: 0.0151\n",
            "Epoch: 757, Batch: 2, Loss: 0.0084\n",
            "Epoch: 757, Batch: 3, Loss: 0.1573\n",
            "Epoch: 757, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 758, Batch: 0, Loss: 0.1156\n",
            "Epoch: 758, Batch: 1, Loss: 0.0045\n",
            "Epoch: 758, Batch: 2, Loss: 0.1343\n",
            "Epoch: 758, Batch: 3, Loss: 0.0167\n",
            "Epoch: 758, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 759, Batch: 0, Loss: 0.0297\n",
            "Epoch: 759, Batch: 1, Loss: 0.0523\n",
            "Epoch: 759, Batch: 2, Loss: 0.1046\n",
            "Epoch: 759, Batch: 3, Loss: 0.0030\n",
            "Epoch: 759, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 760, Batch: 0, Loss: 0.0183\n",
            "Epoch: 760, Batch: 1, Loss: 0.0618\n",
            "Epoch: 760, Batch: 2, Loss: 0.1348\n",
            "Epoch: 760, Batch: 3, Loss: 0.0212\n",
            "Epoch: 760, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 761, Batch: 0, Loss: 0.0268\n",
            "Epoch: 761, Batch: 1, Loss: 0.0325\n",
            "Epoch: 761, Batch: 2, Loss: 0.1084\n",
            "Epoch: 761, Batch: 3, Loss: 0.0214\n",
            "Epoch: 761, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 762, Batch: 0, Loss: 0.0088\n",
            "Epoch: 762, Batch: 1, Loss: 0.0189\n",
            "Epoch: 762, Batch: 2, Loss: 0.0581\n",
            "Epoch: 762, Batch: 3, Loss: 0.1914\n",
            "Epoch: 762, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 763, Batch: 0, Loss: 0.0089\n",
            "Epoch: 763, Batch: 1, Loss: 0.1046\n",
            "Epoch: 763, Batch: 2, Loss: 0.1904\n",
            "Epoch: 763, Batch: 3, Loss: 0.0051\n",
            "Epoch: 763, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 764, Batch: 0, Loss: 0.0238\n",
            "Epoch: 764, Batch: 1, Loss: 0.1006\n",
            "Epoch: 764, Batch: 2, Loss: 0.0093\n",
            "Epoch: 764, Batch: 3, Loss: 0.0555\n",
            "Epoch: 764, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 765, Batch: 0, Loss: 0.1202\n",
            "Epoch: 765, Batch: 1, Loss: 0.0137\n",
            "Epoch: 765, Batch: 2, Loss: 0.0063\n",
            "Epoch: 765, Batch: 3, Loss: 0.0533\n",
            "Epoch: 765, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 766, Batch: 0, Loss: 0.0022\n",
            "Epoch: 766, Batch: 1, Loss: 0.0445\n",
            "Epoch: 766, Batch: 2, Loss: 0.0225\n",
            "Epoch: 766, Batch: 3, Loss: 0.1380\n",
            "Epoch: 766, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 767, Batch: 0, Loss: 0.0832\n",
            "Epoch: 767, Batch: 1, Loss: 0.0617\n",
            "Epoch: 767, Batch: 2, Loss: 0.0330\n",
            "Epoch: 767, Batch: 3, Loss: 0.0199\n",
            "Epoch: 767, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 768, Batch: 0, Loss: 0.0608\n",
            "Epoch: 768, Batch: 1, Loss: 0.0269\n",
            "Epoch: 768, Batch: 2, Loss: 0.0962\n",
            "Epoch: 768, Batch: 3, Loss: 0.0165\n",
            "Epoch: 768, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 769, Batch: 0, Loss: 0.0436\n",
            "Epoch: 769, Batch: 1, Loss: 0.0313\n",
            "Epoch: 769, Batch: 2, Loss: 0.0034\n",
            "Epoch: 769, Batch: 3, Loss: 0.1439\n",
            "Epoch: 769, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 770, Batch: 0, Loss: 0.0669\n",
            "Epoch: 770, Batch: 1, Loss: 0.0413\n",
            "Epoch: 770, Batch: 2, Loss: 0.0711\n",
            "Epoch: 770, Batch: 3, Loss: 0.0416\n",
            "Epoch: 770, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 771, Batch: 0, Loss: 0.1283\n",
            "Epoch: 771, Batch: 1, Loss: 0.0588\n",
            "Epoch: 771, Batch: 2, Loss: 0.0027\n",
            "Epoch: 771, Batch: 3, Loss: 0.0367\n",
            "Epoch: 771, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 772, Batch: 0, Loss: 0.1002\n",
            "Epoch: 772, Batch: 1, Loss: 0.0168\n",
            "Epoch: 772, Batch: 2, Loss: 0.0549\n",
            "Epoch: 772, Batch: 3, Loss: 0.0218\n",
            "Epoch: 772, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 773, Batch: 0, Loss: 0.0204\n",
            "Epoch: 773, Batch: 1, Loss: 0.0093\n",
            "Epoch: 773, Batch: 2, Loss: 0.1456\n",
            "Epoch: 773, Batch: 3, Loss: 0.0248\n",
            "Epoch: 773, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 774, Batch: 0, Loss: 0.0462\n",
            "Epoch: 774, Batch: 1, Loss: 0.0304\n",
            "Epoch: 774, Batch: 2, Loss: 0.0082\n",
            "Epoch: 774, Batch: 3, Loss: 0.1385\n",
            "Epoch: 774, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 775, Batch: 0, Loss: 0.0813\n",
            "Epoch: 775, Batch: 1, Loss: 0.0311\n",
            "Epoch: 775, Batch: 2, Loss: 0.0730\n",
            "Epoch: 775, Batch: 3, Loss: 0.0480\n",
            "Epoch: 775, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 776, Batch: 0, Loss: 0.0950\n",
            "Epoch: 776, Batch: 1, Loss: 0.0784\n",
            "Epoch: 776, Batch: 2, Loss: 0.0057\n",
            "Epoch: 776, Batch: 3, Loss: 0.0313\n",
            "Epoch: 776, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 777, Batch: 0, Loss: 0.0473\n",
            "Epoch: 777, Batch: 1, Loss: 0.0324\n",
            "Epoch: 777, Batch: 2, Loss: 0.0048\n",
            "Epoch: 777, Batch: 3, Loss: 0.1317\n",
            "Epoch: 777, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 778, Batch: 0, Loss: 0.0449\n",
            "Epoch: 778, Batch: 1, Loss: 0.0322\n",
            "Epoch: 778, Batch: 2, Loss: 0.1608\n",
            "Epoch: 778, Batch: 3, Loss: 0.0278\n",
            "Epoch: 778, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 779, Batch: 0, Loss: 0.0172\n",
            "Epoch: 779, Batch: 1, Loss: 0.0146\n",
            "Epoch: 779, Batch: 2, Loss: 0.1205\n",
            "Epoch: 779, Batch: 3, Loss: 0.0257\n",
            "Epoch: 779, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 780, Batch: 0, Loss: 0.0316\n",
            "Epoch: 780, Batch: 1, Loss: 0.0981\n",
            "Epoch: 780, Batch: 2, Loss: 0.0536\n",
            "Epoch: 780, Batch: 3, Loss: 0.0329\n",
            "Epoch: 780, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 781, Batch: 0, Loss: 0.0198\n",
            "Epoch: 781, Batch: 1, Loss: 0.1581\n",
            "Epoch: 781, Batch: 2, Loss: 0.0394\n",
            "Epoch: 781, Batch: 3, Loss: 0.0011\n",
            "Epoch: 781, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 782, Batch: 0, Loss: 0.0985\n",
            "Epoch: 782, Batch: 1, Loss: 0.0326\n",
            "Epoch: 782, Batch: 2, Loss: 0.0363\n",
            "Epoch: 782, Batch: 3, Loss: 0.0396\n",
            "Epoch: 782, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 783, Batch: 0, Loss: 0.0036\n",
            "Epoch: 783, Batch: 1, Loss: 0.1635\n",
            "Epoch: 783, Batch: 2, Loss: 0.0220\n",
            "Epoch: 783, Batch: 3, Loss: 0.0323\n",
            "Epoch: 783, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 784, Batch: 0, Loss: 0.0396\n",
            "Epoch: 784, Batch: 1, Loss: 0.0388\n",
            "Epoch: 784, Batch: 2, Loss: 0.1253\n",
            "Epoch: 784, Batch: 3, Loss: 0.0050\n",
            "Epoch: 784, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 785, Batch: 0, Loss: 0.0091\n",
            "Epoch: 785, Batch: 1, Loss: 0.0167\n",
            "Epoch: 785, Batch: 2, Loss: 0.0621\n",
            "Epoch: 785, Batch: 3, Loss: 0.1498\n",
            "Epoch: 785, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 786, Batch: 0, Loss: 0.0437\n",
            "Epoch: 786, Batch: 1, Loss: 0.0074\n",
            "Epoch: 786, Batch: 2, Loss: 0.0210\n",
            "Epoch: 786, Batch: 3, Loss: 0.1527\n",
            "Epoch: 786, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 787, Batch: 0, Loss: 0.0338\n",
            "Epoch: 787, Batch: 1, Loss: 0.1134\n",
            "Epoch: 787, Batch: 2, Loss: 0.0040\n",
            "Epoch: 787, Batch: 3, Loss: 0.0343\n",
            "Epoch: 787, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 788, Batch: 0, Loss: 0.0211\n",
            "Epoch: 788, Batch: 1, Loss: 0.0431\n",
            "Epoch: 788, Batch: 2, Loss: 0.0137\n",
            "Epoch: 788, Batch: 3, Loss: 0.1441\n",
            "Epoch: 788, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 789, Batch: 0, Loss: 0.0113\n",
            "Epoch: 789, Batch: 1, Loss: 0.0718\n",
            "Epoch: 789, Batch: 2, Loss: 0.0961\n",
            "Epoch: 789, Batch: 3, Loss: 0.0466\n",
            "Epoch: 789, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 790, Batch: 0, Loss: 0.0065\n",
            "Epoch: 790, Batch: 1, Loss: 0.1273\n",
            "Epoch: 790, Batch: 2, Loss: 0.0445\n",
            "Epoch: 790, Batch: 3, Loss: 0.0594\n",
            "Epoch: 790, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 791, Batch: 0, Loss: 0.1677\n",
            "Epoch: 791, Batch: 1, Loss: 0.0144\n",
            "Epoch: 791, Batch: 2, Loss: 0.0245\n",
            "Epoch: 791, Batch: 3, Loss: 0.0113\n",
            "Epoch: 791, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 792, Batch: 0, Loss: 0.0076\n",
            "Epoch: 792, Batch: 1, Loss: 0.1396\n",
            "Epoch: 792, Batch: 2, Loss: 0.0469\n",
            "Epoch: 792, Batch: 3, Loss: 0.0039\n",
            "Epoch: 792, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 793, Batch: 0, Loss: 0.0026\n",
            "Epoch: 793, Batch: 1, Loss: 0.1350\n",
            "Epoch: 793, Batch: 2, Loss: 0.0271\n",
            "Epoch: 793, Batch: 3, Loss: 0.0259\n",
            "Epoch: 793, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 794, Batch: 0, Loss: 0.0813\n",
            "Epoch: 794, Batch: 1, Loss: 0.0757\n",
            "Epoch: 794, Batch: 2, Loss: 0.0438\n",
            "Epoch: 794, Batch: 3, Loss: 0.0377\n",
            "Epoch: 794, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 795, Batch: 0, Loss: 0.0041\n",
            "Epoch: 795, Batch: 1, Loss: 0.0317\n",
            "Epoch: 795, Batch: 2, Loss: 0.2070\n",
            "Epoch: 795, Batch: 3, Loss: 0.0166\n",
            "Epoch: 795, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 796, Batch: 0, Loss: 0.0199\n",
            "Epoch: 796, Batch: 1, Loss: 0.0398\n",
            "Epoch: 796, Batch: 2, Loss: 0.1190\n",
            "Epoch: 796, Batch: 3, Loss: 0.0774\n",
            "Epoch: 796, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 797, Batch: 0, Loss: 0.1312\n",
            "Epoch: 797, Batch: 1, Loss: 0.0605\n",
            "Epoch: 797, Batch: 2, Loss: 0.0080\n",
            "Epoch: 797, Batch: 3, Loss: 0.0213\n",
            "Epoch: 797, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 798, Batch: 0, Loss: 0.0078\n",
            "Epoch: 798, Batch: 1, Loss: 0.0279\n",
            "Epoch: 798, Batch: 2, Loss: 0.0963\n",
            "Epoch: 798, Batch: 3, Loss: 0.0865\n",
            "Epoch: 798, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 799, Batch: 0, Loss: 0.0407\n",
            "Epoch: 799, Batch: 1, Loss: 0.0048\n",
            "Epoch: 799, Batch: 2, Loss: 0.0130\n",
            "Epoch: 799, Batch: 3, Loss: 0.1696\n",
            "Epoch: 799, Training Accuracy: 97.52%, Validation Accuracy: 92.86%\n",
            "Epoch: 800, Batch: 0, Loss: 0.0304\n",
            "Epoch: 800, Batch: 1, Loss: 0.0832\n",
            "Epoch: 800, Batch: 2, Loss: 0.0574\n",
            "Epoch: 800, Batch: 3, Loss: 0.0527\n",
            "Epoch: 800, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 801, Batch: 0, Loss: 0.0202\n",
            "Epoch: 801, Batch: 1, Loss: 0.1123\n",
            "Epoch: 801, Batch: 2, Loss: 0.0226\n",
            "Epoch: 801, Batch: 3, Loss: 0.0297\n",
            "Epoch: 801, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 802, Batch: 0, Loss: 0.0273\n",
            "Epoch: 802, Batch: 1, Loss: 0.1135\n",
            "Epoch: 802, Batch: 2, Loss: 0.0266\n",
            "Epoch: 802, Batch: 3, Loss: 0.0287\n",
            "Epoch: 802, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 803, Batch: 0, Loss: 0.0903\n",
            "Epoch: 803, Batch: 1, Loss: 0.0545\n",
            "Epoch: 803, Batch: 2, Loss: 0.0327\n",
            "Epoch: 803, Batch: 3, Loss: 0.0035\n",
            "Epoch: 803, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 804, Batch: 0, Loss: 0.0193\n",
            "Epoch: 804, Batch: 1, Loss: 0.0498\n",
            "Epoch: 804, Batch: 2, Loss: 0.0740\n",
            "Epoch: 804, Batch: 3, Loss: 0.1128\n",
            "Epoch: 804, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 805, Batch: 0, Loss: 0.0049\n",
            "Epoch: 805, Batch: 1, Loss: 0.0405\n",
            "Epoch: 805, Batch: 2, Loss: 0.0275\n",
            "Epoch: 805, Batch: 3, Loss: 0.1456\n",
            "Epoch: 805, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 806, Batch: 0, Loss: 0.0117\n",
            "Epoch: 806, Batch: 1, Loss: 0.1422\n",
            "Epoch: 806, Batch: 2, Loss: 0.0201\n",
            "Epoch: 806, Batch: 3, Loss: 0.0031\n",
            "Epoch: 806, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 807, Batch: 0, Loss: 0.0030\n",
            "Epoch: 807, Batch: 1, Loss: 0.0169\n",
            "Epoch: 807, Batch: 2, Loss: 0.1452\n",
            "Epoch: 807, Batch: 3, Loss: 0.1195\n",
            "Epoch: 807, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 808, Batch: 0, Loss: 0.1296\n",
            "Epoch: 808, Batch: 1, Loss: 0.0440\n",
            "Epoch: 808, Batch: 2, Loss: 0.0089\n",
            "Epoch: 808, Batch: 3, Loss: 0.0794\n",
            "Epoch: 808, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 809, Batch: 0, Loss: 0.0497\n",
            "Epoch: 809, Batch: 1, Loss: 0.1034\n",
            "Epoch: 809, Batch: 2, Loss: 0.0702\n",
            "Epoch: 809, Batch: 3, Loss: 0.0028\n",
            "Epoch: 809, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 810, Batch: 0, Loss: 0.0431\n",
            "Epoch: 810, Batch: 1, Loss: 0.0290\n",
            "Epoch: 810, Batch: 2, Loss: 0.0062\n",
            "Epoch: 810, Batch: 3, Loss: 0.1297\n",
            "Epoch: 810, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 811, Batch: 0, Loss: 0.0578\n",
            "Epoch: 811, Batch: 1, Loss: 0.0382\n",
            "Epoch: 811, Batch: 2, Loss: 0.0226\n",
            "Epoch: 811, Batch: 3, Loss: 0.1239\n",
            "Epoch: 811, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 812, Batch: 0, Loss: 0.0787\n",
            "Epoch: 812, Batch: 1, Loss: 0.0060\n",
            "Epoch: 812, Batch: 2, Loss: 0.0465\n",
            "Epoch: 812, Batch: 3, Loss: 0.0654\n",
            "Epoch: 812, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 813, Batch: 0, Loss: 0.0103\n",
            "Epoch: 813, Batch: 1, Loss: 0.0360\n",
            "Epoch: 813, Batch: 2, Loss: 0.0665\n",
            "Epoch: 813, Batch: 3, Loss: 0.1038\n",
            "Epoch: 813, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 814, Batch: 0, Loss: 0.0486\n",
            "Epoch: 814, Batch: 1, Loss: 0.0477\n",
            "Epoch: 814, Batch: 2, Loss: 0.0202\n",
            "Epoch: 814, Batch: 3, Loss: 0.1217\n",
            "Epoch: 814, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 815, Batch: 0, Loss: 0.0941\n",
            "Epoch: 815, Batch: 1, Loss: 0.0344\n",
            "Epoch: 815, Batch: 2, Loss: 0.0198\n",
            "Epoch: 815, Batch: 3, Loss: 0.1173\n",
            "Epoch: 815, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 816, Batch: 0, Loss: 0.0422\n",
            "Epoch: 816, Batch: 1, Loss: 0.0973\n",
            "Epoch: 816, Batch: 2, Loss: 0.0491\n",
            "Epoch: 816, Batch: 3, Loss: 0.0046\n",
            "Epoch: 816, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 817, Batch: 0, Loss: 0.0220\n",
            "Epoch: 817, Batch: 1, Loss: 0.0319\n",
            "Epoch: 817, Batch: 2, Loss: 0.0100\n",
            "Epoch: 817, Batch: 3, Loss: 0.1628\n",
            "Epoch: 817, Training Accuracy: 97.52%, Validation Accuracy: 92.86%\n",
            "Epoch: 818, Batch: 0, Loss: 0.0740\n",
            "Epoch: 818, Batch: 1, Loss: 0.0366\n",
            "Epoch: 818, Batch: 2, Loss: 0.0555\n",
            "Epoch: 818, Batch: 3, Loss: 0.0392\n",
            "Epoch: 818, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 819, Batch: 0, Loss: 0.0300\n",
            "Epoch: 819, Batch: 1, Loss: 0.1335\n",
            "Epoch: 819, Batch: 2, Loss: 0.0219\n",
            "Epoch: 819, Batch: 3, Loss: 0.0219\n",
            "Epoch: 819, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 820, Batch: 0, Loss: 0.0376\n",
            "Epoch: 820, Batch: 1, Loss: 0.0215\n",
            "Epoch: 820, Batch: 2, Loss: 0.0087\n",
            "Epoch: 820, Batch: 3, Loss: 0.1375\n",
            "Epoch: 820, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 821, Batch: 0, Loss: 0.0291\n",
            "Epoch: 821, Batch: 1, Loss: 0.1286\n",
            "Epoch: 821, Batch: 2, Loss: 0.0244\n",
            "Epoch: 821, Batch: 3, Loss: 0.0045\n",
            "Epoch: 821, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 822, Batch: 0, Loss: 0.0340\n",
            "Epoch: 822, Batch: 1, Loss: 0.0274\n",
            "Epoch: 822, Batch: 2, Loss: 0.1372\n",
            "Epoch: 822, Batch: 3, Loss: 0.0190\n",
            "Epoch: 822, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 823, Batch: 0, Loss: 0.1288\n",
            "Epoch: 823, Batch: 1, Loss: 0.0243\n",
            "Epoch: 823, Batch: 2, Loss: 0.0163\n",
            "Epoch: 823, Batch: 3, Loss: 0.0053\n",
            "Epoch: 823, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 824, Batch: 0, Loss: 0.0198\n",
            "Epoch: 824, Batch: 1, Loss: 0.0420\n",
            "Epoch: 824, Batch: 2, Loss: 0.1394\n",
            "Epoch: 824, Batch: 3, Loss: 0.0435\n",
            "Epoch: 824, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 825, Batch: 0, Loss: 0.1082\n",
            "Epoch: 825, Batch: 1, Loss: 0.0268\n",
            "Epoch: 825, Batch: 2, Loss: 0.0152\n",
            "Epoch: 825, Batch: 3, Loss: 0.0592\n",
            "Epoch: 825, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 826, Batch: 0, Loss: 0.1136\n",
            "Epoch: 826, Batch: 1, Loss: 0.0269\n",
            "Epoch: 826, Batch: 2, Loss: 0.0293\n",
            "Epoch: 826, Batch: 3, Loss: 0.0348\n",
            "Epoch: 826, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 827, Batch: 0, Loss: 0.0116\n",
            "Epoch: 827, Batch: 1, Loss: 0.0650\n",
            "Epoch: 827, Batch: 2, Loss: 0.0120\n",
            "Epoch: 827, Batch: 3, Loss: 0.1425\n",
            "Epoch: 827, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 828, Batch: 0, Loss: 0.0061\n",
            "Epoch: 828, Batch: 1, Loss: 0.0227\n",
            "Epoch: 828, Batch: 2, Loss: 0.0141\n",
            "Epoch: 828, Batch: 3, Loss: 0.1710\n",
            "Epoch: 828, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 829, Batch: 0, Loss: 0.0376\n",
            "Epoch: 829, Batch: 1, Loss: 0.0216\n",
            "Epoch: 829, Batch: 2, Loss: 0.0016\n",
            "Epoch: 829, Batch: 3, Loss: 0.1435\n",
            "Epoch: 829, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 830, Batch: 0, Loss: 0.0508\n",
            "Epoch: 830, Batch: 1, Loss: 0.0185\n",
            "Epoch: 830, Batch: 2, Loss: 0.1066\n",
            "Epoch: 830, Batch: 3, Loss: 0.0168\n",
            "Epoch: 830, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 831, Batch: 0, Loss: 0.0171\n",
            "Epoch: 831, Batch: 1, Loss: 0.0884\n",
            "Epoch: 831, Batch: 2, Loss: 0.0249\n",
            "Epoch: 831, Batch: 3, Loss: 0.0847\n",
            "Epoch: 831, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 832, Batch: 0, Loss: 0.0372\n",
            "Epoch: 832, Batch: 1, Loss: 0.0953\n",
            "Epoch: 832, Batch: 2, Loss: 0.0508\n",
            "Epoch: 832, Batch: 3, Loss: 0.0240\n",
            "Epoch: 832, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 833, Batch: 0, Loss: 0.0324\n",
            "Epoch: 833, Batch: 1, Loss: 0.1137\n",
            "Epoch: 833, Batch: 2, Loss: 0.0097\n",
            "Epoch: 833, Batch: 3, Loss: 0.0480\n",
            "Epoch: 833, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 834, Batch: 0, Loss: 0.0074\n",
            "Epoch: 834, Batch: 1, Loss: 0.0237\n",
            "Epoch: 834, Batch: 2, Loss: 0.1045\n",
            "Epoch: 834, Batch: 3, Loss: 0.1341\n",
            "Epoch: 834, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 835, Batch: 0, Loss: 0.0244\n",
            "Epoch: 835, Batch: 1, Loss: 0.1516\n",
            "Epoch: 835, Batch: 2, Loss: 0.0187\n",
            "Epoch: 835, Batch: 3, Loss: 0.0420\n",
            "Epoch: 835, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 836, Batch: 0, Loss: 0.0047\n",
            "Epoch: 836, Batch: 1, Loss: 0.0317\n",
            "Epoch: 836, Batch: 2, Loss: 0.0477\n",
            "Epoch: 836, Batch: 3, Loss: 0.1449\n",
            "Epoch: 836, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 837, Batch: 0, Loss: 0.0902\n",
            "Epoch: 837, Batch: 1, Loss: 0.1503\n",
            "Epoch: 837, Batch: 2, Loss: 0.0019\n",
            "Epoch: 837, Batch: 3, Loss: 0.0216\n",
            "Epoch: 837, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 838, Batch: 0, Loss: 0.0972\n",
            "Epoch: 838, Batch: 1, Loss: 0.0270\n",
            "Epoch: 838, Batch: 2, Loss: 0.0124\n",
            "Epoch: 838, Batch: 3, Loss: 0.0717\n",
            "Epoch: 838, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 839, Batch: 0, Loss: 0.1517\n",
            "Epoch: 839, Batch: 1, Loss: 0.0096\n",
            "Epoch: 839, Batch: 2, Loss: 0.0440\n",
            "Epoch: 839, Batch: 3, Loss: 0.0037\n",
            "Epoch: 839, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 840, Batch: 0, Loss: 0.0207\n",
            "Epoch: 840, Batch: 1, Loss: 0.0493\n",
            "Epoch: 840, Batch: 2, Loss: 0.0369\n",
            "Epoch: 840, Batch: 3, Loss: 0.1271\n",
            "Epoch: 840, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 841, Batch: 0, Loss: 0.0147\n",
            "Epoch: 841, Batch: 1, Loss: 0.0410\n",
            "Epoch: 841, Batch: 2, Loss: 0.1085\n",
            "Epoch: 841, Batch: 3, Loss: 0.0258\n",
            "Epoch: 841, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 842, Batch: 0, Loss: 0.0366\n",
            "Epoch: 842, Batch: 1, Loss: 0.0056\n",
            "Epoch: 842, Batch: 2, Loss: 0.1285\n",
            "Epoch: 842, Batch: 3, Loss: 0.0261\n",
            "Epoch: 842, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 843, Batch: 0, Loss: 0.0514\n",
            "Epoch: 843, Batch: 1, Loss: 0.1055\n",
            "Epoch: 843, Batch: 2, Loss: 0.0181\n",
            "Epoch: 843, Batch: 3, Loss: 0.0075\n",
            "Epoch: 843, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 844, Batch: 0, Loss: 0.0140\n",
            "Epoch: 844, Batch: 1, Loss: 0.0668\n",
            "Epoch: 844, Batch: 2, Loss: 0.1238\n",
            "Epoch: 844, Batch: 3, Loss: 0.0165\n",
            "Epoch: 844, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 845, Batch: 0, Loss: 0.1102\n",
            "Epoch: 845, Batch: 1, Loss: 0.0097\n",
            "Epoch: 845, Batch: 2, Loss: 0.0190\n",
            "Epoch: 845, Batch: 3, Loss: 0.0488\n",
            "Epoch: 845, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 846, Batch: 0, Loss: 0.0962\n",
            "Epoch: 846, Batch: 1, Loss: 0.0650\n",
            "Epoch: 846, Batch: 2, Loss: 0.0053\n",
            "Epoch: 846, Batch: 3, Loss: 0.0209\n",
            "Epoch: 846, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 847, Batch: 0, Loss: 0.1326\n",
            "Epoch: 847, Batch: 1, Loss: 0.0651\n",
            "Epoch: 847, Batch: 2, Loss: 0.0330\n",
            "Epoch: 847, Batch: 3, Loss: 0.0060\n",
            "Epoch: 847, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 848, Batch: 0, Loss: 0.0204\n",
            "Epoch: 848, Batch: 1, Loss: 0.0170\n",
            "Epoch: 848, Batch: 2, Loss: 0.1279\n",
            "Epoch: 848, Batch: 3, Loss: 0.0315\n",
            "Epoch: 848, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 849, Batch: 0, Loss: 0.0649\n",
            "Epoch: 849, Batch: 1, Loss: 0.1370\n",
            "Epoch: 849, Batch: 2, Loss: 0.0070\n",
            "Epoch: 849, Batch: 3, Loss: 0.0025\n",
            "Epoch: 849, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 850, Batch: 0, Loss: 0.0110\n",
            "Epoch: 850, Batch: 1, Loss: 0.0553\n",
            "Epoch: 850, Batch: 2, Loss: 0.1063\n",
            "Epoch: 850, Batch: 3, Loss: 0.0060\n",
            "Epoch: 850, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 851, Batch: 0, Loss: 0.0242\n",
            "Epoch: 851, Batch: 1, Loss: 0.0264\n",
            "Epoch: 851, Batch: 2, Loss: 0.1126\n",
            "Epoch: 851, Batch: 3, Loss: 0.0277\n",
            "Epoch: 851, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 852, Batch: 0, Loss: 0.0219\n",
            "Epoch: 852, Batch: 1, Loss: 0.0451\n",
            "Epoch: 852, Batch: 2, Loss: 0.0050\n",
            "Epoch: 852, Batch: 3, Loss: 0.1423\n",
            "Epoch: 852, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 853, Batch: 0, Loss: 0.0165\n",
            "Epoch: 853, Batch: 1, Loss: 0.0247\n",
            "Epoch: 853, Batch: 2, Loss: 0.1022\n",
            "Epoch: 853, Batch: 3, Loss: 0.0586\n",
            "Epoch: 853, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 854, Batch: 0, Loss: 0.0184\n",
            "Epoch: 854, Batch: 1, Loss: 0.1156\n",
            "Epoch: 854, Batch: 2, Loss: 0.0061\n",
            "Epoch: 854, Batch: 3, Loss: 0.0636\n",
            "Epoch: 854, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 855, Batch: 0, Loss: 0.0344\n",
            "Epoch: 855, Batch: 1, Loss: 0.1163\n",
            "Epoch: 855, Batch: 2, Loss: 0.0187\n",
            "Epoch: 855, Batch: 3, Loss: 0.0072\n",
            "Epoch: 855, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 856, Batch: 0, Loss: 0.1135\n",
            "Epoch: 856, Batch: 1, Loss: 0.0193\n",
            "Epoch: 856, Batch: 2, Loss: 0.0262\n",
            "Epoch: 856, Batch: 3, Loss: 0.0238\n",
            "Epoch: 856, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 857, Batch: 0, Loss: 0.0130\n",
            "Epoch: 857, Batch: 1, Loss: 0.0894\n",
            "Epoch: 857, Batch: 2, Loss: 0.0635\n",
            "Epoch: 857, Batch: 3, Loss: 0.0204\n",
            "Epoch: 857, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 858, Batch: 0, Loss: 0.1299\n",
            "Epoch: 858, Batch: 1, Loss: 0.0221\n",
            "Epoch: 858, Batch: 2, Loss: 0.0288\n",
            "Epoch: 858, Batch: 3, Loss: 0.0060\n",
            "Epoch: 858, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 859, Batch: 0, Loss: 0.0252\n",
            "Epoch: 859, Batch: 1, Loss: 0.0976\n",
            "Epoch: 859, Batch: 2, Loss: 0.0618\n",
            "Epoch: 859, Batch: 3, Loss: 0.0344\n",
            "Epoch: 859, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 860, Batch: 0, Loss: 0.0064\n",
            "Epoch: 860, Batch: 1, Loss: 0.0178\n",
            "Epoch: 860, Batch: 2, Loss: 0.1578\n",
            "Epoch: 860, Batch: 3, Loss: 0.0165\n",
            "Epoch: 860, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 861, Batch: 0, Loss: 0.0201\n",
            "Epoch: 861, Batch: 1, Loss: 0.0893\n",
            "Epoch: 861, Batch: 2, Loss: 0.0447\n",
            "Epoch: 861, Batch: 3, Loss: 0.0400\n",
            "Epoch: 861, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 862, Batch: 0, Loss: 0.0217\n",
            "Epoch: 862, Batch: 1, Loss: 0.1038\n",
            "Epoch: 862, Batch: 2, Loss: 0.0451\n",
            "Epoch: 862, Batch: 3, Loss: 0.0275\n",
            "Epoch: 862, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 863, Batch: 0, Loss: 0.0051\n",
            "Epoch: 863, Batch: 1, Loss: 0.0201\n",
            "Epoch: 863, Batch: 2, Loss: 0.0930\n",
            "Epoch: 863, Batch: 3, Loss: 0.1090\n",
            "Epoch: 863, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 864, Batch: 0, Loss: 0.1358\n",
            "Epoch: 864, Batch: 1, Loss: 0.0442\n",
            "Epoch: 864, Batch: 2, Loss: 0.0285\n",
            "Epoch: 864, Batch: 3, Loss: 0.0270\n",
            "Epoch: 864, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 865, Batch: 0, Loss: 0.0991\n",
            "Epoch: 865, Batch: 1, Loss: 0.0176\n",
            "Epoch: 865, Batch: 2, Loss: 0.0822\n",
            "Epoch: 865, Batch: 3, Loss: 0.0153\n",
            "Epoch: 865, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 866, Batch: 0, Loss: 0.0074\n",
            "Epoch: 866, Batch: 1, Loss: 0.1268\n",
            "Epoch: 866, Batch: 2, Loss: 0.0320\n",
            "Epoch: 866, Batch: 3, Loss: 0.0467\n",
            "Epoch: 866, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 867, Batch: 0, Loss: 0.1497\n",
            "Epoch: 867, Batch: 1, Loss: 0.0140\n",
            "Epoch: 867, Batch: 2, Loss: 0.0034\n",
            "Epoch: 867, Batch: 3, Loss: 0.0193\n",
            "Epoch: 867, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 868, Batch: 0, Loss: 0.1328\n",
            "Epoch: 868, Batch: 1, Loss: 0.0167\n",
            "Epoch: 868, Batch: 2, Loss: 0.0189\n",
            "Epoch: 868, Batch: 3, Loss: 0.0098\n",
            "Epoch: 868, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 869, Batch: 0, Loss: 0.0190\n",
            "Epoch: 869, Batch: 1, Loss: 0.0189\n",
            "Epoch: 869, Batch: 2, Loss: 0.1248\n",
            "Epoch: 869, Batch: 3, Loss: 0.0161\n",
            "Epoch: 869, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 870, Batch: 0, Loss: 0.0188\n",
            "Epoch: 870, Batch: 1, Loss: 0.0423\n",
            "Epoch: 870, Batch: 2, Loss: 0.0981\n",
            "Epoch: 870, Batch: 3, Loss: 0.0620\n",
            "Epoch: 870, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 871, Batch: 0, Loss: 0.0017\n",
            "Epoch: 871, Batch: 1, Loss: 0.0275\n",
            "Epoch: 871, Batch: 2, Loss: 0.1640\n",
            "Epoch: 871, Batch: 3, Loss: 0.0252\n",
            "Epoch: 871, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 872, Batch: 0, Loss: 0.0118\n",
            "Epoch: 872, Batch: 1, Loss: 0.1210\n",
            "Epoch: 872, Batch: 2, Loss: 0.0102\n",
            "Epoch: 872, Batch: 3, Loss: 0.0501\n",
            "Epoch: 872, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 873, Batch: 0, Loss: 0.0051\n",
            "Epoch: 873, Batch: 1, Loss: 0.1044\n",
            "Epoch: 873, Batch: 2, Loss: 0.0194\n",
            "Epoch: 873, Batch: 3, Loss: 0.0865\n",
            "Epoch: 873, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 874, Batch: 0, Loss: 0.1364\n",
            "Epoch: 874, Batch: 1, Loss: 0.0202\n",
            "Epoch: 874, Batch: 2, Loss: 0.0173\n",
            "Epoch: 874, Batch: 3, Loss: 0.0280\n",
            "Epoch: 874, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 875, Batch: 0, Loss: 0.1257\n",
            "Epoch: 875, Batch: 1, Loss: 0.0308\n",
            "Epoch: 875, Batch: 2, Loss: 0.0026\n",
            "Epoch: 875, Batch: 3, Loss: 0.0166\n",
            "Epoch: 875, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 876, Batch: 0, Loss: 0.0292\n",
            "Epoch: 876, Batch: 1, Loss: 0.1399\n",
            "Epoch: 876, Batch: 2, Loss: 0.0607\n",
            "Epoch: 876, Batch: 3, Loss: 0.0007\n",
            "Epoch: 876, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 877, Batch: 0, Loss: 0.1157\n",
            "Epoch: 877, Batch: 1, Loss: 0.0173\n",
            "Epoch: 877, Batch: 2, Loss: 0.0118\n",
            "Epoch: 877, Batch: 3, Loss: 0.0418\n",
            "Epoch: 877, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 878, Batch: 0, Loss: 0.1232\n",
            "Epoch: 878, Batch: 1, Loss: 0.0973\n",
            "Epoch: 878, Batch: 2, Loss: 0.0423\n",
            "Epoch: 878, Batch: 3, Loss: 0.0058\n",
            "Epoch: 878, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 879, Batch: 0, Loss: 0.0442\n",
            "Epoch: 879, Batch: 1, Loss: 0.0191\n",
            "Epoch: 879, Batch: 2, Loss: 0.1052\n",
            "Epoch: 879, Batch: 3, Loss: 0.0076\n",
            "Epoch: 879, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 880, Batch: 0, Loss: 0.0143\n",
            "Epoch: 880, Batch: 1, Loss: 0.0146\n",
            "Epoch: 880, Batch: 2, Loss: 0.1149\n",
            "Epoch: 880, Batch: 3, Loss: 0.0387\n",
            "Epoch: 880, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 881, Batch: 0, Loss: 0.0177\n",
            "Epoch: 881, Batch: 1, Loss: 0.1547\n",
            "Epoch: 881, Batch: 2, Loss: 0.0118\n",
            "Epoch: 881, Batch: 3, Loss: 0.0600\n",
            "Epoch: 881, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 882, Batch: 0, Loss: 0.0263\n",
            "Epoch: 882, Batch: 1, Loss: 0.1294\n",
            "Epoch: 882, Batch: 2, Loss: 0.0241\n",
            "Epoch: 882, Batch: 3, Loss: 0.0048\n",
            "Epoch: 882, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 883, Batch: 0, Loss: 0.1045\n",
            "Epoch: 883, Batch: 1, Loss: 0.0114\n",
            "Epoch: 883, Batch: 2, Loss: 0.0363\n",
            "Epoch: 883, Batch: 3, Loss: 0.0530\n",
            "Epoch: 883, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 884, Batch: 0, Loss: 0.0064\n",
            "Epoch: 884, Batch: 1, Loss: 0.0448\n",
            "Epoch: 884, Batch: 2, Loss: 0.0076\n",
            "Epoch: 884, Batch: 3, Loss: 0.1668\n",
            "Epoch: 884, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 885, Batch: 0, Loss: 0.0175\n",
            "Epoch: 885, Batch: 1, Loss: 0.0899\n",
            "Epoch: 885, Batch: 2, Loss: 0.0386\n",
            "Epoch: 885, Batch: 3, Loss: 0.1274\n",
            "Epoch: 885, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 886, Batch: 0, Loss: 0.0115\n",
            "Epoch: 886, Batch: 1, Loss: 0.0802\n",
            "Epoch: 886, Batch: 2, Loss: 0.1190\n",
            "Epoch: 886, Batch: 3, Loss: 0.0036\n",
            "Epoch: 886, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 887, Batch: 0, Loss: 0.1000\n",
            "Epoch: 887, Batch: 1, Loss: 0.0139\n",
            "Epoch: 887, Batch: 2, Loss: 0.0632\n",
            "Epoch: 887, Batch: 3, Loss: 0.0236\n",
            "Epoch: 887, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 888, Batch: 0, Loss: 0.1202\n",
            "Epoch: 888, Batch: 1, Loss: 0.0321\n",
            "Epoch: 888, Batch: 2, Loss: 0.0470\n",
            "Epoch: 888, Batch: 3, Loss: 0.0432\n",
            "Epoch: 888, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 889, Batch: 0, Loss: 0.0106\n",
            "Epoch: 889, Batch: 1, Loss: 0.0366\n",
            "Epoch: 889, Batch: 2, Loss: 0.1243\n",
            "Epoch: 889, Batch: 3, Loss: 0.0242\n",
            "Epoch: 889, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 890, Batch: 0, Loss: 0.0305\n",
            "Epoch: 890, Batch: 1, Loss: 0.0146\n",
            "Epoch: 890, Batch: 2, Loss: 0.1658\n",
            "Epoch: 890, Batch: 3, Loss: 0.0237\n",
            "Epoch: 890, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 891, Batch: 0, Loss: 0.0817\n",
            "Epoch: 891, Batch: 1, Loss: 0.0088\n",
            "Epoch: 891, Batch: 2, Loss: 0.1052\n",
            "Epoch: 891, Batch: 3, Loss: 0.0206\n",
            "Epoch: 891, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 892, Batch: 0, Loss: 0.1422\n",
            "Epoch: 892, Batch: 1, Loss: 0.0077\n",
            "Epoch: 892, Batch: 2, Loss: 0.0190\n",
            "Epoch: 892, Batch: 3, Loss: 0.0054\n",
            "Epoch: 892, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 893, Batch: 0, Loss: 0.0378\n",
            "Epoch: 893, Batch: 1, Loss: 0.0287\n",
            "Epoch: 893, Batch: 2, Loss: 0.0140\n",
            "Epoch: 893, Batch: 3, Loss: 0.1646\n",
            "Epoch: 893, Training Accuracy: 97.52%, Validation Accuracy: 92.86%\n",
            "Epoch: 894, Batch: 0, Loss: 0.0428\n",
            "Epoch: 894, Batch: 1, Loss: 0.0151\n",
            "Epoch: 894, Batch: 2, Loss: 0.0289\n",
            "Epoch: 894, Batch: 3, Loss: 0.1778\n",
            "Epoch: 894, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 895, Batch: 0, Loss: 0.0259\n",
            "Epoch: 895, Batch: 1, Loss: 0.0214\n",
            "Epoch: 895, Batch: 2, Loss: 0.1285\n",
            "Epoch: 895, Batch: 3, Loss: 0.0262\n",
            "Epoch: 895, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 896, Batch: 0, Loss: 0.0168\n",
            "Epoch: 896, Batch: 1, Loss: 0.0074\n",
            "Epoch: 896, Batch: 2, Loss: 0.1256\n",
            "Epoch: 896, Batch: 3, Loss: 0.0613\n",
            "Epoch: 896, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 897, Batch: 0, Loss: 0.0035\n",
            "Epoch: 897, Batch: 1, Loss: 0.0181\n",
            "Epoch: 897, Batch: 2, Loss: 0.0581\n",
            "Epoch: 897, Batch: 3, Loss: 0.1429\n",
            "Epoch: 897, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 898, Batch: 0, Loss: 0.0732\n",
            "Epoch: 898, Batch: 1, Loss: 0.0197\n",
            "Epoch: 898, Batch: 2, Loss: 0.0386\n",
            "Epoch: 898, Batch: 3, Loss: 0.0621\n",
            "Epoch: 898, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 899, Batch: 0, Loss: 0.0378\n",
            "Epoch: 899, Batch: 1, Loss: 0.1189\n",
            "Epoch: 899, Batch: 2, Loss: 0.0178\n",
            "Epoch: 899, Batch: 3, Loss: 0.0356\n",
            "Epoch: 899, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 900, Batch: 0, Loss: 0.0439\n",
            "Epoch: 900, Batch: 1, Loss: 0.1001\n",
            "Epoch: 900, Batch: 2, Loss: 0.0451\n",
            "Epoch: 900, Batch: 3, Loss: 0.0045\n",
            "Epoch: 900, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 901, Batch: 0, Loss: 0.0396\n",
            "Epoch: 901, Batch: 1, Loss: 0.0413\n",
            "Epoch: 901, Batch: 2, Loss: 0.1170\n",
            "Epoch: 901, Batch: 3, Loss: 0.0019\n",
            "Epoch: 901, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 902, Batch: 0, Loss: 0.0517\n",
            "Epoch: 902, Batch: 1, Loss: 0.0943\n",
            "Epoch: 902, Batch: 2, Loss: 0.0152\n",
            "Epoch: 902, Batch: 3, Loss: 0.0319\n",
            "Epoch: 902, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 903, Batch: 0, Loss: 0.0157\n",
            "Epoch: 903, Batch: 1, Loss: 0.0142\n",
            "Epoch: 903, Batch: 2, Loss: 0.1533\n",
            "Epoch: 903, Batch: 3, Loss: 0.0251\n",
            "Epoch: 903, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 904, Batch: 0, Loss: 0.0405\n",
            "Epoch: 904, Batch: 1, Loss: 0.0148\n",
            "Epoch: 904, Batch: 2, Loss: 0.0232\n",
            "Epoch: 904, Batch: 3, Loss: 0.1288\n",
            "Epoch: 904, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 905, Batch: 0, Loss: 0.0493\n",
            "Epoch: 905, Batch: 1, Loss: 0.0308\n",
            "Epoch: 905, Batch: 2, Loss: 0.1168\n",
            "Epoch: 905, Batch: 3, Loss: 0.0371\n",
            "Epoch: 905, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 906, Batch: 0, Loss: 0.1059\n",
            "Epoch: 906, Batch: 1, Loss: 0.0550\n",
            "Epoch: 906, Batch: 2, Loss: 0.0238\n",
            "Epoch: 906, Batch: 3, Loss: 0.0057\n",
            "Epoch: 906, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 907, Batch: 0, Loss: 0.0377\n",
            "Epoch: 907, Batch: 1, Loss: 0.0313\n",
            "Epoch: 907, Batch: 2, Loss: 0.1010\n",
            "Epoch: 907, Batch: 3, Loss: 0.0109\n",
            "Epoch: 907, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 908, Batch: 0, Loss: 0.0908\n",
            "Epoch: 908, Batch: 1, Loss: 0.0207\n",
            "Epoch: 908, Batch: 2, Loss: 0.0725\n",
            "Epoch: 908, Batch: 3, Loss: 0.0351\n",
            "Epoch: 908, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 909, Batch: 0, Loss: 0.0193\n",
            "Epoch: 909, Batch: 1, Loss: 0.1170\n",
            "Epoch: 909, Batch: 2, Loss: 0.0191\n",
            "Epoch: 909, Batch: 3, Loss: 0.0294\n",
            "Epoch: 909, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 910, Batch: 0, Loss: 0.1420\n",
            "Epoch: 910, Batch: 1, Loss: 0.0103\n",
            "Epoch: 910, Batch: 2, Loss: 0.0497\n",
            "Epoch: 910, Batch: 3, Loss: 0.0088\n",
            "Epoch: 910, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 911, Batch: 0, Loss: 0.0041\n",
            "Epoch: 911, Batch: 1, Loss: 0.0223\n",
            "Epoch: 911, Batch: 2, Loss: 0.1339\n",
            "Epoch: 911, Batch: 3, Loss: 0.0631\n",
            "Epoch: 911, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 912, Batch: 0, Loss: 0.0075\n",
            "Epoch: 912, Batch: 1, Loss: 0.0201\n",
            "Epoch: 912, Batch: 2, Loss: 0.0360\n",
            "Epoch: 912, Batch: 3, Loss: 0.1458\n",
            "Epoch: 912, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 913, Batch: 0, Loss: 0.0643\n",
            "Epoch: 913, Batch: 1, Loss: 0.0302\n",
            "Epoch: 913, Batch: 2, Loss: 0.0094\n",
            "Epoch: 913, Batch: 3, Loss: 0.1337\n",
            "Epoch: 913, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 914, Batch: 0, Loss: 0.0762\n",
            "Epoch: 914, Batch: 1, Loss: 0.0881\n",
            "Epoch: 914, Batch: 2, Loss: 0.0222\n",
            "Epoch: 914, Batch: 3, Loss: 0.0072\n",
            "Epoch: 914, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 915, Batch: 0, Loss: 0.0395\n",
            "Epoch: 915, Batch: 1, Loss: 0.1225\n",
            "Epoch: 915, Batch: 2, Loss: 0.0073\n",
            "Epoch: 915, Batch: 3, Loss: 0.0227\n",
            "Epoch: 915, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 916, Batch: 0, Loss: 0.0064\n",
            "Epoch: 916, Batch: 1, Loss: 0.1197\n",
            "Epoch: 916, Batch: 2, Loss: 0.0488\n",
            "Epoch: 916, Batch: 3, Loss: 0.0126\n",
            "Epoch: 916, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 917, Batch: 0, Loss: 0.0222\n",
            "Epoch: 917, Batch: 1, Loss: 0.0393\n",
            "Epoch: 917, Batch: 2, Loss: 0.1174\n",
            "Epoch: 917, Batch: 3, Loss: 0.0013\n",
            "Epoch: 917, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 918, Batch: 0, Loss: 0.0269\n",
            "Epoch: 918, Batch: 1, Loss: 0.0056\n",
            "Epoch: 918, Batch: 2, Loss: 0.0251\n",
            "Epoch: 918, Batch: 3, Loss: 0.1602\n",
            "Epoch: 918, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 919, Batch: 0, Loss: 0.0219\n",
            "Epoch: 919, Batch: 1, Loss: 0.0684\n",
            "Epoch: 919, Batch: 2, Loss: 0.1154\n",
            "Epoch: 919, Batch: 3, Loss: 0.0108\n",
            "Epoch: 919, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 920, Batch: 0, Loss: 0.1514\n",
            "Epoch: 920, Batch: 1, Loss: 0.0037\n",
            "Epoch: 920, Batch: 2, Loss: 0.0132\n",
            "Epoch: 920, Batch: 3, Loss: 0.0061\n",
            "Epoch: 920, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 921, Batch: 0, Loss: 0.0252\n",
            "Epoch: 921, Batch: 1, Loss: 0.0026\n",
            "Epoch: 921, Batch: 2, Loss: 0.0349\n",
            "Epoch: 921, Batch: 3, Loss: 0.1659\n",
            "Epoch: 921, Training Accuracy: 97.52%, Validation Accuracy: 92.86%\n",
            "Epoch: 922, Batch: 0, Loss: 0.1201\n",
            "Epoch: 922, Batch: 1, Loss: 0.0036\n",
            "Epoch: 922, Batch: 2, Loss: 0.0293\n",
            "Epoch: 922, Batch: 3, Loss: 0.1430\n",
            "Epoch: 922, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 923, Batch: 0, Loss: 0.1171\n",
            "Epoch: 923, Batch: 1, Loss: 0.0136\n",
            "Epoch: 923, Batch: 2, Loss: 0.0146\n",
            "Epoch: 923, Batch: 3, Loss: 0.0433\n",
            "Epoch: 923, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 924, Batch: 0, Loss: 0.0247\n",
            "Epoch: 924, Batch: 1, Loss: 0.1349\n",
            "Epoch: 924, Batch: 2, Loss: 0.0089\n",
            "Epoch: 924, Batch: 3, Loss: 0.0174\n",
            "Epoch: 924, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 925, Batch: 0, Loss: 0.1139\n",
            "Epoch: 925, Batch: 1, Loss: 0.0823\n",
            "Epoch: 925, Batch: 2, Loss: 0.0250\n",
            "Epoch: 925, Batch: 3, Loss: 0.0245\n",
            "Epoch: 925, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 926, Batch: 0, Loss: 0.0413\n",
            "Epoch: 926, Batch: 1, Loss: 0.0240\n",
            "Epoch: 926, Batch: 2, Loss: 0.1122\n",
            "Epoch: 926, Batch: 3, Loss: 0.0006\n",
            "Epoch: 926, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 927, Batch: 0, Loss: 0.0889\n",
            "Epoch: 927, Batch: 1, Loss: 0.0548\n",
            "Epoch: 927, Batch: 2, Loss: 0.0519\n",
            "Epoch: 927, Batch: 3, Loss: 0.0040\n",
            "Epoch: 927, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 928, Batch: 0, Loss: 0.0197\n",
            "Epoch: 928, Batch: 1, Loss: 0.1466\n",
            "Epoch: 928, Batch: 2, Loss: 0.0217\n",
            "Epoch: 928, Batch: 3, Loss: 0.0339\n",
            "Epoch: 928, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 929, Batch: 0, Loss: 0.0408\n",
            "Epoch: 929, Batch: 1, Loss: 0.1209\n",
            "Epoch: 929, Batch: 2, Loss: 0.0032\n",
            "Epoch: 929, Batch: 3, Loss: 0.0464\n",
            "Epoch: 929, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 930, Batch: 0, Loss: 0.0066\n",
            "Epoch: 930, Batch: 1, Loss: 0.0334\n",
            "Epoch: 930, Batch: 2, Loss: 0.1787\n",
            "Epoch: 930, Batch: 3, Loss: 0.0365\n",
            "Epoch: 930, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 931, Batch: 0, Loss: 0.0518\n",
            "Epoch: 931, Batch: 1, Loss: 0.0062\n",
            "Epoch: 931, Batch: 2, Loss: 0.1521\n",
            "Epoch: 931, Batch: 3, Loss: 0.0187\n",
            "Epoch: 931, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 932, Batch: 0, Loss: 0.0504\n",
            "Epoch: 932, Batch: 1, Loss: 0.0347\n",
            "Epoch: 932, Batch: 2, Loss: 0.0050\n",
            "Epoch: 932, Batch: 3, Loss: 0.1467\n",
            "Epoch: 932, Training Accuracy: 97.52%, Validation Accuracy: 92.86%\n",
            "Epoch: 933, Batch: 0, Loss: 0.0688\n",
            "Epoch: 933, Batch: 1, Loss: 0.0952\n",
            "Epoch: 933, Batch: 2, Loss: 0.0253\n",
            "Epoch: 933, Batch: 3, Loss: 0.0252\n",
            "Epoch: 933, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 934, Batch: 0, Loss: 0.0269\n",
            "Epoch: 934, Batch: 1, Loss: 0.1187\n",
            "Epoch: 934, Batch: 2, Loss: 0.0077\n",
            "Epoch: 934, Batch: 3, Loss: 0.0422\n",
            "Epoch: 934, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 935, Batch: 0, Loss: 0.1022\n",
            "Epoch: 935, Batch: 1, Loss: 0.0099\n",
            "Epoch: 935, Batch: 2, Loss: 0.0458\n",
            "Epoch: 935, Batch: 3, Loss: 0.0473\n",
            "Epoch: 935, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 936, Batch: 0, Loss: 0.0041\n",
            "Epoch: 936, Batch: 1, Loss: 0.0121\n",
            "Epoch: 936, Batch: 2, Loss: 0.1467\n",
            "Epoch: 936, Batch: 3, Loss: 0.0137\n",
            "Epoch: 936, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 937, Batch: 0, Loss: 0.0192\n",
            "Epoch: 937, Batch: 1, Loss: 0.0389\n",
            "Epoch: 937, Batch: 2, Loss: 0.1369\n",
            "Epoch: 937, Batch: 3, Loss: 0.0176\n",
            "Epoch: 937, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 938, Batch: 0, Loss: 0.0094\n",
            "Epoch: 938, Batch: 1, Loss: 0.0104\n",
            "Epoch: 938, Batch: 2, Loss: 0.1545\n",
            "Epoch: 938, Batch: 3, Loss: 0.0044\n",
            "Epoch: 938, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 939, Batch: 0, Loss: 0.0803\n",
            "Epoch: 939, Batch: 1, Loss: 0.0085\n",
            "Epoch: 939, Batch: 2, Loss: 0.1061\n",
            "Epoch: 939, Batch: 3, Loss: 0.0178\n",
            "Epoch: 939, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 940, Batch: 0, Loss: 0.0060\n",
            "Epoch: 940, Batch: 1, Loss: 0.0993\n",
            "Epoch: 940, Batch: 2, Loss: 0.0447\n",
            "Epoch: 940, Batch: 3, Loss: 0.0398\n",
            "Epoch: 940, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 941, Batch: 0, Loss: 0.0359\n",
            "Epoch: 941, Batch: 1, Loss: 0.0350\n",
            "Epoch: 941, Batch: 2, Loss: 0.1126\n",
            "Epoch: 941, Batch: 3, Loss: 0.0175\n",
            "Epoch: 941, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 942, Batch: 0, Loss: 0.0365\n",
            "Epoch: 942, Batch: 1, Loss: 0.0017\n",
            "Epoch: 942, Batch: 2, Loss: 0.1061\n",
            "Epoch: 942, Batch: 3, Loss: 0.0966\n",
            "Epoch: 942, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 943, Batch: 0, Loss: 0.0149\n",
            "Epoch: 943, Batch: 1, Loss: 0.0072\n",
            "Epoch: 943, Batch: 2, Loss: 0.1499\n",
            "Epoch: 943, Batch: 3, Loss: 0.0221\n",
            "Epoch: 943, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 944, Batch: 0, Loss: 0.0171\n",
            "Epoch: 944, Batch: 1, Loss: 0.0545\n",
            "Epoch: 944, Batch: 2, Loss: 0.1147\n",
            "Epoch: 944, Batch: 3, Loss: 0.0022\n",
            "Epoch: 944, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 945, Batch: 0, Loss: 0.0045\n",
            "Epoch: 945, Batch: 1, Loss: 0.0328\n",
            "Epoch: 945, Batch: 2, Loss: 0.0451\n",
            "Epoch: 945, Batch: 3, Loss: 0.1299\n",
            "Epoch: 945, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 946, Batch: 0, Loss: 0.0751\n",
            "Epoch: 946, Batch: 1, Loss: 0.1051\n",
            "Epoch: 946, Batch: 2, Loss: 0.0306\n",
            "Epoch: 946, Batch: 3, Loss: 0.0228\n",
            "Epoch: 946, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 947, Batch: 0, Loss: 0.0337\n",
            "Epoch: 947, Batch: 1, Loss: 0.0292\n",
            "Epoch: 947, Batch: 2, Loss: 0.0249\n",
            "Epoch: 947, Batch: 3, Loss: 0.1148\n",
            "Epoch: 947, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 948, Batch: 0, Loss: 0.0305\n",
            "Epoch: 948, Batch: 1, Loss: 0.1238\n",
            "Epoch: 948, Batch: 2, Loss: 0.0259\n",
            "Epoch: 948, Batch: 3, Loss: 0.0248\n",
            "Epoch: 948, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 949, Batch: 0, Loss: 0.0093\n",
            "Epoch: 949, Batch: 1, Loss: 0.0307\n",
            "Epoch: 949, Batch: 2, Loss: 0.0072\n",
            "Epoch: 949, Batch: 3, Loss: 0.2252\n",
            "Epoch: 949, Training Accuracy: 94.21%, Validation Accuracy: 92.86%\n",
            "Epoch: 950, Batch: 0, Loss: 0.0866\n",
            "Epoch: 950, Batch: 1, Loss: 0.0473\n",
            "Epoch: 950, Batch: 2, Loss: 0.1102\n",
            "Epoch: 950, Batch: 3, Loss: 0.0210\n",
            "Epoch: 950, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 951, Batch: 0, Loss: 0.0183\n",
            "Epoch: 951, Batch: 1, Loss: 0.0027\n",
            "Epoch: 951, Batch: 2, Loss: 0.1462\n",
            "Epoch: 951, Batch: 3, Loss: 0.0243\n",
            "Epoch: 951, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 952, Batch: 0, Loss: 0.1370\n",
            "Epoch: 952, Batch: 1, Loss: 0.0195\n",
            "Epoch: 952, Batch: 2, Loss: 0.0082\n",
            "Epoch: 952, Batch: 3, Loss: 0.0080\n",
            "Epoch: 952, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 953, Batch: 0, Loss: 0.1149\n",
            "Epoch: 953, Batch: 1, Loss: 0.0284\n",
            "Epoch: 953, Batch: 2, Loss: 0.0073\n",
            "Epoch: 953, Batch: 3, Loss: 0.0462\n",
            "Epoch: 953, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 954, Batch: 0, Loss: 0.0186\n",
            "Epoch: 954, Batch: 1, Loss: 0.0249\n",
            "Epoch: 954, Batch: 2, Loss: 0.0213\n",
            "Epoch: 954, Batch: 3, Loss: 0.1403\n",
            "Epoch: 954, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 955, Batch: 0, Loss: 0.0570\n",
            "Epoch: 955, Batch: 1, Loss: 0.0244\n",
            "Epoch: 955, Batch: 2, Loss: 0.1071\n",
            "Epoch: 955, Batch: 3, Loss: 0.0015\n",
            "Epoch: 955, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 956, Batch: 0, Loss: 0.0500\n",
            "Epoch: 956, Batch: 1, Loss: 0.0015\n",
            "Epoch: 956, Batch: 2, Loss: 0.1092\n",
            "Epoch: 956, Batch: 3, Loss: 0.0637\n",
            "Epoch: 956, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 957, Batch: 0, Loss: 0.1107\n",
            "Epoch: 957, Batch: 1, Loss: 0.0421\n",
            "Epoch: 957, Batch: 2, Loss: 0.0088\n",
            "Epoch: 957, Batch: 3, Loss: 0.0335\n",
            "Epoch: 957, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 958, Batch: 0, Loss: 0.0020\n",
            "Epoch: 958, Batch: 1, Loss: 0.1018\n",
            "Epoch: 958, Batch: 2, Loss: 0.0573\n",
            "Epoch: 958, Batch: 3, Loss: 0.0324\n",
            "Epoch: 958, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 959, Batch: 0, Loss: 0.0410\n",
            "Epoch: 959, Batch: 1, Loss: 0.0066\n",
            "Epoch: 959, Batch: 2, Loss: 0.1246\n",
            "Epoch: 959, Batch: 3, Loss: 0.0353\n",
            "Epoch: 959, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 960, Batch: 0, Loss: 0.0169\n",
            "Epoch: 960, Batch: 1, Loss: 0.0571\n",
            "Epoch: 960, Batch: 2, Loss: 0.0178\n",
            "Epoch: 960, Batch: 3, Loss: 0.1409\n",
            "Epoch: 960, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 961, Batch: 0, Loss: 0.0128\n",
            "Epoch: 961, Batch: 1, Loss: 0.0534\n",
            "Epoch: 961, Batch: 2, Loss: 0.0068\n",
            "Epoch: 961, Batch: 3, Loss: 0.1414\n",
            "Epoch: 961, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 962, Batch: 0, Loss: 0.1080\n",
            "Epoch: 962, Batch: 1, Loss: 0.0450\n",
            "Epoch: 962, Batch: 2, Loss: 0.0216\n",
            "Epoch: 962, Batch: 3, Loss: 0.0071\n",
            "Epoch: 962, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 963, Batch: 0, Loss: 0.0048\n",
            "Epoch: 963, Batch: 1, Loss: 0.0323\n",
            "Epoch: 963, Batch: 2, Loss: 0.1041\n",
            "Epoch: 963, Batch: 3, Loss: 0.0546\n",
            "Epoch: 963, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 964, Batch: 0, Loss: 0.0334\n",
            "Epoch: 964, Batch: 1, Loss: 0.0376\n",
            "Epoch: 964, Batch: 2, Loss: 0.0039\n",
            "Epoch: 964, Batch: 3, Loss: 0.1333\n",
            "Epoch: 964, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 965, Batch: 0, Loss: 0.1565\n",
            "Epoch: 965, Batch: 1, Loss: 0.0055\n",
            "Epoch: 965, Batch: 2, Loss: 0.0220\n",
            "Epoch: 965, Batch: 3, Loss: 0.0200\n",
            "Epoch: 965, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 966, Batch: 0, Loss: 0.0164\n",
            "Epoch: 966, Batch: 1, Loss: 0.0160\n",
            "Epoch: 966, Batch: 2, Loss: 0.0199\n",
            "Epoch: 966, Batch: 3, Loss: 0.1573\n",
            "Epoch: 966, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 967, Batch: 0, Loss: 0.0231\n",
            "Epoch: 967, Batch: 1, Loss: 0.0909\n",
            "Epoch: 967, Batch: 2, Loss: 0.0413\n",
            "Epoch: 967, Batch: 3, Loss: 0.0542\n",
            "Epoch: 967, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 968, Batch: 0, Loss: 0.0317\n",
            "Epoch: 968, Batch: 1, Loss: 0.1363\n",
            "Epoch: 968, Batch: 2, Loss: 0.0456\n",
            "Epoch: 968, Batch: 3, Loss: 0.0065\n",
            "Epoch: 968, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 969, Batch: 0, Loss: 0.0220\n",
            "Epoch: 969, Batch: 1, Loss: 0.0191\n",
            "Epoch: 969, Batch: 2, Loss: 0.0312\n",
            "Epoch: 969, Batch: 3, Loss: 0.1598\n",
            "Epoch: 969, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 970, Batch: 0, Loss: 0.0036\n",
            "Epoch: 970, Batch: 1, Loss: 0.0187\n",
            "Epoch: 970, Batch: 2, Loss: 0.1261\n",
            "Epoch: 970, Batch: 3, Loss: 0.0377\n",
            "Epoch: 970, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 971, Batch: 0, Loss: 0.0227\n",
            "Epoch: 971, Batch: 1, Loss: 0.1000\n",
            "Epoch: 971, Batch: 2, Loss: 0.0342\n",
            "Epoch: 971, Batch: 3, Loss: 0.0403\n",
            "Epoch: 971, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 972, Batch: 0, Loss: 0.1404\n",
            "Epoch: 972, Batch: 1, Loss: 0.0213\n",
            "Epoch: 972, Batch: 2, Loss: 0.0288\n",
            "Epoch: 972, Batch: 3, Loss: 0.0038\n",
            "Epoch: 972, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 973, Batch: 0, Loss: 0.0152\n",
            "Epoch: 973, Batch: 1, Loss: 0.0288\n",
            "Epoch: 973, Batch: 2, Loss: 0.0404\n",
            "Epoch: 973, Batch: 3, Loss: 0.1284\n",
            "Epoch: 973, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 974, Batch: 0, Loss: 0.0549\n",
            "Epoch: 974, Batch: 1, Loss: 0.0086\n",
            "Epoch: 974, Batch: 2, Loss: 0.1245\n",
            "Epoch: 974, Batch: 3, Loss: 0.0159\n",
            "Epoch: 974, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 975, Batch: 0, Loss: 0.0014\n",
            "Epoch: 975, Batch: 1, Loss: 0.0291\n",
            "Epoch: 975, Batch: 2, Loss: 0.1511\n",
            "Epoch: 975, Batch: 3, Loss: 0.0372\n",
            "Epoch: 975, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 976, Batch: 0, Loss: 0.0188\n",
            "Epoch: 976, Batch: 1, Loss: 0.1008\n",
            "Epoch: 976, Batch: 2, Loss: 0.0723\n",
            "Epoch: 976, Batch: 3, Loss: 0.0060\n",
            "Epoch: 976, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 977, Batch: 0, Loss: 0.0467\n",
            "Epoch: 977, Batch: 1, Loss: 0.0048\n",
            "Epoch: 977, Batch: 2, Loss: 0.0257\n",
            "Epoch: 977, Batch: 3, Loss: 0.1266\n",
            "Epoch: 977, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 978, Batch: 0, Loss: 0.0361\n",
            "Epoch: 978, Batch: 1, Loss: 0.1343\n",
            "Epoch: 978, Batch: 2, Loss: 0.0392\n",
            "Epoch: 978, Batch: 3, Loss: 0.0057\n",
            "Epoch: 978, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 979, Batch: 0, Loss: 0.1089\n",
            "Epoch: 979, Batch: 1, Loss: 0.0989\n",
            "Epoch: 979, Batch: 2, Loss: 0.0049\n",
            "Epoch: 979, Batch: 3, Loss: 0.0100\n",
            "Epoch: 979, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 980, Batch: 0, Loss: 0.0236\n",
            "Epoch: 980, Batch: 1, Loss: 0.0213\n",
            "Epoch: 980, Batch: 2, Loss: 0.0291\n",
            "Epoch: 980, Batch: 3, Loss: 0.1445\n",
            "Epoch: 980, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 981, Batch: 0, Loss: 0.0418\n",
            "Epoch: 981, Batch: 1, Loss: 0.0533\n",
            "Epoch: 981, Batch: 2, Loss: 0.0044\n",
            "Epoch: 981, Batch: 3, Loss: 0.1094\n",
            "Epoch: 981, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 982, Batch: 0, Loss: 0.0940\n",
            "Epoch: 982, Batch: 1, Loss: 0.0554\n",
            "Epoch: 982, Batch: 2, Loss: 0.0170\n",
            "Epoch: 982, Batch: 3, Loss: 0.0200\n",
            "Epoch: 982, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 983, Batch: 0, Loss: 0.1197\n",
            "Epoch: 983, Batch: 1, Loss: 0.0166\n",
            "Epoch: 983, Batch: 2, Loss: 0.0376\n",
            "Epoch: 983, Batch: 3, Loss: 0.0448\n",
            "Epoch: 983, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 984, Batch: 0, Loss: 0.0221\n",
            "Epoch: 984, Batch: 1, Loss: 0.0063\n",
            "Epoch: 984, Batch: 2, Loss: 0.1602\n",
            "Epoch: 984, Batch: 3, Loss: 0.1031\n",
            "Epoch: 984, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 985, Batch: 0, Loss: 0.0232\n",
            "Epoch: 985, Batch: 1, Loss: 0.1562\n",
            "Epoch: 985, Batch: 2, Loss: 0.0060\n",
            "Epoch: 985, Batch: 3, Loss: 0.0196\n",
            "Epoch: 985, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 986, Batch: 0, Loss: 0.1144\n",
            "Epoch: 986, Batch: 1, Loss: 0.0299\n",
            "Epoch: 986, Batch: 2, Loss: 0.0162\n",
            "Epoch: 986, Batch: 3, Loss: 0.0305\n",
            "Epoch: 986, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 987, Batch: 0, Loss: 0.1056\n",
            "Epoch: 987, Batch: 1, Loss: 0.0090\n",
            "Epoch: 987, Batch: 2, Loss: 0.0564\n",
            "Epoch: 987, Batch: 3, Loss: 0.0099\n",
            "Epoch: 987, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 988, Batch: 0, Loss: 0.0151\n",
            "Epoch: 988, Batch: 1, Loss: 0.1348\n",
            "Epoch: 988, Batch: 2, Loss: 0.0188\n",
            "Epoch: 988, Batch: 3, Loss: 0.0598\n",
            "Epoch: 988, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 989, Batch: 0, Loss: 0.1186\n",
            "Epoch: 989, Batch: 1, Loss: 0.0153\n",
            "Epoch: 989, Batch: 2, Loss: 0.0484\n",
            "Epoch: 989, Batch: 3, Loss: 0.0217\n",
            "Epoch: 989, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 990, Batch: 0, Loss: 0.0035\n",
            "Epoch: 990, Batch: 1, Loss: 0.0431\n",
            "Epoch: 990, Batch: 2, Loss: 0.0059\n",
            "Epoch: 990, Batch: 3, Loss: 0.1742\n",
            "Epoch: 990, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 991, Batch: 0, Loss: 0.1072\n",
            "Epoch: 991, Batch: 1, Loss: 0.0728\n",
            "Epoch: 991, Batch: 2, Loss: 0.0136\n",
            "Epoch: 991, Batch: 3, Loss: 0.1164\n",
            "Epoch: 991, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 992, Batch: 0, Loss: 0.0366\n",
            "Epoch: 992, Batch: 1, Loss: 0.0042\n",
            "Epoch: 992, Batch: 2, Loss: 0.0812\n",
            "Epoch: 992, Batch: 3, Loss: 0.1232\n",
            "Epoch: 992, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 993, Batch: 0, Loss: 0.1462\n",
            "Epoch: 993, Batch: 1, Loss: 0.0356\n",
            "Epoch: 993, Batch: 2, Loss: 0.0326\n",
            "Epoch: 993, Batch: 3, Loss: 0.0046\n",
            "Epoch: 993, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 994, Batch: 0, Loss: 0.0254\n",
            "Epoch: 994, Batch: 1, Loss: 0.0363\n",
            "Epoch: 994, Batch: 2, Loss: 0.1143\n",
            "Epoch: 994, Batch: 3, Loss: 0.0058\n",
            "Epoch: 994, Training Accuracy: 98.35%, Validation Accuracy: 85.71%\n",
            "Epoch: 995, Batch: 0, Loss: 0.0370\n",
            "Epoch: 995, Batch: 1, Loss: 0.0494\n",
            "Epoch: 995, Batch: 2, Loss: 0.0165\n",
            "Epoch: 995, Batch: 3, Loss: 0.1212\n",
            "Epoch: 995, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 996, Batch: 0, Loss: 0.0592\n",
            "Epoch: 996, Batch: 1, Loss: 0.0195\n",
            "Epoch: 996, Batch: 2, Loss: 0.1003\n",
            "Epoch: 996, Batch: 3, Loss: 0.0383\n",
            "Epoch: 996, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n",
            "Epoch: 997, Batch: 0, Loss: 0.1040\n",
            "Epoch: 997, Batch: 1, Loss: 0.0504\n",
            "Epoch: 997, Batch: 2, Loss: 0.0418\n",
            "Epoch: 997, Batch: 3, Loss: 0.0048\n",
            "Epoch: 997, Training Accuracy: 97.52%, Validation Accuracy: 85.71%\n",
            "Epoch: 998, Batch: 0, Loss: 0.0054\n",
            "Epoch: 998, Batch: 1, Loss: 0.0070\n",
            "Epoch: 998, Batch: 2, Loss: 0.0490\n",
            "Epoch: 998, Batch: 3, Loss: 0.1512\n",
            "Epoch: 998, Training Accuracy: 97.52%, Validation Accuracy: 78.57%\n",
            "Epoch: 999, Batch: 0, Loss: 0.0748\n",
            "Epoch: 999, Batch: 1, Loss: 0.0621\n",
            "Epoch: 999, Batch: 2, Loss: 0.0327\n",
            "Epoch: 999, Batch: 3, Loss: 0.0119\n",
            "Epoch: 999, Training Accuracy: 99.17%, Validation Accuracy: 85.71%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc = compute_accuracy(model,train_loader)\n",
        "val_acc = compute_accuracy(model,val_loader)\n",
        "test_acc = compute_accuracy(model,test_loader)\n",
        "\n",
        "print(f'Training Accuracy: {train_acc * 100:.2f}%')\n",
        "print(f'Validation Accuracy: {val_acc * 100:.2f}%')\n",
        "print(f'Testing Accuracy: {test_acc * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocg_PYuFK_uT",
        "outputId": "c8241e94-1291-47b2-d159-1f8fe6b12564"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 98.35%\n",
            "Validation Accuracy: 85.71%\n",
            "Testing Accuracy: 100.00%\n"
          ]
        }
      ]
    }
  ]
}